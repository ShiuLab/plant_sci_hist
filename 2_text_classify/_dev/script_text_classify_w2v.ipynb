{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 2b: Word2Vec models__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Setup__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For building text classification model based on embedding of Word2Vec and BERT\n",
    "'''\n",
    "\n",
    "## for data\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import chdir\n",
    "from pathlib import Path\n",
    "\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, feature_selection, metrics\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4016c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for word embedding with w2v\n",
    "import gensim\n",
    "\n",
    "## for deep learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, callbacks\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Functions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_configs(config_file):\n",
    "  \"\"\"Read configuration file and return a config_dict\"\"\"\n",
    "  # required\n",
    "  config_dict = {'lang_model':0,\n",
    "                 'proj_dir':0,\n",
    "                 'work_dir':0,\n",
    "                 'corpus_combo_file':0,\n",
    "                 'rand_state':0,\n",
    "                 'xg_param':0,\n",
    "                 'n_splits':0,\n",
    "                 'xg_param_comb':0,\n",
    "                 'n_jobs':0,}\n",
    "\n",
    "  # Read config file and fill in the dictionary\n",
    "  with open(config_file, 'r') as f:\n",
    "    configs     = f.readlines()\n",
    "    for config in configs:\n",
    "      if config.strip() == \"\" or config[0] == \"#\":\n",
    "        pass\n",
    "      else:\n",
    "        config = config.strip().split(\"=\")\n",
    "        if config[0] in config_dict:\n",
    "          config_dict[config[0]] = eval(config[1])\n",
    "\n",
    "  # Check if any config missing\n",
    "  missing = 0\n",
    "  for config in config_dict:\n",
    "    if config_dict[config] == 0:\n",
    "      print(\"  missing:\", config)\n",
    "      missing += 1\n",
    "    else:\n",
    "      print(\"  \", config, \"=\", config_dict[config])\n",
    "\n",
    "  if missing == 0:\n",
    "    print(\"  all config available\")\n",
    "  else:\n",
    "    print(\"  missing config, QUIT!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "  return config_dict\n",
    "\n",
    "\n",
    "def split_train_test(corpus_combo_file, rand_state):\n",
    "  '''Load data and split train test\n",
    "  Args:\n",
    "    corpus_combo_file (str): path to the json data file\n",
    "    rand_state (int): for reproducibility\n",
    "  Return:\n",
    "    train_ori, test_ori, train_cln, test_cln (pandas dataframes): for the\n",
    "      original and clean texts, training and testing splits.\n",
    "  '''\n",
    "  # Load json file\n",
    "  with corpus_combo_file.open(\"r+\") as f:\n",
    "      corpus_combo_json = json.load(f)\n",
    "\n",
    "  # Convert json back to dataframe\n",
    "  corpus_combo = pd.read_json(corpus_combo_json)\n",
    "\n",
    "  corpus_ori = corpus_combo[['label','txt']]\n",
    "  train_ori, test_ori = model_selection.train_test_split(corpus_ori, \n",
    "      test_size=0.2, stratify=corpus_ori['label'], random_state=rand_state)\n",
    "\n",
    "  # Cleaned corpus\n",
    "  corpus_cln = corpus_combo[['label','txt_clean']]\n",
    "  corpus_cln.rename(columns={'txt_clean': 'txt'}) # make col names consistent\n",
    "  train_cln, test_cln = model_selection.train_test_split(corpus_cln, \n",
    "      test_size=0.2, stratify=corpus_cln['label'], random_state=rand_state)\n",
    "\n",
    "  return train_ori, test_ori, train_cln, test_cln\n",
    "  \n",
    "\n",
    "def run_main_function(work_dir, train, test, txt_flag, config_dict):\n",
    "\n",
    "  # Get the training/testing corpus and labels\n",
    "  if txt_flag == \"ori\":\n",
    "    X_train = train['txt']\n",
    "    X_test  = test['txt']\n",
    "  else:\n",
    "    X_train = train['txt_clean']\n",
    "    X_test  = test['txt_clean']\n",
    "\n",
    "  y_train = train['label']\n",
    "  y_test  = test['label']\n",
    "\n",
    "  # get vectorizer parameter list\n",
    "  p_threshold = config_dict['p_threshold']\n",
    "  param_list  = get_hyperparameters(config_dict['vec_param'], p_threshold)\n",
    "  lang_model  = config_dict['lang_model']\n",
    "\n",
    "  # iterate through different parameters\n",
    "  with open(work_dir / f\"scores_{txt_flag}\", \"w\") as f:\n",
    "    f.write(\"run\\ttxt_flag\\tlang_model\\tparameters\\tnum_feat\\tcv_f1\\t\" +\\\n",
    "            \"test_f1\\tmodel_name\\n\")\n",
    "    run_num = 0\n",
    "    for param in param_list:\n",
    "      print(f\"\\n## param: {param}\")\n",
    "      best_score, num_select, model_name, test_score = run_pipeline(\n",
    "        work_dir, X_train, y_train, X_test, y_test, param, txt_flag, config_dict)\n",
    "\n",
    "      f.write(f\"{run_num}\\t{txt_flag}\\t{lang_model}\\t{str(param)}\\t\"+\\\n",
    "              f\"{num_select}\\t{best_score}\\t{test_score}\\t{model_name}\\n\")\n",
    "\n",
    "      run_num += 1\n",
    "\n",
    "\n",
    "def run_pipeline(work_dir, X_train, y_train, X_test, y_test, param, txt_flag,\n",
    "                 config_dict):\n",
    "  '''Carry out the major steps'''\n",
    "\n",
    "  # Get vectorizer and fitted X_train\n",
    "  print(\"  extract features by fitting a vectorizer\")\n",
    "  lang_model = config_dict['lang_model']\n",
    "  vectorizer, X_train_vec = extract_feat(X_train, param, lang_model)\n",
    "  print(\"    train dim:\", X_train_vec.shape)\n",
    "\n",
    "  # Get selected feature names\n",
    "  print(\"  select features\")\n",
    "  p_threshold = config_dict['p_threshold']\n",
    "  X_names     = select_feat(X_train_vec, y_train, vectorizer, p_threshold)\n",
    "  num_select  = len(X_names)\n",
    "  print('    total selected:', num_select)\n",
    "\n",
    "  # Refit vectorizer with selected features and re-transform X_train\n",
    "  print(\"  refit vectorizer with training data and transform\")\n",
    "  vectorizer_sel, X_train_vec_sel = extract_feat(X_train, vocab=X_names)\n",
    "  print(\"    train dim:\", X_train_vec_sel.shape)\n",
    "\n",
    "  # Also apply the refitted vecorizer to testing data\n",
    "  print(\"  transform testing data\")\n",
    "  X_test_vec_sel = vectorizer_sel.transform(X_test)\n",
    "  print(\"    test dim:\", X_test_vec_sel.shape)\n",
    "\n",
    "  # Get xgboost model and cv results\n",
    "  print(\"  cross-validation and tuning with xgboost\")\n",
    "  rand_search = run_xgboost(X_train_vec_sel, y_train, config_dict)\n",
    "\n",
    "  best_est   = rand_search.best_estimator_\n",
    "  best_param = rand_search.best_params_\n",
    "  best_score = rand_search.best_score_\n",
    "  print(\"    best F1:\", best_score)\n",
    "  print(\"    best param:\", best_param)\n",
    "\n",
    "  # Save the best model\n",
    "  print (\"  save model\")\n",
    "  param_str  = \\\n",
    "      f\"{int(param[0])}-{'to'.join(map(str,param[1]))}-{param[2]}\"\n",
    "\n",
    "  model_name = work_dir / f'model_{txt_flag}_{param_str}.sav'\n",
    "  joblib.dump(best_est, model_name)\n",
    "\n",
    "  # Get testing results: This is not for tuning/selection purpose but because\n",
    "  # X_test is transformed by vectorizer for each parameter combination. If\n",
    "  # the testing set is not evaluated now, things just get too complicated.\n",
    "  # Keep in mind that the testing F1s will not be compared against each other.\n",
    "  print(\"  get testing f1\")\n",
    "  y_pred = best_est.predict(X_test_vec_sel)\n",
    "  test_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "  # provide some space between runs\n",
    "  print('\\n')\n",
    "\n",
    "  return best_score, num_select, model_name, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Get training/testing split_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read configuration file...\n",
      "   lang_model = w2v\n",
      "   proj_dir = /home/shius/projects/plant_sci_hist\n",
      "   work_dir = 2_text_classify\n",
      "   corpus_combo_file = corpus_combo\n",
      "   rand_state = 20220609\n",
      "   xg_param = {'min_child_weight': [1, 5, 10], 'gamma': [0.5, 1, 1.5, 2, 5], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'max_depth': [3, 4, 5]}\n",
      "   n_splits = 5\n",
      "   xg_param_comb = 5\n",
      "   n_jobs = 12\n",
      "  all config available\n",
      "\n",
      "Read file and split train/test...\n"
     ]
    }
   ],
   "source": [
    "config_file = Path(\"config_w2v.txt\")\n",
    "\n",
    "print(\"\\nRead configuration file...\")\n",
    "config_dict = read_configs(config_file)\n",
    "\n",
    "# Set up working directory and corpus file location\n",
    "proj_dir          = Path(config_dict['proj_dir'])\n",
    "work_dir          = proj_dir / config_dict['work_dir']\n",
    "corpus_combo_file = work_dir / config_dict['corpus_combo_file']\n",
    "\n",
    "# For reproducibility\n",
    "rand_state = config_dict['rand_state']\n",
    "\n",
    "# Split train/test for original and cleaned text\n",
    "print(\"\\nRead file and split train/test...\")\n",
    "train_ori, test_ori, train_cln, test_cln = split_train_test(\n",
    "                                              corpus_combo_file, rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Note_\n",
    "\n",
    "Starting out, I was testing with the original text. When looking into most similar words to \"jasmonate\" there are substantial issue. Top 20 most similar:\n",
    "\n",
    "````Python\n",
    "[('(MeJA)', 0.7294234037399292), ('jasmonic', 0.6400792002677917), ('methyl', 0.638791024684906), ('JA', 0.6380835175514221), ('(JA)', 0.6271078586578369), ('(MeJA),', 0.6264932155609131), ('jasmonate,', 0.6005000472068787), ('(MeJA).', 0.5945847034454346), ('ZIM-domain', 0.5596743226051331), ('jasmonate-', 0.5553220510482788), ('salicylic', 0.5499346256256104), ('JA-isoleucine', 0.5474823713302612), ('12-oxophytodienoic', 0.5435537099838257), ('aminocyclopropane', 0.542698860168457), ('methyl-jasmonate', 0.5406786799430847), ('methyljasmonate', 0.5398091077804565), ('wounding', 0.5363242030143738), ('jasmonate..', 0.5355076789855957), ('acid-isoleucine', 0.531741738319397), ('(MeSA)', 0.5283530950546265)]\n",
    "```\n",
    "\n",
    "So for the next test run repeat and the real run, only cleaned text is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Set up the corpus__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Create a list of unigram lists_\n",
    "\n",
    "A nested list with the first dimension the number of training instances:\n",
    "- 69316\n",
    "\n",
    "Q: Why not use tokenizer now instead of later?\n",
    "- Need to get the unigrams so a tokenizer can be trained.\n",
    "\n",
    "Q: Why bi- and tri-gram detector not used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series,\n",
       " 853778     update exertional hyponatremia active componen...\n",
       " 1165206    stable megadalton toctic supercomplexes major ...\n",
       " Name: txt_clean, dtype: object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the cleaned text as corpus\n",
    "corpus = train_cln['txt_clean'] # pandas Series\n",
    "type(corpus), corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69316"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create list of lists of unigrams\n",
    "lst_corpus = []\n",
    "lst_corpus_test = []\n",
    "for string in corpus:\n",
    "\n",
    "   # Q: lst_words and lst_grams are the same, what's the point?\n",
    "   lst_words = string.split()\n",
    "   #lst_grams = [\" \".join(lst_words[i:i+1]) \n",
    "   #            for i in range(0, len(lst_words), 1)]\n",
    "   #lst_corpus.append(lst_grams)\n",
    "   #lst_corpus_test.append(lst_words)\n",
    "   lst_corpus.append(lst_words)\n",
    "\n",
    "len(lst_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncount_not_the_same = 0\\nfor i in range(len(lst_corpus)):\\n    gram = lst_corpus[i]\\n    word = lst_corpus_test[i]\\n    if gram != word:\\n        count_not_the_same += 1\\nprint(count_not_the_same)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if lst_words and lst_grams are the same. They are EXACTLY the same. So\n",
    "# did not use the lst_gram part in the cell above.\n",
    "'''\n",
    "count_not_the_same = 0\n",
    "for i in range(len(lst_corpus)):\n",
    "    gram = lst_corpus[i]\n",
    "    word = lst_corpus_test[i]\n",
    "    if gram != word:\n",
    "        count_not_the_same += 1\n",
    "print(count_not_the_same)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## detect bigrams and trigrams\n",
    "bigrams_detector  = gensim.models.phrases.Phrases(lst_corpus, \n",
    "                                                  delimiter=\" \", \n",
    "                                                  min_count=5, \n",
    "                                                  threshold=10)\n",
    "bigrams_detector  = gensim.models.phrases.Phraser(bigrams_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the input the trigrams_detector is output of the bigrams_detector\n",
    "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], \n",
    "                                                  delimiter=\" \", \n",
    "                                                  min_count=5, \n",
    "                                                  threshold=10)\n",
    "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d8b33",
   "metadata": {},
   "source": [
    "### _Initialize Word2Vec model_\n",
    "\n",
    "- `sequences`: lst_corpus\n",
    "- `vector_size`: dimension of word embeddings\n",
    "- `window`: max distance between the current and the predicted words in a sentence\n",
    "- `min_count`: ignore all words with total frquency lower than this.\n",
    "  - [Discussion on seeting min_count](https://stackoverflow.com/questions/50723303/how-is-word2vec-min-count-applied)\n",
    "- `sg`: history algorithm, 1: skip-gram, otherwise CBOW.\n",
    "\n",
    "Following [this](https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial/notebook).\n",
    "- Q: Why don't we train the w2v model using bi and tri-grams?\n",
    "  - See [this article](https://www.kaggle.com/code/hamishdickson/training-and-plotting-word2vec-with-bigrams/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = gensim.models.Word2Vec(vector_size=300, window=8, \n",
    "                                   min_count=20, sg=1, epochs=30, workers=16,\n",
    "                                   seed=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Vocabulary Table\n",
    "model_w2v.build_vocab(lst_corpus, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train w2v model\n",
    "model_w2v.train(lst_corpus, total_examples=model_w2v.corpus_count, epochs=30,\n",
    "                report_delay=1)\n",
    "\n",
    "# Save the w2v model\n",
    "with open(work_dir / \"model_cln_w2v\", \"wb\") as f:\n",
    "    pickle.dump(model_w2v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the w2v model\n",
    "with open(work_dir / \"model_cln_w2v\", \"rb\") as f:\n",
    "    model_w2v = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "[('ja', 0.6890448331832886), ('jasmonic', 0.6880596280097961), ('meja', 0.6707953810691833), ('methyl', 0.6292332410812378), ('zimdomain', 0.6150268316268921), ('salicylic', 0.5850669741630554), ('jasmonates', 0.5643168091773987), ('wounding', 0.5591111183166504), ('jaile', 0.545391321182251), ('abscisic', 0.5396086573600769), ('ethylene', 0.5352954864501953), ('jaresponsive', 0.5283914804458618), ('jamediated', 0.5222938060760498), ('jaz', 0.5193976759910583), ('jadependent', 0.5175454020500183), ('myc2', 0.5140773057937622), ('phytohormone', 0.5132154226303101), ('pdf12', 0.5060152411460876), ('coronatine', 0.5018571615219116), ('aba', 0.5010020732879639)]\n"
     ]
    }
   ],
   "source": [
    "# Testing the w2v model\n",
    "# Here there is problem with stop words. Like 'jasmonate..', '(MeJA)', and other\n",
    "# variants. So should use the cleaned text.\n",
    "example = \"jasmonate\"\n",
    "print(len(model_w2v.wv[example]))\n",
    "print(model_w2v.wv.most_similar(example, topn=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Feature engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79996785",
   "metadata": {},
   "source": [
    "#### _Train tokenizer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialize tokenizer\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(\n",
    "                        lower=True, \n",
    "                        split=' ', \n",
    "                        oov_token=\"NaN\", \n",
    "                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "# tokenize corpus \n",
    "tokenizer.fit_on_texts(lst_corpus)\n",
    "\n",
    "# get token dictionary, with token as key, index number as value\n",
    "dic_vocab_token = tokenizer.word_index\n",
    "len(dic_vocab_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f3631",
   "metadata": {},
   "source": [
    "#### _Turn texts into index numbers_\n",
    "\n",
    "Transforms each text in texts to a sequence of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b631dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update', 'exertional', 'hyponatremia', 'active', 'component']\n",
      "[3809, 22571, 17330, 285, 181]\n"
     ]
    }
   ],
   "source": [
    "lst_text2seq = tokenizer.texts_to_sequences(lst_corpus)\n",
    "print(lst_corpus[0][:5])\n",
    "print(lst_text2seq[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e5f571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3809, 22571)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index numbers are the values from the token dictionary\n",
    "# Note that these are lowercased\n",
    "dic_vocab_token['update'], dic_vocab_token['exertional']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Pad or trucate sequences_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499096a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69316, 500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v = keras.preprocessing.sequence.pad_sequences(\n",
    "                    lst_text2seq,      # List of sequences, each a list of ints \n",
    "                    maxlen=500,         # maximum length of all sequences\n",
    "                    padding=\"post\",    # 'pre' or 'post' \n",
    "                    truncating=\"post\") # remove values from sequences > maxlen\n",
    "X_train_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Create embedding matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "## start the matrix (length of vocabulary x vector size) with all 0s\n",
    "\n",
    "embeddings = np.zeros((len(dic_vocab_token)+1, 300))\n",
    "not_in_emb = {}\n",
    "for word, idx in dic_vocab_token.items():\n",
    "    ## update the row with vector\n",
    "    try:\n",
    "        embeddings[idx] =  model_w2v.wv[word]\n",
    "    ## if word not in model then skip and the row stays all 0s\n",
    "    except KeyError:\n",
    "        not_in_emb[word] = 1\n",
    "\n",
    "len(not_in_emb) # Q: How did this got into the corpus??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Set up ANN_\n",
    "\n",
    "The model contains:\n",
    "- An embedding layer:\n",
    "  - Sequences as input (15 tokens, including padding)\n",
    "  - Word (embedding?) vectors as weights (what??)\n",
    "  - Embedding as output (15x300).\n",
    "- An attention layer\n",
    "  - Capture the eughts of each instance for building an explaniner.\n",
    "  - Not needed for the predictions.\n",
    "- Two layers of bidirectional LSTM.\n",
    "- Two final dense layer to predict probabilities of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13763269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_emb_model(embeddings):\n",
    "\n",
    "    ## code attention layer\n",
    "    def attention_layer(inputs, neurons):\n",
    "        x = layers.Permute((2,1))(inputs)\n",
    "        x = layers.Dense(neurons, activation=\"softmax\")(x)\n",
    "        x = layers.Permute((2,1), name=\"attention\")(x)\n",
    "        x = layers.multiply([inputs, x])\n",
    "        return x\n",
    "\n",
    "    ## input\n",
    "    x_in = layers.Input(shape=(500,)) ## embedding\n",
    "    x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
    "                        output_dim=embeddings.shape[1], \n",
    "                        weights=[embeddings],\n",
    "                        input_length=500, trainable=False)(x_in)\n",
    "\n",
    "    ## apply attention\n",
    "    x = attention_layer(x, neurons=500)\n",
    "\n",
    "    ## 2 layers of bidirectional lstm\n",
    "    x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2, \n",
    "                            return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2))(x)\n",
    "\n",
    "    ## final dense layers\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    y_out = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "    ## Initialize and compile model\n",
    "    model = models.Model(x_in, y_out)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = get_w2v_emb_model(embeddings)\n",
    "model_emb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5796c1",
   "metadata": {},
   "source": [
    "#### _Convert text labels to numeric ones_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7818d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode y\n",
    "#  This is the class label, not sure why inversse is done\n",
    "y_train       = train_cln['label']\n",
    "dic_y_mapping = {n:label for n,label in enumerate(np.unique(y_train))}\n",
    "inverse_dic   = {v:k for k,v in dic_y_mapping.items()}\n",
    "inverse_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397318ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text labels to numeric ones.\n",
    "#y_train_label = np.array([inverse_dic[y] for y in y_train])\n",
    "y_train_label = y_train\n",
    "X_train_w2v.shape, len(y_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7c049",
   "metadata": {},
   "source": [
    "#### _Train model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c21389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "callback = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model_emb.fit(x=X_train_w2v, y=y_train_label, batch_size=256, \n",
    "                        epochs=20, shuffle=True, verbose=1, \n",
    "                        validation_split=0.3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_emb.save('model_cln_w2v_dnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a4dc6",
   "metadata": {},
   "source": [
    "#### _Plot loss and accuracy_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_keys = history.history.keys()\n",
    "his_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "df_history_loss = pd.DataFrame(history.history)[['loss','val_loss']]\n",
    "df_history_loss.plot(ax=ax1)\n",
    "df_history_accu = pd.DataFrame(history.history)[['accuracy','val_accuracy']]\n",
    "df_history_accu.plot(ax=ax2)\n",
    "ax1.grid(True); ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss')\n",
    "ax2.grid(True); ax2.set_xlabel('Epoch'); ax2.set_ylabel('Cross entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Get prediction f1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob = model_emb.predict(X_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = [dic_y_mapping[np.argmax(pred)] for pred in y_train_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_train_label, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ec201",
   "metadata": {},
   "source": [
    "#### _Evaluate model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of n-grams for test set\n",
    "X_test = test_cln['txt_clean']\n",
    "y_test = test_cln['label']\n",
    "\n",
    "lst_corpus_test = []\n",
    "for text in X_test:\n",
    "    lst_words = text.split()\n",
    "    lst_corpus_test.append(lst_words)\n",
    "\n",
    "## Detect common bigram and trigram with fitted detectors\n",
    "lst_corpus_test_bi = list(bigrams_detector[lst_corpus_test])\n",
    "lst_corpus_test_tr = list(trigrams_detector[lst_corpus_test_bi])\n",
    "\n",
    "len(lst_corpus_test_bi), len(lst_corpus_test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text to sequence with the fitted tokenizer\n",
    "lst_text2seq_test = tokenizer.texts_to_sequences(lst_corpus_test_tr)\n",
    "\n",
    "## padding sequence\n",
    "X_test_w2v = keras.preprocessing.sequence.pad_sequences(lst_text2seq_test, \n",
    "                                maxlen=500, padding=\"post\", truncating=\"post\")\n",
    "X_test_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a31ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_w2v = model_emb.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_w2v[1:4,] # Why are there 3 columns??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q: Why use dic_y_mapping instead of inverse_dic???\n",
    "y_pred_w2v      = [dic_y_mapping[np.argmax(pred)] for pred in y_pred_prob_w2v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = metrics.f1_score(y_test, y_pred_w2v)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __NOT USED__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166e656",
   "metadata": {},
   "source": [
    "#### _Check min, max, avg len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT Run ###\n",
    "'''\n",
    "minlen = 100; maxlen = 0; totlen = 0\n",
    "lst_0  = []   # index of sequences with zero lengths\n",
    "\n",
    "for idx in tqdm(range(len(lst_text2seq))):\n",
    "    slen   = len(lst_text2seq[idx])\n",
    "    totlen +=slen\n",
    "    if slen > maxlen: maxlen = slen\n",
    "    if slen < minlen: \n",
    "        if slen == 0: lst_0.append(idx)\n",
    "        else: minlen = slen\n",
    "print(f'Min:{minlen}, Max:{maxlen}, Avg:{totlen/len(lst_text2seq)}')\n",
    "print('Zero length:', lst_0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e975340",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation\n",
    "def eval_model(y_test, y_pred, y_pred_prob, plot_auc=1):\n",
    "    \n",
    "    classes = np.unique(y_test)\n",
    "\n",
    "    # pd.get_dummies: Convert categorical variable into dummy/indicator \n",
    "    # variables.\n",
    "    y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "    ## Accuracy, Precision, Recall\n",
    "    #accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "    #print(\"Accuracy:\",  round(accuracy,2))\n",
    "    print(\"Auc:\", round(auc,2))\n",
    "    print(\"Detail:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "        \n",
    "    ## Plot confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    _, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "                cbar=False)\n",
    "    ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "        yticklabels=classes, title=\"Confusion matrix\")\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "    # Setup subplots\n",
    "    if plot_auc:\n",
    "        _, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "        ## Plot roc\n",
    "        for i in range(len(classes)):\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                                y_pred_prob[:,i])\n",
    "                ax[0].plot(fpr, tpr, lw=3, \n",
    "                        label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                        metrics.auc(fpr, tpr))\n",
    "                        )\n",
    "        ax[0].plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "        ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "                xlabel='False Positive Rate', \n",
    "                ylabel=\"True Positive Rate (Recall)\", \n",
    "                title=\"Receiver operating characteristic\")\n",
    "        ax[0].legend(loc=\"lower right\")\n",
    "        ax[0].grid(True)\n",
    "                \n",
    "        ## Plot precision-recall curve\n",
    "        for i in range(len(classes)):\n",
    "                precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                        y_test_array[:,i], y_pred_prob[:,i])\n",
    "                ax[1].plot(recall, precision, lw=3, \n",
    "                        label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                        metrics.auc(recall, precision))\n",
    "                        )\n",
    "        ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "                ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "        ax[1].plot([0,1], [1/3,1/3], color='navy', lw=2, linestyle='--')\n",
    "        ax[1].legend(loc=\"best\")\n",
    "        ax[1].grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(y_test, y_pred_w2v, y_pred_prob_w2v, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd3af54f5fe992bccbd23931b262c263c643af7052ca64c3b616d552ec510a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
