{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 5: Make predictions__\n",
    "\n",
    "The best model is Word2Vec:\n",
    "- Because the performance is all very similar, for interpretability purpose, choose to focus on the Word2Vec-based model with ` [min_count, window, n_gram] = [20, 8, 3]`. \n",
    "- This way there is a smaller set of eature (because min_count is high) that include tri-grams (so 3 word combinations that help with interpretation).\n",
    "\n",
    "Goal\n",
    "- Make predictions of the entire corupus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Set up___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import script_2_3_text_classify_w2v as script23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting paths\n",
    "work_dir   = Path.home() / \"projects/plant_sci_hist/2_text_classify\"\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Training data for interpretation purpose\n",
    "corpus_train = work_dir / \"corpus_train.json\"\n",
    "\n",
    "# The columns to focus on\n",
    "target_col = 'txt'\n",
    "\n",
    "# Trainded Word2Vec model, tokenizer, and vocab for getting embeddings\n",
    "w2v_name   = work_dir / f\"model_cln_w2v_20-8-3\"\n",
    "tok_name   = work_dir / f\"model_cln_w2v_token_20-8-3\"\n",
    "vocab_name = work_dir / f\"model_cln_w2v_vocab_20-8-3\"\n",
    "\n",
    "# Getting ngrams\n",
    "ngram = 3\n",
    "min_count = 20\n",
    "\n",
    "# DNN checkpoint path\n",
    "cp_filepath = work_dir / f\"model_cln_w2v_20-8-3_dnn\"\n",
    "\n",
    "# Corpus to make predictions for\n",
    "corpus_dir  = Path.home() / \"projects/plant_sci_hist/1_obtaining_corpus\"\n",
    "corpus_file = corpus_dir / \"pubmed_qualified.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Analysis of prediction outcome___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load w2v model, tokenizer, and vocab\n",
    "\n",
    "Need:\n",
    "- W2V model\n",
    "- Tokenizer and vocab\n",
    "- Trained DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f7acfa60be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load word2vec model\n",
    "with open(w2v_name, \"rb\") as f:\n",
    "  model_w2v = pickle.load(f)\n",
    "model_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenzier and vocab\n",
    "with open(tok_name, \"rb\") as f:\n",
    "  tokenizer = pickle.load(f)\n",
    "\n",
    "with open(vocab_name, \"rb\") as f:\n",
    "  vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed...\n",
    "with corpus_train.open(\"r+\") as f:\n",
    "  corpus_combo_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Make predictions on the whole dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read corpus that needs to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df_raw = pd.read_csv(corpus_file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497511, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385417, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicated rows\n",
    "corpus_df = corpus_df_raw[corpus_df_raw.duplicated() == False]\n",
    "\n",
    "# Rid of all records with NAs\n",
    "corpus_df = corpus_df.dropna(axis=0)\n",
    "\n",
    "# Create a new column 'txt' which is concatenated between 'Title' and 'Abstract'\n",
    "corpus_df['txt'] = corpus_df['Title'] + \" \" + corpus_df['Abstract']\n",
    "corpus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>QualifiedName</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>1975-11-01</td>\n",
       "      <td>The British journal of nutrition</td>\n",
       "      <td>The effects of processing of barley-based supp...</td>\n",
       "      <td>1. In one experiment the effect on rumen pH of...</td>\n",
       "      <td>barley</td>\n",
       "      <td>The effects of processing of barley-based supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1975-12-02</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Evidence of the involvement of a 50S ribosomal...</td>\n",
       "      <td>The functional role of the Bacillus stearother...</td>\n",
       "      <td>rose</td>\n",
       "      <td>Evidence of the involvement of a 50S ribosomal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1975-12-11</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>The reaction between the superoxide anion radi...</td>\n",
       "      <td>1. The superoxide anion radical (O2-) reacts w...</td>\n",
       "      <td>tuna</td>\n",
       "      <td>The reaction between the superoxide anion radi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PMID        Date                           Journal  \\\n",
       "0   36  1975-11-01  The British journal of nutrition   \n",
       "1   52  1975-12-02                      Biochemistry   \n",
       "2   60  1975-12-11     Biochimica et biophysica acta   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The effects of processing of barley-based supp...   \n",
       "1  Evidence of the involvement of a 50S ribosomal...   \n",
       "2  The reaction between the superoxide anion radi...   \n",
       "\n",
       "                                            Abstract QualifiedName  \\\n",
       "0  1. In one experiment the effect on rumen pH of...        barley   \n",
       "1  The functional role of the Bacillus stearother...          rose   \n",
       "2  1. The superoxide anion radical (O2-) reacts w...          tuna   \n",
       "\n",
       "                                                 txt  \n",
       "0  The effects of processing of barley-based supp...  \n",
       "1  Evidence of the involvement of a 50S ribosomal...  \n",
       "2  The reaction between the superoxide anion radi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The effects of processing of barley-based supplements on rumen pH, rate of digestion of voluntary in'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df['txt'][0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word embeddings, w2v feature matrix using corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    load ngrams\n"
     ]
    }
   ],
   "source": [
    "# Get ngrams: \n",
    "# ##### This is not necessary #####\n",
    "X        = corpus_df[target_col]\n",
    "X_ngrams = script23.get_ngram(X, ngram, min_count, \"train\", work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "embeddings, X_w2v = script23.get_embeddings(X, model_w2v, tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398412, 300), (1385417, 500))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, X_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     1,     1,   856,     1,   631,    65,     1,     1,\n",
       "       22713,   493,    43,     1,  3786,     1,  8018,  1214,     1,\n",
       "        4962,  1222], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = tf.keras.models.load_model(cp_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a long time so save the prediction and prediction prob to a file\n",
    "# ~52 min\n",
    "y_pred_prob   = model_emb.predict(X_w2v)\n",
    "dic_y_mapping = {n:label for n,label in enumerate(np.unique([0,1]))}\n",
    "y_pred        = [dic_y_mapping[np.argmax(pred)] for pred in y_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1385417"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385417, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df[\"y_prob\"] = y_pred_prob[:,1]\n",
    "corpus_df[\"y_pred\"] = y_pred\n",
    "corpus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    963677\n",
       "1    421740\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df['y_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save prediction file\n",
    "corpus_df_file = work_dir / \"pubmed_qual_1385417_w2v_pred_prob.tsv.gz\"\n",
    "corpus_df.to_csv(corpus_df_file, sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consolidate positive predictions into a compressed dataframe\n",
    "corpus_df_pos_file = work_dir / \"corpus_plant_421740.gz\"\n",
    "corpus_df[corpus_df['y_pred'] == 1].to_csv(corpus_df_pos_file, sep='\\t', \n",
    "                                                            compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.histplot(data=corpus_df, x=\"y_prob\", hue=\"y_pred\", data='pdf')\n",
    "plt.savefig(work_dir / 'figure_pubmed_qual_1385417_w2v_pred_prob.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tSNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd3af54f5fe992bccbd23931b262c263c643af7052ca64c3b616d552ec510a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
