{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PHBpLPuQdmK"
   },
   "source": [
    "# __Test another way to finetune BERT__\n",
    "\n",
    "Based on [Classify text with BERT](https://www.tensorflow.org/text/tutorials/classify_text_with_bert) from TensorflowHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:29:38.728372Z",
     "iopub.status.busy": "2022-03-29T12:29:38.727971Z",
     "iopub.status.idle": "2022-03-29T12:29:40.581474Z",
     "shell.execute_reply": "2022-03-29T12:29:40.580473Z"
    },
    "id": "q-YbjCkzw0yU"
   },
   "source": [
    "## __Setup__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Install_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
    "!pip install -q tf-models-official==2.7.0\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Import_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:29:49.396206Z",
     "iopub.status.busy": "2022-03-29T12:29:49.395613Z",
     "iopub.status.idle": "2022-03-29T12:29:52.068483Z",
     "shell.execute_reply": "2022-03-29T12:29:52.067720Z"
    },
    "id": "_XgTpm9ZxoN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Configuration info_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting paths\n",
    "work_dir          = Path.home() / \"projects/plant_sci_hist/\"\n",
    "corpus_combo_file = work_dir / \"2_text_classify/corpus_combo\"\n",
    "\n",
    "# Dataset\n",
    "batch_size     = 32\n",
    "shuffle_buffer = 2\n",
    "\n",
    "# https://stackoverflow.com/questions/56613155/tensorflow-tf-data-autotune\n",
    "# tf.data builds a performance model of the input pipeline and runs an \n",
    "# optimization algorithm to find a good allocation of its CPU budget across all\n",
    "# parameters specified as AUTOTUNE\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# maximum number of tokens in a document\n",
    "max_length = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Get text ready__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Read json to dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validate_test(corpus_combo_file, rand_state):\n",
    "  '''Load data and split train, validation, test subsets for the cleaned texts\n",
    "  Args:\n",
    "    corpus_combo_file (str): path to the json data file\n",
    "    rand_state (int): for reproducibility\n",
    "  Return:\n",
    "    train, test, test (pandas dataframes): training, validation, testing sets\n",
    "  '''\n",
    "  # Load json file\n",
    "  with corpus_combo_file.open(\"r+\") as f:\n",
    "      corpus_combo_json = json.load(f)\n",
    "\n",
    "  # Convert json back to dataframe\n",
    "  corpus_combo = pd.read_json(corpus_combo_json)\n",
    "\n",
    "  # Cleaned corpus\n",
    "  corpus = corpus_combo[['label','txt']]\n",
    "\n",
    "  # Split train test\n",
    "  train, test = model_selection.train_test_split(corpus, \n",
    "      test_size=0.2, stratify=corpus['label'], random_state=rand_state)\n",
    "\n",
    "  # Split train validate\n",
    "  train, valid = model_selection.train_test_split(train, \n",
    "      test_size=0.25, stratify=train['label'], random_state=rand_state)\n",
    "\n",
    "  return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = split_train_validate_test(corpus_combo_file, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Convert training dataframe to dataset_\n",
    "\n",
    "- See the [pd_dataframe_to_tf_dataset](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/pd_dataframe_to_tf_dataset) function, but this needs tf 2.9, conflict with tensorflow_text.\n",
    "- See [this](https://www.tensorflow.org/tutorials/load_data/pandas_dataframe): See the shuffle and batch functions. Does not work...\n",
    "- See [this post](https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168):  Was able to create SicedDataset, then BatchDatabase after applying the batch function, then PrefetchDataset. But trying to retreive a test example from trainin dataset lead to:\n",
    "  - InvalidArgumentError: Index out of range using input dim 0; input has only 0 dims [Op:StridedSlice] name: strided_slice/\n",
    "  - Ok, as I was implmenting the next solution, realize that I did not call the right obj for prefetch. Can be the reason why.\n",
    "- Ah, see [this post](https://stackoverflow.com/questions/58461609/how-to-convert-pandas-dataframe-to-tensorflow-dataset): key is to turn train_data to dictionary before calling from_tensor_slices.\n",
    "  - A little comment below say need to do .to_dict() instead which make sense. Because if just do dict(train), the thing finish in 0.1 sec which does not make sense. But this fails and throw:\n",
    "    - ValueError: Unbatching a tensor is only supported for rank >= 1\n",
    "  - Found [this post](https://stackoverflow.com/questions/55560620/valueerror-unbatching-a-tensor-is-only-supported-for-rank-1): Now try to uses another syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:25:12.873849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:12.926073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:12.926404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:12.928202: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-18 17:25:12.929786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:12.930141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:12.930567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:13.532388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:13.532695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:13.532710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-06-18 17:25:13.532938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-18 17:25:13.533229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5430 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates a TensorSliceDataset\n",
    "\n",
    "# The following does not work\n",
    "#raw_train_ds = (tf.data.Dataset.from_tensor_slices(\n",
    "#        (tf.cast(train['txt'].values, tf.string),\n",
    "#         tf.cast(train['label'].values, tf.int32),)))\n",
    "#raw_train_ds = tf.data.Dataset.from_tensor_slices(train)\n",
    "#raw_train_ds = tf.data.Dataset.from_tensor_slices(dict(train))\n",
    "#raw_train_ds = tf.data.Dataset.from_tensor_slices(train.to_dict())\n",
    "\n",
    "X_train      = train['txt']\n",
    "y_train      = train['label']\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "type(raw_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_ds_batch = raw_train_ds.batch(batch_size)\n",
    "type(raw_train_ds_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This throws:\n",
    "#  AttributeError: 'TensorSliceDataset' object has no attribute 'class_names'\n",
    "#class_names = raw_train_ds.class_names\n",
    "class_names = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From BatchDataset, get PrefetchDataset\n",
    "train_ds = raw_train_ds_batch.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Covert validation and test sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation dataset\n",
    "X_valid      = valid['txt']\n",
    "y_valid      = valid['label']\n",
    "raw_valid_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "raw_valid_ds_batch = raw_valid_ds.batch(batch_size)\n",
    "valid_ds = raw_valid_ds_batch.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Get testing dataset\n",
    "X_test      = test['txt']\n",
    "y_test      = test['label']\n",
    "raw_test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "raw_test_ds_batch = raw_test_ds.batch(batch_size)\n",
    "test_ds = raw_test_ds_batch.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Testing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Analysis of leaf microbiome composition of near-isogenic maize lines differing in broad-spectrum disease resistance.. Plant genotype strongly affects disease resistance, and also influences the composition of the leaf microbiome. However, these processes have not been studied and linked in the microevolutionary context of breeding for improved disease resistance. We hypothesised that broad-spectrum disease resistance alleles also affect colonisation by nonpathogenic symbionts. Quantitative trait loci (QTL) conferring resistance to multiple fungal pathogens were introgressed into a disease-susceptible maize inbred line. Bacterial and fungal leaf microbiomes of the resulting near-isogenic lines were compared with the microbiome of the disease-susceptible parent line at two time points in multiple fields. Introgression of QTL from disease-resistant lines strongly shifted the relative abundance of diverse fungal and bacterial taxa in both 3-wk-old and 7-wk-old plants. Nevertheless, the effects on overall community structure and diversity were minor and varied among fields and years. Contrary to our expectations, host genotype effects were not any stronger in fields with high disease pressure than in uninfected fields, and microbiome succession over time was similar in heavily infected and uninfected plants. These results show that introgressed QTL can greatly improve broad-spectrum disease resistance while having only limited and inconsistent pleiotropic effects on the leaf microbiome in maize.\\xc2\\xa9 2019 The Authors. New Phytologist \\xc2\\xa9 2019 New Phytologist Trust.', shape=(), dtype=string)\n",
      "32\n",
      "tf.Tensor([1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1], shape=(32,), dtype=int64)\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:26:19.455255: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  print(text_batch[0])\n",
    "  print(len(text_batch))\n",
    "  print(label_batch)\n",
    "  print(len(label_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:15.751221Z",
     "iopub.status.busy": "2022-03-29T12:30:15.750998Z",
     "iopub.status.idle": "2022-03-29T12:30:15.778963Z",
     "shell.execute_reply": "2022-03-29T12:30:15.778411Z"
    },
    "id": "JuxDkcvVIoev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'Analysis of leaf microbiome composition of near-isogenic maize lines differing in broad-spectrum disease resistance.. Plant genotype strongly affects disease resistance, and also influences the composition of the leaf microbiome. However, these processes have not been studied and linked in the microevolutionary context of breeding for improved disease resistance. We hypothesised that broad-spectrum disease resistance alleles also affect colonisation by nonpathogenic symbionts. Quantitative trait loci (QTL) conferring resistance to multiple fungal pathogens were introgressed into a disease-susceptible maize inbred line. Bacterial and fungal leaf microbiomes of the resulting near-isogenic lines were compared with the microbiome of the disease-susceptible parent line at two time points in multiple fields. Introgression of QTL from disease-resistant lines strongly shifted the relative abundance of diverse fungal and bacterial taxa in both 3-wk-old and 7-wk-old plants. Nevertheless, the effects on overall community structure and diversity were minor and varied among fields and years. Contrary to our expectations, host genotype effects were not any stronger in fields with high disease pressure than in uninfected fields, and microbiome succession over time was similar in heavily infected and uninfected plants. These results show that introgressed QTL can greatly improve broad-spectrum disease resistance while having only limited and inconsistent pleiotropic effects on the leaf microbiome in maize.\\xc2\\xa9 2019 The Authors. New Phytologist \\xc2\\xa9 2019 New Phytologist Trust.'\n",
      "Label : 1 (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:26:29.062032: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(1):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Define Hub models and initial testing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX8FtlpGJRE6"
   },
   "source": [
    "### _Hub models to use_\n",
    "\n",
    "Use BERT trained on MEDLINE/Pubmed:\n",
    "- https://tfhub.dev/google/experts/bert/pubmed/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_encoder = 'https://tfhub.dev/google/experts/bert/pubmed/2'\n",
    "tfhub_preproc = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WrcxxTRDdHi"
   },
   "source": [
    "### _Load and test preprocessing model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:15.795438Z",
     "iopub.status.busy": "2022-03-29T12:30:15.795041Z",
     "iopub.status.idle": "2022-03-29T12:30:18.992854Z",
     "shell.execute_reply": "2022-03-29T12:30:18.992262Z"
    },
    "id": "0SQi-jWd_jzq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_preproc)\n",
    "type(bert_preprocess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note this is not a layer but a saved model\n",
    "bert_preprocess = hub.load(tfhub_preproc)\n",
    "type(bert_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:18.996679Z",
     "iopub.status.busy": "2022-03-29T12:30:18.996239Z",
     "iopub.status.idle": "2022-03-29T12:30:19.160173Z",
     "shell.execute_reply": "2022-03-29T12:30:19.159548Z"
    },
    "id": "r9-zCzJpnuwS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
      "Shape      : (1, 512)\n",
      "Word Ids   : [  101  2023  3259  2003  2055  3269  1010  2066 21154  1010  5785  1010\n",
      "  1998 20856   999   102  2023  3259  2003  2055  3269  1010  2066 21154\n",
      "  1010  5785  1010  1998 20856   999]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['This paper is about Plant, like maize, rice, and tomato!']\n",
    "\n",
    "#######################\n",
    "# CRITICAL STEP!!! NEED TO CHANGE DIMENSION From 128 to 512\n",
    "#######################\n",
    "\n",
    "tok = bert_preprocess.tokenize(tf.constant(text_test))\n",
    "text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok], \n",
    "                                                     tf.constant(max_length))\n",
    "#text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "\n",
    "# The size is 128.\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :30]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :30]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :30]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKnLPSEmtp9i"
   },
   "source": [
    "### _Load and test BERT model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:19.163550Z",
     "iopub.status.busy": "2022-03-29T12:30:19.163058Z",
     "iopub.status.idle": "2022-03-29T12:30:26.095648Z",
     "shell.execute_reply": "2022-03-29T12:30:26.094996Z"
    },
    "id": "tXxYpK8ixL34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_encoder)\n",
    "type(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:26.099587Z",
     "iopub.status.busy": "2022-03-29T12:30:26.098983Z",
     "iopub.status.idle": "2022-03-29T12:30:26.708358Z",
     "shell.execute_reply": "2022-03-29T12:30:26.707624Z"
    },
    "id": "_OoF9mebuSZc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/google/experts/bert/pubmed/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:56:46.339952: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "print(f'Loaded BERT: {tfhub_encoder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[ 0.20681225 -0.6118757   0.01431939 -0.94472456 -0.35345343  0.38756847\n",
      " -0.90354735]\n"
     ]
    }
   ],
   "source": [
    "# pooled_output: embedding of the document\n",
    "# 768: size of the embedding vector\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Outputs Shape:(1, 512, 768)\n",
      "Sequence Outputs Values:[[ 0.20988233 -0.7119897   0.0143176  ...  0.06562965  0.8226177\n",
      "   0.42425305]\n",
      " [-0.8292844  -1.1429014   0.23615694 ... -0.15752412 -0.5507309\n",
      "  -2.2226732 ]]\n"
     ]
    }
   ],
   "source": [
    "# sequence_output: embeddings of each token\n",
    "# 512: number of tokens of text_preprocessed\n",
    "# 768: size of the embedding vector\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Outputs length:12\n",
      "Sequence Outputs shape:(1, 512, 768)\n",
      "Sequence Outputs shape:[[ 0.04168119 -0.05507107  0.05931066 ... -0.07429774  0.0130739\n",
      "   0.04005793]\n",
      " [-0.7037214  -0.5592795   0.16818535 ... -0.1520418   0.34704968\n",
      "  -0.40375572]]\n"
     ]
    }
   ],
   "source": [
    "# encoder_outputs: intermediate activation of a transformer block\n",
    "# Q: Assuming activation is the output value of the activation function.\n",
    "# 12: number of transformer blocks\n",
    "print(f'Encoder Outputs length:{len(bert_results[\"encoder_outputs\"])}')\n",
    "\n",
    "# Saem as sequence output values\n",
    "print(f'Sequence Outputs shape:{bert_results[\"encoder_outputs\"][0].shape}')\n",
    "print(f'Sequence Outputs shape:{bert_results[\"encoder_outputs\"][0][0, :2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDNKfAXbDnJH"
   },
   "source": [
    "## __Build classification model__\n",
    "\n",
    "The challenge is how to use bert_pack_inputs as a prprocessing layer.\n",
    "- [This hub page](https://www.tensorflow.org/hub/common_saved_model_apis/text) has some info.\n",
    "- Remove the input layer and make it something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:26.711934Z",
     "iopub.status.busy": "2022-03-29T12:30:26.711712Z",
     "iopub.status.idle": "2022-03-29T12:30:26.716508Z",
     "shell.execute_reply": "2022-03-29T12:30:26.715939Z"
    },
    "id": "aksj743St9ga"
   },
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  # Input layer\n",
    "  #text_input        = tf.keras.layers.Input(shape=(), dtype=tf.string, \n",
    "  #                                          name='txt')\n",
    "  input_segments = [\n",
    "      tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
    "      for ft in sentence_features]\n",
    "\n",
    "  # Will this work??  \n",
    "  tokenizer_layer   = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
    "  tokenizer_outputs = tokenizer_layer(text_input)\n",
    "\n",
    "  # Processing layer: This has the key change to allow longer texts.\n",
    "  preproc_layer     = hub.KerasLayer(bert_preprocess.bert_pack_inputs, \n",
    "                                     arguments=dict(seq_lenght=max_length),\n",
    "                                     name='preprocessing')\n",
    "  preproc_outputs   = preproc_layer(tokenizer_outputs)\n",
    "\n",
    "  # Initialize encoder\n",
    "  encoder           = hub.KerasLayer(tfhub_encoder, trainable=True, \n",
    "                                   name='BERT_encoder')\n",
    "  encoder_outputs   = encoder(preproc_outputs)\n",
    "  # Q: Wonder if this is the dense layer mentioned above.\n",
    "  print(type(encoder_outputs))\n",
    "\n",
    "  # Get just the embeddings for each doc (ignore token level info)\n",
    "  net            = encoder_outputs['pooled_output']\n",
    "\n",
    "  # Dropout layer\n",
    "  net            = tf.keras.layers.Dropout(0.1)(net)\n",
    "\n",
    "  # output layer: single node, Q: Why??\n",
    "  net            = tf.keras.layers.Dense(2, activation='softmax', \n",
    "                                                        name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs4yhFraBuGQ"
   },
   "source": [
    "Let's check that the model runs with the output of the preprocessing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:26.719652Z",
     "iopub.status.busy": "2022-03-29T12:30:26.719155Z",
     "iopub.status.idle": "2022-03-29T12:30:33.483247Z",
     "shell.execute_reply": "2022-03-29T12:30:33.482586Z"
    },
    "id": "mGMF8AZcB2Zy"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"preprocessing\" (type KerasLayer).\n\nin user code:\n\n    File \"/home/shinhan/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py\", line 229, in call  *\n        result = f()\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (2 total):\n        * tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_2:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_1:0\", shape=(None,), dtype=int64))\n        * 128\n      Keyword arguments: {'seq_lenght': 512}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n\n\nCall arguments received:\n  • inputs=tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), dtype=int64))\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000041?line=0'>1</a>\u001b[0m classifier_model \u001b[39m=\u001b[39m build_classifier_model()\n\u001b[1;32m      <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000041?line=2'>3</a>\u001b[0m \u001b[39m# tf.constant: create a Tensor from tensor like objects\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000041?line=3'>4</a>\u001b[0m tensor_test      \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(text_test)\n",
      "\u001b[1;32md:/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb Cell 37'\u001b[0m in \u001b[0;36mbuild_classifier_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=9'>10</a>\u001b[0m \u001b[39m# Processing layer: This has the key change to allow longer texts.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=10'>11</a>\u001b[0m preproc_layer     \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(bert_preprocess\u001b[39m.\u001b[39mbert_pack_inputs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=11'>12</a>\u001b[0m                                    arguments\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(seq_lenght\u001b[39m=\u001b[39mmax_length),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=12'>13</a>\u001b[0m                                    name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpreprocessing\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=13'>14</a>\u001b[0m preproc_outputs   \u001b[39m=\u001b[39m preproc_layer(tokenizer_outputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=15'>16</a>\u001b[0m \u001b[39m# Initialize encoder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=16'>17</a>\u001b[0m encoder           \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(tfhub_encoder, trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000039?line=17'>18</a>\u001b[0m                                  name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBERT_encoder\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"preprocessing\" (type KerasLayer).\n\nin user code:\n\n    File \"/home/shinhan/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py\", line 229, in call  *\n        result = f()\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (2 total):\n        * tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_2:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_1:0\", shape=(None,), dtype=int64))\n        * 128\n      Keyword arguments: {'seq_lenght': 512}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n\n\nCall arguments received:\n  • inputs=tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), dtype=int64))\n  • training=None"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "\n",
    "# tf.constant: create a Tensor from tensor like objects\n",
    "tensor_test      = tf.constant(text_test)\n",
    "bert_raw_result  = classifier_model(tensor_test)\n",
    "\n",
    "print(\"Raw result   :\", bert_raw_result)\n",
    "print(\"Apply sigmoid:\", tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.486539Z",
     "iopub.status.busy": "2022-03-29T12:30:33.486005Z",
     "iopub.status.idle": "2022-03-29T12:30:33.607583Z",
     "shell.execute_reply": "2022-03-29T12:30:33.606965Z"
    },
    "id": "0EmzyHZXKIpm"
   },
   "outputs": [],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbUWoZMwc302"
   },
   "source": [
    "## Model training\n",
    "\n",
    "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpJ3xcwDT56v"
   },
   "source": [
    "### Loss function\n",
    "\n",
    "Since this is a binary classification problem and the model outputs a probability (a single-unit layer), you'll use `losses.BinaryCrossentropy` loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.611866Z",
     "iopub.status.busy": "2022-03-29T12:30:33.611329Z",
     "iopub.status.idle": "2022-03-29T12:30:33.621515Z",
     "shell.execute_reply": "2022-03-29T12:30:33.620990Z"
    },
    "id": "OWPOZE-L3AgE"
   },
   "outputs": [],
   "source": [
    "loss    = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77psrpfzbxtp"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101).\n",
    "\n",
    "For the learning rate (`init_lr`), you will use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds: PrefetchDataset of the training data\n",
    "# tf.data.experimental.cardinality: return the cadinality of dataset\n",
    "# cardinality: number of elements in a set\n",
    "# Here should be the number of batches\n",
    "cardinality = tf.data.experimental.cardinality(train_ds)\n",
    "type(cardinality), cardinality.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.624696Z",
     "iopub.status.busy": "2022-03-29T12:30:33.624232Z",
     "iopub.status.idle": "2022-03-29T12:30:33.628769Z",
     "shell.execute_reply": "2022-03-29T12:30:33.628248Z"
    },
    "id": "P9eP2y9dbw32"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch  = cardinality.numpy()\n",
    "num_train_steps  = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "# Initial learning rate\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqlarlpC_v0g"
   },
   "source": [
    "### Loading the BERT model and training\n",
    "\n",
    "Using the `classifier_model` you created earlier, you can compile the model with the loss, metric and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.631424Z",
     "iopub.status.busy": "2022-03-29T12:30:33.631013Z",
     "iopub.status.idle": "2022-03-29T12:30:33.640619Z",
     "shell.execute_reply": "2022-03-29T12:30:33.640151Z"
    },
    "id": "-7GPDhR98jsD"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpBuV5j2cS_b"
   },
   "source": [
    "Note: training time will vary depending on the complexity of the BERT model you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.643759Z",
     "iopub.status.busy": "2022-03-29T12:30:33.643317Z",
     "iopub.status.idle": "2022-03-29T12:37:37.231432Z",
     "shell.execute_reply": "2022-03-29T12:37:37.230870Z"
    },
    "id": "HtfDFAnN_Neu"
   },
   "outputs": [],
   "source": [
    "print(f'Training model with {tfhub_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBthMlTSV8kn"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Let's see how the model performs. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:37:37.235151Z",
     "iopub.status.busy": "2022-03-29T12:37:37.234581Z",
     "iopub.status.idle": "2022-03-29T12:38:36.128910Z",
     "shell.execute_reply": "2022-03-29T12:38:36.128342Z"
    },
    "id": "slqB-urBV9sP"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uttWpgmSfzq9"
   },
   "source": [
    "### Plot the accuracy and loss over time\n",
    "\n",
    "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:36.132081Z",
     "iopub.status.busy": "2022-03-29T12:38:36.131630Z",
     "iopub.status.idle": "2022-03-29T12:38:36.424503Z",
     "shell.execute_reply": "2022-03-29T12:38:36.424018Z"
    },
    "id": "fiythcODf0xo"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# r is for \"solid red line\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzJZCo-cf-Jf"
   },
   "source": [
    "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rtn7jewb6dg4"
   },
   "source": [
    "## Export for inference\n",
    "\n",
    "Now you just save your fine-tuned model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:36.428146Z",
     "iopub.status.busy": "2022-03-29T12:38:36.427717Z",
     "iopub.status.idle": "2022-03-29T12:38:42.015407Z",
     "shell.execute_reply": "2022-03-29T12:38:42.014764Z"
    },
    "id": "ShcvqJAgVera"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'imdb'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbI25bS1vD7s"
   },
   "source": [
    "Let's reload the model, so you can try it side by side with the model that is still in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:42.019271Z",
     "iopub.status.busy": "2022-03-29T12:38:42.018826Z",
     "iopub.status.idle": "2022-03-29T12:38:48.305286Z",
     "shell.execute_reply": "2022-03-29T12:38:48.304688Z"
    },
    "id": "gUEWVskZjEF0"
   },
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyTappHTvNCz"
   },
   "source": [
    "Here you can test your model on any sentence you want, just add to the examples variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:48.309376Z",
     "iopub.status.busy": "2022-03-29T12:38:48.308953Z",
     "iopub.status.idle": "2022-03-29T12:38:48.694457Z",
     "shell.execute_reply": "2022-03-29T12:38:48.693822Z"
    },
    "id": "VBWzH6exlCPS"
   },
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
    "    'The movie was great!',\n",
    "    'The movie was meh.',\n",
    "    'The movie was okish.',\n",
    "    'The movie was terrible...'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "print('Results from the model in memory:')\n",
    "print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cOmih754Y_M"
   },
   "source": [
    "If you want to use your model on [TF Serving](https://www.tensorflow.org/tfx/guide/serving), remember that it will call your SavedModel through one of its named signatures. In Python, you can test them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:48.697594Z",
     "iopub.status.busy": "2022-03-29T12:38:48.697394Z",
     "iopub.status.idle": "2022-03-29T12:38:48.996870Z",
     "shell.execute_reply": "2022-03-29T12:38:48.996220Z"
    },
    "id": "0FdVD3973S-O"
   },
   "outputs": [],
   "source": [
    "serving_results = reloaded_model \\\n",
    "            .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4gN1KwReLPN"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "As a next step, you can try [Solve GLUE tasks using BERT on a TPU tutorial](https://www.tensorflow.org/text/tutorials/bert_glue), which runs on a TPU and shows you how to work with multiple inputs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classify_text_with_bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1761d8df3801bd2a70c9560dc6d458568584f11b389930146f99ac99ddb0b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
