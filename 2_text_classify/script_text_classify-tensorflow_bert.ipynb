{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PHBpLPuQdmK"
   },
   "source": [
    "# __Test another way to finetune BERT__\n",
    "\n",
    "Based on [Classify text with BERT](https://www.tensorflow.org/text/tutorials/classify_text_with_bert) from TensorflowHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:29:38.728372Z",
     "iopub.status.busy": "2022-03-29T12:29:38.727971Z",
     "iopub.status.idle": "2022-03-29T12:29:40.581474Z",
     "shell.execute_reply": "2022-03-29T12:29:40.580473Z"
    },
    "id": "q-YbjCkzw0yU"
   },
   "source": [
    "## __Setup__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Install_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!pip install -U \"tensorflow-text==2.8.*\"\n",
    "!pip install tf-models-official==2.7.0\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Import_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:29:49.396206Z",
     "iopub.status.busy": "2022-03-29T12:29:49.395613Z",
     "iopub.status.idle": "2022-03-29T12:29:52.068483Z",
     "shell.execute_reply": "2022-03-29T12:29:52.067720Z"
    },
    "id": "_XgTpm9ZxoN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflow_models as tfm\n",
    "from official.nlp import optimization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Configuration info_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting paths\n",
    "work_dir          = Path.home() / \"projects/plant_sci_hist/2_text_classify\"\n",
    "corpus_combo_file = work_dir / \"corpus_combo\"\n",
    "\n",
    "# Dataset\n",
    "batch_size     = 32\n",
    "shuffle_buffer = 2\n",
    "\n",
    "# https://stackoverflow.com/questions/56613155/tensorflow-tf-data-autotune\n",
    "# tf.data builds a performance model of the input pipeline and runs an \n",
    "# optimization algorithm to find a good allocation of its CPU budget across all\n",
    "# parameters specified as AUTOTUNE\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# maximum number of tokens in a document\n",
    "max_length = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Get text ready__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Read json to dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validate_test(corpus_combo_file, rand_state):\n",
    "  '''Load data and split train, validation, test subsets for the cleaned texts\n",
    "  Args:\n",
    "    corpus_combo_file (str): path to the json data file\n",
    "    rand_state (int): for reproducibility\n",
    "  Return:\n",
    "    train, test, test (pandas dataframes): training, validation, testing sets\n",
    "  '''\n",
    "  # Load json file\n",
    "  with corpus_combo_file.open(\"r+\") as f:\n",
    "      corpus_combo_json = json.load(f)\n",
    "\n",
    "  # Convert json back to dataframe\n",
    "  corpus_combo = pd.read_json(corpus_combo_json)\n",
    "\n",
    "  # Cleaned corpus\n",
    "  corpus = corpus_combo[['label','txt']]\n",
    "\n",
    "  # Split train test\n",
    "  train, test = model_selection.train_test_split(corpus, \n",
    "      test_size=0.2, stratify=corpus['label'], random_state=rand_state)\n",
    "\n",
    "  # Split train validate\n",
    "  train, valid = model_selection.train_test_split(train, \n",
    "      test_size=0.25, stratify=train['label'], random_state=rand_state)\n",
    "\n",
    "  return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = split_train_validate_test(corpus_combo_file, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Save text entires into files_\n",
    "\n",
    "Follow the same structure as the IMDB dataset in the `aclImdb` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dir = work_dir / \"corpus_dir\"\n",
    "\n",
    "# Create train, valid, test dir\n",
    "train_dir  = corpus_dir / 'train'\n",
    "valid_dir  = corpus_dir / 'valid'\n",
    "test_dir   = corpus_dir / 'test'\n",
    "\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "valid_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pos, neg directory for each\n",
    "(train_dir / \"pos\").mkdir(parents=True, exist_ok=True)\n",
    "(train_dir / \"neg\").mkdir(parents=True, exist_ok=True)\n",
    "(valid_dir / \"pos\").mkdir(parents=True, exist_ok=True)\n",
    "(valid_dir / \"neg\").mkdir(parents=True, exist_ok=True)\n",
    "(test_dir  / \"pos\").mkdir(parents=True, exist_ok=True)\n",
    "(test_dir  / \"neg\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entry_to_file(df, target_dir):\n",
    "  '''Save each text entry in the dataframe as a file\n",
    "  '''\n",
    "\n",
    "  labels = df['label'].values\n",
    "  txts   = df['txt'].values\n",
    "  c_dict = {0:0, 1:0}\n",
    "  for count, label in tqdm(enumerate(labels), total=len(labels)):\n",
    "    if label == 0:\n",
    "      c_dict[0] += 1\n",
    "      with open(target_dir / f\"neg/{count}.txt\", \"w\") as f:\n",
    "        f.write(txts[count])\n",
    "    else:\n",
    "      c_dict[1] += 1\n",
    "      with open(target_dir / f\"pos/{count}.txt\", \"w\") as f:\n",
    "        f.write(txts[count])\n",
    "\n",
    "  print(c_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51987/51987 [02:45<00:00, 313.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 25994, 1: 25993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17329/17329 [01:10<00:00, 246.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 8664, 1: 8665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 225.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_entry_to_file(train, train_dir)\n",
    "save_entry_to_file(valid, valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17330/17330 [01:12<00:00, 240.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 8665, 1: 8665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_entry_to_file(test , test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Create datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51987 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train dataset\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(str(train_dir), \n",
    "                                                          batch_size=batch_size)\n",
    "type(raw_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['neg', 'pos'], tensorflow.python.data.ops.dataset_ops.PrefetchDataset)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = raw_train_ds.class_names\n",
    "train_ds    = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "class_names, type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17329 files belonging to 2 classes.\n",
      "Found 17332 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get valition set\n",
    "raw_valid_ds = tf.keras.utils.text_dataset_from_directory(str(valid_dir), \n",
    "                                                          batch_size=batch_size)\n",
    "valid_ds     = raw_valid_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Get test set\n",
    "raw_test_ds  = tf.keras.utils.text_dataset_from_directory(str(test_dir), \n",
    "                                                          batch_size=batch_size)\n",
    "test_ds      = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:15.751221Z",
     "iopub.status.busy": "2022-03-29T12:30:15.750998Z",
     "iopub.status.idle": "2022-03-29T12:30:15.778963Z",
     "shell.execute_reply": "2022-03-29T12:30:15.778411Z"
    },
    "id": "JuxDkcvVIoev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: b\"Human kin detection.. Natural selection has favored the evolution of behaviors that benefit not only one's genes, but also their copies in genetically related individuals. These behaviors include optimal outbreeding (choosing a mate that is neither too closely related, nor too distant), nepotism (helping kin), and spite (hurting non-kin at a personal cost), and all require some form of kin detection or kin recognition. Yet, kinship cannot be assessed directly; human kin detection relies on heuristic cues that take into account individuals' context (whether they were reared by our mother, or grew up in our home, or were given birth by our spouse), appearance (whether they smell or look like us), and ability to arouse certain feelings (whether we feel emotionally close to them). The uncertainties of kin detection, along with its dependence on social information, create ample opportunities for the evolution of deception and self-deception. For example, babies carry no unequivocal stamp of their biological father, but across cultures they are passionately claimed to resemble their mother's spouse; to the same effect, 'neutral' observers are greatly influenced by belief in relatedness when judging resemblance between strangers. Still, paternity uncertainty profoundly shapes human relationships, reducing not only the investment contributed by paternal versus maternal kin, but also prosocial behavior between individuals who are related through one or more males rather than females alone. Because of its relevance to racial discrimination and political preferences, the evolutionary pressure to prefer kin to non-kin has a manifold influence on society at large.\\xc2\\xa9 2015 John Wiley &amp; Sons, Ltd.\"\n",
      "Label : 0 (neg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 16:08:07.755973: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Check out one record\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(1):\n",
    "    print(f'Text: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Define Hub models and initial testing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX8FtlpGJRE6"
   },
   "source": [
    "### _Hub models to use_\n",
    "\n",
    "Use BERT trained on MEDLINE/Pubmed:\n",
    "- https://tfhub.dev/google/experts/bert/pubmed/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_encoder = 'https://tfhub.dev/google/experts/bert/pubmed/2'\n",
    "tfhub_preproc = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WrcxxTRDdHi"
   },
   "source": [
    "### _Load and test preprocessing model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:15.795438Z",
     "iopub.status.busy": "2022-03-29T12:30:15.795041Z",
     "iopub.status.idle": "2022-03-29T12:30:18.992854Z",
     "shell.execute_reply": "2022-03-29T12:30:18.992262Z"
    },
    "id": "0SQi-jWd_jzq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_preproc)\n",
    "type(bert_preprocess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note this is not a layer but a saved model\n",
    "bert_preprocess = hub.load(tfhub_preproc)\n",
    "type(bert_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:18.996679Z",
     "iopub.status.busy": "2022-03-29T12:30:18.996239Z",
     "iopub.status.idle": "2022-03-29T12:30:19.160173Z",
     "shell.execute_reply": "2022-03-29T12:30:19.159548Z"
    },
    "id": "r9-zCzJpnuwS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_type_ids', 'input_word_ids', 'input_mask']\n",
      "Shape      : (1, 512)\n",
      "Word Ids   : [  101  2023  3259  2003  2055  3269  1010  2066 21154  1010  5785  1010\n",
      "  1998 20856   999   102  2023  3259  2003  2055  3269  1010  2066 21154\n",
      "  1010  5785  1010  1998 20856   999]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['This paper is about Plant, like maize, rice, and tomato!']\n",
    "\n",
    "#######################\n",
    "# CRITICAL STEP!!! NEED TO CHANGE DIMENSION From 128 to 512\n",
    "#######################\n",
    "\n",
    "tok = bert_preprocess.tokenize(tf.constant(text_test))\n",
    "text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok], \n",
    "                                                     tf.constant(max_length))\n",
    "#text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "\n",
    "# The size is 128.\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :30]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :30]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :30]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKnLPSEmtp9i"
   },
   "source": [
    "### _Load and test BERT model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:19.163550Z",
     "iopub.status.busy": "2022-03-29T12:30:19.163058Z",
     "iopub.status.idle": "2022-03-29T12:30:26.095648Z",
     "shell.execute_reply": "2022-03-29T12:30:26.094996Z"
    },
    "id": "tXxYpK8ixL34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_encoder)\n",
    "type(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:26.099587Z",
     "iopub.status.busy": "2022-03-29T12:30:26.098983Z",
     "iopub.status.idle": "2022-03-29T12:30:26.708358Z",
     "shell.execute_reply": "2022-03-29T12:30:26.707624Z"
    },
    "id": "_OoF9mebuSZc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/google/experts/bert/pubmed/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 16:08:59.931293: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "print(f'Loaded BERT: {tfhub_encoder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[ 0.20681225 -0.6118757   0.01431939 -0.94472456 -0.35345343  0.38756847\n",
      " -0.90354735]\n"
     ]
    }
   ],
   "source": [
    "# pooled_output: embedding of the document\n",
    "# 768: size of the embedding vector\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Outputs Shape:(1, 512, 768)\n",
      "Sequence Outputs Values:[[ 0.20988233 -0.7119897   0.0143176  ...  0.06562965  0.8226177\n",
      "   0.42425305]\n",
      " [-0.8292844  -1.1429014   0.23615694 ... -0.15752412 -0.5507309\n",
      "  -2.2226732 ]]\n"
     ]
    }
   ],
   "source": [
    "# sequence_output: embeddings of each token\n",
    "# 512: number of tokens of text_preprocessed\n",
    "# 768: size of the embedding vector\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Outputs length:12\n",
      "Sequence Outputs shape:(1, 512, 768)\n",
      "Sequence Outputs shape:[[ 0.04168119 -0.05507107  0.05931066 ... -0.07429774  0.0130739\n",
      "   0.04005793]\n",
      " [-0.7037214  -0.5592795   0.16818535 ... -0.1520418   0.34704968\n",
      "  -0.40375572]]\n"
     ]
    }
   ],
   "source": [
    "# encoder_outputs: intermediate activation of a transformer block\n",
    "# Q: Assuming activation is the output value of the activation function.\n",
    "# 12: number of transformer blocks\n",
    "print(f'Encoder Outputs length:{len(bert_results[\"encoder_outputs\"])}')\n",
    "\n",
    "# Saem as sequence output values\n",
    "print(f'Sequence Outputs shape:{bert_results[\"encoder_outputs\"][0].shape}')\n",
    "print(f'Sequence Outputs shape:{bert_results[\"encoder_outputs\"][0][0, :2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDNKfAXbDnJH"
   },
   "source": [
    "## __Build classification model__\n",
    "\n",
    "6/18/19\n",
    "- The challenge is how to use bert_pack_inputs as a prprocessing layer.\n",
    "- [This hub page](https://www.tensorflow.org/hub/common_saved_model_apis/text) has some info: does not help much, as the info is for individual instance and the model is very different from what I want.\n",
    "- [Fine-tuning a BERT model](https://www.tensorflow.org/text/tutorials/fine_tune_bert) tutorial: Here the dataset is tokenized, packed, and them used as input to model. Try it and see.\n",
    "- Also check the [preprocess model page](https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3) for syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Get tokenizer to work_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original example\n",
    "#tok = bert_preprocess.tokenize(tf.constant(text_test))\n",
    "#text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok], \n",
    "#                                                     tf.constant(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer  = hub.KerasLayer(bert_preprocess.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[[7592], [23435, 12314]]]>,\n",
       " <tf.RaggedTensor [[[9119], [23435, 12314]]]>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences1 = tf.constant([\"hello tensorflow\"])\n",
    "sentences2 = tf.constant([\"goodbye tensorflow\"])\n",
    "tokens1    = tokenizer(sentences1)\n",
    "tokens2    = tokenizer(sentences2)\n",
    "tokens1, tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_of_segment_id': <tf.Tensor: shape=(), dtype=int32, numpy=102>,\n",
       " 'padding_id': <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " 'vocab_size': <tf.Tensor: shape=(), dtype=int32, numpy=30522>,\n",
       " 'start_of_sequence_id': <tf.Tensor: shape=(), dtype=int32, numpy=101>,\n",
       " 'mask_id': <tf.Tensor: shape=(), dtype=int32, numpy=103>}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following throw an error:\n",
    "# AttributeError: 'KerasLayer' object has no attribute 'get_special_tokens_dict'\n",
    "# Not sure how important this is...\n",
    "#special = tokenizer.get_special_tokens_dict\n",
    "\n",
    "# Ok, in the \"Custom input packing and MLM support\" section of this page:\n",
    "# https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
    "# There is this line:\n",
    "special = bert_preprocess.tokenize.get_special_tokens_dict()\n",
    "special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Get Packer to work_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "packer = tfm.nlp.layers.BertPackInputs(\n",
    "    seq_length=max_length,\n",
    "    special_tokens_dict = special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_word_ids : (1, 512), [[  101  7592 23435 12314   102  9119 23435 12314   102     0]]\n",
      "input_mask     : (1, 512), [[1 1 1 1 1 1 1 1 1 0]]\n",
      "input_type_ids : (1, 512), [[0 0 0 0 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "packed = packer([tokens1, tokens2])\n",
    "for key, tensor in packed.items():\n",
    "  print(f\"{key:15s}: {tensor.shape}, {tensor[:, :10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Combine tokenizer and packer into a layer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertInputProcessor(tf.keras.layers.Layer):\n",
    "  def __init__(self, tokenizer, packer):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.packer = packer\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Original code is expecting two features, but I only have one.\n",
    "    #tok1 = self.tokenizer(inputs['sentence1'])\n",
    "    #tok2 = self.tokenizer(inputs['sentence2'])\n",
    "    tok = self.tokenizer(inputs['txt'])\n",
    "\n",
    "    packed = self.packer([tok, tok])\n",
    "\n",
    "    if 'label' in inputs:\n",
    "      return packed, inputs['label']\n",
    "    else:\n",
    "      return packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_processor = BertInputProcessor(tokenizer, packer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__call() takes 2 positional arguments but 3 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb Cell 50'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000053vscode-remote?line=0'>1</a>\u001b[0m train_packed, _ \u001b[39m=\u001b[39m train_ds\u001b[39m.\u001b[39;49mmap(bert_inputs_processor)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2048\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2045\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2046\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2047\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2048\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2049\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2051\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2052\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2055\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2056\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5243\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5241\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5242\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5244\u001b[0m     map_func,\n\u001b[1;32m   5245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   5246\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   5247\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   5248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m   5249\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m   5250\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   5251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5254\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   5255\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2567\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2559\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \n\u001b[1;32m   2561\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2565\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   2566\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2567\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m   2568\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2569\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2570\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2533\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2532\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2533\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2534\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   2535\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   2536\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[1;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                          graph_function)\n\u001b[1;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2624\u001b[0m ]\n\u001b[1;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2630\u001b[0m         args,\n\u001b[1;32m   2631\u001b[0m         kwargs,\n\u001b[1;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__call() takes 2 positional arguments but 3 were given\n"
     ]
    }
   ],
   "source": [
    "train_packed, _ = train_ds.map(bert_inputs_processor).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:26.711934Z",
     "iopub.status.busy": "2022-03-29T12:30:26.711712Z",
     "iopub.status.idle": "2022-03-29T12:30:26.716508Z",
     "shell.execute_reply": "2022-03-29T12:30:26.715939Z"
    },
    "id": "aksj743St9ga"
   },
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  # Input layer\n",
    "  text_input        = tf.keras.layers.Input(shape=(), dtype=tf.string, \n",
    "                                            name='txt')\n",
    "\n",
    "  # Will this work??  \n",
    "  tokenizer         = hub.KerasLayer(bert_preprocess.tokenize)\n",
    "  special           = bert_preprocess.tokenize.get_special_tokens_dict()\n",
    "  tokenizer_outputs = tokenizer(text_input)\n",
    "\n",
    "  # Processing layer: This has the key change to allow longer texts.\n",
    "  packer            = tfm.nlp.layers.BertPackInputs(\n",
    "                      seq_length=max_length,\n",
    "                      special_tokens_dict = special)\n",
    "\n",
    "  #preproc_layer     = hub.KerasLayer(bert_preprocess.bert_pack_inputs, \n",
    "  #                                   arguments=dict(seq_lenght=max_length),\n",
    "  #                                   name='preprocessing')\n",
    "                                     \n",
    "  packer_outputs   = packer(tokenizer_outputs)\n",
    "\n",
    "  # Initialize encoder\n",
    "  encoder           = hub.KerasLayer(tfhub_encoder, trainable=True, \n",
    "                                   name='BERT_encoder')\n",
    "  encoder_outputs   = encoder(packer_outputs)\n",
    "  \n",
    "  # Q: Wonder if this is the dense layer mentioned above.\n",
    "  print(type(encoder_outputs))\n",
    "\n",
    "  # Get just the embeddings for each doc (ignore token level info)\n",
    "  net            = encoder_outputs['pooled_output']\n",
    "\n",
    "  # Dropout layer\n",
    "  net            = tf.keras.layers.Dropout(0.1)(net)\n",
    "\n",
    "  # output layer: single node, Q: Why??\n",
    "  net            = tf.keras.layers.Dense(2, activation='softmax', \n",
    "                                                        name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:26.719652Z",
     "iopub.status.busy": "2022-03-29T12:30:26.719155Z",
     "iopub.status.idle": "2022-03-29T12:30:33.483247Z",
     "shell.execute_reply": "2022-03-29T12:30:33.482586Z"
    },
    "id": "mGMF8AZcB2Zy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "Raw result   : tf.Tensor([[0.15798162 0.84201837]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "\n",
    "text_test        = ['Plant science focuses on studies of photosynthetic species.']\n",
    "\n",
    "# tf.constant: create a Tensor from tensor like objects\n",
    "tensor_test      = tf.constant(text_test)\n",
    "bert_raw_result  = classifier_model(tensor_test)\n",
    "\n",
    "print(\"Raw result   :\", bert_raw_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.486539Z",
     "iopub.status.busy": "2022-03-29T12:30:33.486005Z",
     "iopub.status.idle": "2022-03-29T12:30:33.607583Z",
     "shell.execute_reply": "2022-03-29T12:30:33.606965Z"
    },
    "id": "0EmzyHZXKIpm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " txt (InputLayer)               [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_5 (KerasLayer)     (None, None, None)   0           ['txt[0][0]']                    \n",
      "                                                                                                  \n",
      " bert_pack_inputs_3 (BertPackIn  {'input_word_ids':   0          ['keras_layer_5[0][0]']          \n",
      " puts)                          (None, 512),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 512),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 512)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'pooled_output': (  109482241   ['bert_pack_inputs_3[0][0]',     \n",
      "                                None, 768),                       'bert_pack_inputs_3[0][1]',     \n",
      "                                 'sequence_output':               'bert_pack_inputs_3[0][2]']     \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 512, 768),                                               \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768),                                                \n",
      "                                 (None, 512, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 768)          0           ['BERT_encoder[0][13]']          \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 2)            1538        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,779\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbUWoZMwc302"
   },
   "source": [
    "## __Model training__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpJ3xcwDT56v"
   },
   "source": [
    "### _Compile model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.624696Z",
     "iopub.status.busy": "2022-03-29T12:30:33.624232Z",
     "iopub.status.idle": "2022-03-29T12:30:33.628769Z",
     "shell.execute_reply": "2022-03-29T12:30:33.628248Z"
    },
    "id": "P9eP2y9dbw32"
   },
   "outputs": [],
   "source": [
    "epochs           = 20\n",
    "cardinality      = tf.data.experimental.cardinality(train_ds)\n",
    "steps_per_epoch  = cardinality.numpy()\n",
    "num_train_steps  = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "# loss function: \n",
    "loss    = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# evaluation metrics\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "# Initial learning rate\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.631424Z",
     "iopub.status.busy": "2022-03-29T12:30:33.631013Z",
     "iopub.status.idle": "2022-03-29T12:30:33.640619Z",
     "shell.execute_reply": "2022-03-29T12:30:33.640151Z"
    },
    "id": "-7GPDhR98jsD"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqlarlpC_v0g"
   },
   "source": [
    "### _Train model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify callbacks\n",
    "\n",
    "# early stopping\n",
    "callback_es  = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# model checkpoint\n",
    "cp_filepath  = work_dir / \"model_ori_bert_tf_pubmed\"\n",
    "callback_mcp = tf.keras.callbacks.ModelCheckpoint(filepath=str(cp_filepath), \n",
    "              mode='max', save_weights_only=False, monitor='val_accuracy', \n",
    "              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:33.643759Z",
     "iopub.status.busy": "2022-03-29T12:30:33.643317Z",
     "iopub.status.idle": "2022-03-29T12:37:37.231432Z",
     "shell.execute_reply": "2022-03-29T12:37:37.230870Z"
    },
    "id": "HtfDFAnN_Neu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/google/experts/bert/pubmed/2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 16:45:26.186857: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 192.00MiB (rounded to 201326592)requested by op model_2/BERT_encoder/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/bert_encoder/StatefulPartitionedCall/transformer/layer_0/dropout_1/dropout/random_uniform/RandomUniform\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-06-19 16:45:26.186922: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-06-19 16:45:26.186933: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 213, Chunks in use: 212. 53.2KiB allocated for chunks. 53.0KiB in use in bin. 1.5KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186938: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186942: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186947: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 556, Chunks in use: 555. 1.63MiB allocated for chunks. 1.63MiB in use in bin. 1.63MiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186954: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 11, Chunks in use: 11. 65.0KiB allocated for chunks. 65.0KiB in use in bin. 63.0KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186964: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 59, Chunks in use: 59. 711.2KiB allocated for chunks. 711.2KiB in use in bin. 705.8KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186968: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 2, Chunks in use: 2. 42.0KiB allocated for chunks. 42.0KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186973: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186977: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 6, Chunks in use: 5. 384.0KiB allocated for chunks. 320.0KiB in use in bin. 320.0KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186981: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 128.0KiB allocated for chunks. 128.0KiB in use in bin. 128.0KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186986: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 812.5KiB allocated for chunks. 812.5KiB in use in bin. 812.3KiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186990: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-19 16:45:26.186994: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 18, Chunks in use: 17. 26.70MiB allocated for chunks. 25.51MiB in use in bin. 25.50MiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187000: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 296, Chunks in use: 294. 671.07MiB allocated for chunks. 666.59MiB in use in bin. 661.50MiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187007: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187017: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 145, Chunks in use: 144. 1.30GiB allocated for chunks. 1.29GiB in use in bin. 1.27GiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187021: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187025: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 12, Chunks in use: 11. 563.39MiB allocated for chunks. 515.39MiB in use in bin. 512.00MiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187031: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 7, Chunks in use: 7. 614.15MiB allocated for chunks. 614.15MiB in use in bin. 543.10MiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187036: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 5. 1003.67MiB allocated for chunks. 1003.67MiB in use in bin. 960.00MiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187041: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 3. 1.19GiB allocated for chunks. 1.19GiB in use in bin. 1.12GiB client-requested in use in bin.\n",
      "2022-06-19 16:45:26.187047: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 192.00MiB was 128.00MiB, Chunk State: \n",
      "2022-06-19 16:45:26.187052: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 5692260352\n",
      "2022-06-19 16:45:26.187070: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7135d0000 of size 1280 next 1\n",
      "2022-06-19 16:45:26.187074: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7135d0500 of size 256 next 2\n",
      "2022-06-19 16:45:26.187076: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7135d0600 of size 256 next 3\n",
      "2022-06-19 16:45:26.187079: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7135d0700 of size 256 next 4\n",
      "2022-06-19 16:45:26.187081: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7135d0800 of size 416000 next 5\n",
      "2022-06-19 16:45:26.187086: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 713636100 of size 416000 next 6\n",
      "2022-06-19 16:45:26.187088: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369ba00 of size 256 next 7\n",
      "2022-06-19 16:45:26.187091: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369bb00 of size 256 next 21\n",
      "2022-06-19 16:45:26.187093: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369bc00 of size 256 next 8\n",
      "2022-06-19 16:45:26.187095: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369bd00 of size 256 next 9\n",
      "2022-06-19 16:45:26.187097: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369be00 of size 256 next 22\n",
      "2022-06-19 16:45:26.187100: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369bf00 of size 256 next 23\n",
      "2022-06-19 16:45:26.187102: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c000 of size 256 next 24\n",
      "2022-06-19 16:45:26.187104: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c100 of size 256 next 25\n",
      "2022-06-19 16:45:26.187106: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c200 of size 256 next 26\n",
      "2022-06-19 16:45:26.187109: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c300 of size 256 next 27\n",
      "2022-06-19 16:45:26.187111: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c400 of size 256 next 28\n",
      "2022-06-19 16:45:26.187113: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c500 of size 256 next 29\n",
      "2022-06-19 16:45:26.187115: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c600 of size 256 next 30\n",
      "2022-06-19 16:45:26.187117: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c700 of size 256 next 31\n",
      "2022-06-19 16:45:26.187120: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c800 of size 256 next 32\n",
      "2022-06-19 16:45:26.187122: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369c900 of size 256 next 33\n",
      "2022-06-19 16:45:26.187124: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369ca00 of size 256 next 34\n",
      "2022-06-19 16:45:26.187126: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369cb00 of size 256 next 35\n",
      "2022-06-19 16:45:26.187129: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369cc00 of size 256 next 37\n",
      "2022-06-19 16:45:26.187133: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369cd00 of size 3072 next 43\n",
      "2022-06-19 16:45:26.187136: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369d900 of size 3072 next 36\n",
      "2022-06-19 16:45:26.187140: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369e500 of size 3072 next 42\n",
      "2022-06-19 16:45:26.187143: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369f100 of size 3072 next 46\n",
      "2022-06-19 16:45:26.187145: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71369fd00 of size 3072 next 41\n",
      "2022-06-19 16:45:26.187147: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a0900 of size 3072 next 52\n",
      "2022-06-19 16:45:26.187149: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a1500 of size 3072 next 48\n",
      "2022-06-19 16:45:26.187152: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a2100 of size 3072 next 53\n",
      "2022-06-19 16:45:26.187154: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a2d00 of size 12288 next 50\n",
      "2022-06-19 16:45:26.187157: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a5d00 of size 3072 next 55\n",
      "2022-06-19 16:45:26.187159: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a6900 of size 3072 next 56\n",
      "2022-06-19 16:45:26.187161: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a7500 of size 3072 next 57\n",
      "2022-06-19 16:45:26.187164: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a8100 of size 3072 next 59\n",
      "2022-06-19 16:45:26.187166: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a8d00 of size 3072 next 61\n",
      "2022-06-19 16:45:26.187168: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136a9900 of size 3072 next 62\n",
      "2022-06-19 16:45:26.187170: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136aa500 of size 3072 next 64\n",
      "2022-06-19 16:45:26.187172: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136ab100 of size 3072 next 66\n",
      "2022-06-19 16:45:26.187175: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136abd00 of size 3072 next 67\n",
      "2022-06-19 16:45:26.187177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136ac900 of size 3072 next 68\n",
      "2022-06-19 16:45:26.187179: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136ad500 of size 12288 next 70\n",
      "2022-06-19 16:45:26.187181: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b0500 of size 3072 next 72\n",
      "2022-06-19 16:45:26.187184: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b1100 of size 3072 next 73\n",
      "2022-06-19 16:45:26.187186: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b1d00 of size 3072 next 74\n",
      "2022-06-19 16:45:26.187188: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b2900 of size 3072 next 75\n",
      "2022-06-19 16:45:26.187190: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b3500 of size 3072 next 77\n",
      "2022-06-19 16:45:26.187192: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b4100 of size 3072 next 79\n",
      "2022-06-19 16:45:26.187195: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b4d00 of size 3072 next 81\n",
      "2022-06-19 16:45:26.187197: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b5900 of size 3072 next 83\n",
      "2022-06-19 16:45:26.187199: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b6500 of size 3072 next 84\n",
      "2022-06-19 16:45:26.187201: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b7100 of size 3072 next 85\n",
      "2022-06-19 16:45:26.187204: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b7d00 of size 3072 next 86\n",
      "2022-06-19 16:45:26.187206: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136b8900 of size 12288 next 88\n",
      "2022-06-19 16:45:26.187208: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136bb900 of size 3072 next 90\n",
      "2022-06-19 16:45:26.187210: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136bc500 of size 3072 next 91\n",
      "2022-06-19 16:45:26.187213: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136bd100 of size 3072 next 92\n",
      "2022-06-19 16:45:26.187215: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136bdd00 of size 3072 next 95\n",
      "2022-06-19 16:45:26.187217: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136be900 of size 3072 next 97\n",
      "2022-06-19 16:45:26.187219: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136bf500 of size 3072 next 99\n",
      "2022-06-19 16:45:26.187222: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c0100 of size 3072 next 101\n",
      "2022-06-19 16:45:26.187224: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c0d00 of size 3072 next 102\n",
      "2022-06-19 16:45:26.187226: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c1900 of size 3072 next 103\n",
      "2022-06-19 16:45:26.187228: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c2500 of size 12288 next 105\n",
      "2022-06-19 16:45:26.187231: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c5500 of size 12288 next 106\n",
      "2022-06-19 16:45:26.187233: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c8500 of size 3072 next 108\n",
      "2022-06-19 16:45:26.187235: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c9100 of size 3072 next 109\n",
      "2022-06-19 16:45:26.187237: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136c9d00 of size 3072 next 110\n",
      "2022-06-19 16:45:26.187239: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136ca900 of size 3072 next 112\n",
      "2022-06-19 16:45:26.187242: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136cb500 of size 3072 next 114\n",
      "2022-06-19 16:45:26.187244: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136cc100 of size 3072 next 117\n",
      "2022-06-19 16:45:26.187246: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136ccd00 of size 3072 next 119\n",
      "2022-06-19 16:45:26.187248: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136cd900 of size 3072 next 120\n",
      "2022-06-19 16:45:26.187251: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136ce500 of size 3072 next 121\n",
      "2022-06-19 16:45:26.187253: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136cf100 of size 12288 next 123\n",
      "2022-06-19 16:45:26.187255: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d2100 of size 3072 next 125\n",
      "2022-06-19 16:45:26.187257: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d2d00 of size 3072 next 126\n",
      "2022-06-19 16:45:26.187259: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d3900 of size 3072 next 127\n",
      "2022-06-19 16:45:26.187262: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d4500 of size 3072 next 128\n",
      "2022-06-19 16:45:26.187264: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d5100 of size 3072 next 130\n",
      "2022-06-19 16:45:26.187266: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d5d00 of size 3072 next 132\n",
      "2022-06-19 16:45:26.187268: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d6900 of size 3072 next 134\n",
      "2022-06-19 16:45:26.187271: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d7500 of size 3072 next 136\n",
      "2022-06-19 16:45:26.187273: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d8100 of size 3072 next 137\n",
      "2022-06-19 16:45:26.187275: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d8d00 of size 3072 next 138\n",
      "2022-06-19 16:45:26.187277: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136d9900 of size 3072 next 139\n",
      "2022-06-19 16:45:26.187280: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136da500 of size 21248 next 10\n",
      "2022-06-19 16:45:26.187282: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136df800 of size 256 next 11\n",
      "2022-06-19 16:45:26.187284: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136df900 of size 256 next 12\n",
      "2022-06-19 16:45:26.187287: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136dfa00 of size 256 next 13\n",
      "2022-06-19 16:45:26.187289: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136dfb00 of size 256 next 14\n",
      "2022-06-19 16:45:26.187291: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136dfc00 of size 256 next 15\n",
      "2022-06-19 16:45:26.187293: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136dfd00 of size 256 next 16\n",
      "2022-06-19 16:45:26.187296: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136dfe00 of size 256 next 17\n",
      "2022-06-19 16:45:26.187298: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136dff00 of size 256 next 18\n",
      "2022-06-19 16:45:26.187300: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136e0000 of size 256 next 19\n",
      "2022-06-19 16:45:26.187302: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136e0100 of size 256 next 20\n",
      "2022-06-19 16:45:26.187305: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7136e0200 of size 93763584 next 39\n",
      "2022-06-19 16:45:26.187307: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71904ba00 of size 1572864 next 40\n",
      "2022-06-19 16:45:26.187310: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7191cba00 of size 2359296 next 44\n",
      "2022-06-19 16:45:26.187312: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71940ba00 of size 2359296 next 45\n",
      "2022-06-19 16:45:26.187314: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71964ba00 of size 2359296 next 51\n",
      "2022-06-19 16:45:26.187316: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71988ba00 of size 2359296 next 38\n",
      "2022-06-19 16:45:26.187319: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 719acba00 of size 2359296 next 47\n",
      "2022-06-19 16:45:26.187321: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 719d0ba00 of size 9437184 next 54\n",
      "2022-06-19 16:45:26.187323: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71a60ba00 of size 9437184 next 49\n",
      "2022-06-19 16:45:26.187326: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71af0ba00 of size 2359296 next 58\n",
      "2022-06-19 16:45:26.187328: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71b14ba00 of size 2359296 next 60\n",
      "2022-06-19 16:45:26.187330: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71b38ba00 of size 2359296 next 63\n",
      "2022-06-19 16:45:26.187332: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71b5cba00 of size 2359296 next 65\n",
      "2022-06-19 16:45:26.187335: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71b80ba00 of size 9437184 next 69\n",
      "2022-06-19 16:45:26.187337: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71c10ba00 of size 9437184 next 71\n",
      "2022-06-19 16:45:26.187339: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71ca0ba00 of size 2359296 next 76\n",
      "2022-06-19 16:45:26.187341: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71cc4ba00 of size 2359296 next 78\n",
      "2022-06-19 16:45:26.187343: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71ce8ba00 of size 2359296 next 80\n",
      "2022-06-19 16:45:26.187346: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71d0cba00 of size 2359296 next 82\n",
      "2022-06-19 16:45:26.187348: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71d30ba00 of size 9437184 next 87\n",
      "2022-06-19 16:45:26.187350: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71dc0ba00 of size 9437184 next 89\n",
      "2022-06-19 16:45:26.187353: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71e50ba00 of size 2359296 next 93\n",
      "2022-06-19 16:45:26.187355: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71e74ba00 of size 9437184 next 94\n",
      "2022-06-19 16:45:26.187357: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71f04ba00 of size 2359296 next 96\n",
      "2022-06-19 16:45:26.187359: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71f28ba00 of size 2359296 next 98\n",
      "2022-06-19 16:45:26.187362: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71f4cba00 of size 2359296 next 100\n",
      "2022-06-19 16:45:26.187364: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 71f70ba00 of size 9437184 next 104\n",
      "2022-06-19 16:45:26.187366: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72000ba00 of size 9437184 next 107\n",
      "2022-06-19 16:45:26.187369: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72090ba00 of size 2359296 next 111\n",
      "2022-06-19 16:45:26.187371: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 720b4ba00 of size 2359296 next 113\n",
      "2022-06-19 16:45:26.187373: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 720d8ba00 of size 2359296 next 115\n",
      "2022-06-19 16:45:26.187375: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 720fcba00 of size 9437184 next 116\n",
      "2022-06-19 16:45:26.187377: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7218cba00 of size 2359296 next 118\n",
      "2022-06-19 16:45:26.187380: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 721b0ba00 of size 9437184 next 122\n",
      "2022-06-19 16:45:26.187382: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72240ba00 of size 9437184 next 124\n",
      "2022-06-19 16:45:26.187384: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 722d0ba00 of size 2359296 next 129\n",
      "2022-06-19 16:45:26.187386: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 722f4ba00 of size 2359296 next 131\n",
      "2022-06-19 16:45:26.187389: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72318ba00 of size 2359296 next 133\n",
      "2022-06-19 16:45:26.187391: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7233cba00 of size 2359296 next 135\n",
      "2022-06-19 16:45:26.187393: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72360ba00 of size 9437184 next 140\n",
      "2022-06-19 16:45:26.187395: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 723f0ba00 of size 9437184 next 141\n",
      "2022-06-19 16:45:26.187398: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72480ba00 of size 3072 next 142\n",
      "2022-06-19 16:45:26.187400: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72480c600 of size 3072 next 143\n",
      "2022-06-19 16:45:26.187402: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72480d200 of size 3072 next 144\n",
      "2022-06-19 16:45:26.187404: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72480de00 of size 2359296 next 145\n",
      "2022-06-19 16:45:26.187407: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724a4de00 of size 3072 next 146\n",
      "2022-06-19 16:45:26.187409: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724a4ea00 of size 6144 next 147\n",
      "2022-06-19 16:45:26.187411: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724a50200 of size 3072 next 148\n",
      "2022-06-19 16:45:26.187413: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724a50e00 of size 2359296 next 149\n",
      "2022-06-19 16:45:26.187416: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724c90e00 of size 3072 next 150\n",
      "2022-06-19 16:45:26.187418: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724c91a00 of size 2359296 next 151\n",
      "2022-06-19 16:45:26.187420: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724ed1a00 of size 3072 next 152\n",
      "2022-06-19 16:45:26.187422: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 724ed2600 of size 2359296 next 153\n",
      "2022-06-19 16:45:26.187425: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725112600 of size 3072 next 154\n",
      "2022-06-19 16:45:26.187429: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725113200 of size 2359296 next 155\n",
      "2022-06-19 16:45:26.187435: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725353200 of size 3072 next 156\n",
      "2022-06-19 16:45:26.187442: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725353e00 of size 3072 next 157\n",
      "2022-06-19 16:45:26.187445: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725354a00 of size 3072 next 158\n",
      "2022-06-19 16:45:26.187448: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725355600 of size 3072 next 159\n",
      "2022-06-19 16:45:26.187451: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725356200 of size 9437184 next 160\n",
      "2022-06-19 16:45:26.187454: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725c56200 of size 12288 next 161\n",
      "2022-06-19 16:45:26.187457: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 725c59200 of size 9437184 next 162\n",
      "2022-06-19 16:45:26.187460: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726559200 of size 3072 next 163\n",
      "2022-06-19 16:45:26.187463: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726559e00 of size 3072 next 164\n",
      "2022-06-19 16:45:26.187466: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72655aa00 of size 3072 next 165\n",
      "2022-06-19 16:45:26.187469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72655b600 of size 2359296 next 166\n",
      "2022-06-19 16:45:26.187472: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72679b600 of size 3072 next 167\n",
      "2022-06-19 16:45:26.187475: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72679c200 of size 2359296 next 168\n",
      "2022-06-19 16:45:26.187477: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7269dc200 of size 3072 next 169\n",
      "2022-06-19 16:45:26.187480: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7269dce00 of size 3072 next 170\n",
      "2022-06-19 16:45:26.187483: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7269dda00 of size 2359296 next 171\n",
      "2022-06-19 16:45:26.187486: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726c1da00 of size 3072 next 172\n",
      "2022-06-19 16:45:26.187489: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726c1e600 of size 2359296 next 173\n",
      "2022-06-19 16:45:26.187492: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726e5e600 of size 3072 next 174\n",
      "2022-06-19 16:45:26.187495: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726e5f200 of size 3072 next 175\n",
      "2022-06-19 16:45:26.187498: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726e5fe00 of size 3072 next 176\n",
      "2022-06-19 16:45:26.187501: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 726e60a00 of size 9437184 next 177\n",
      "2022-06-19 16:45:26.187504: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 727760a00 of size 12288 next 178\n",
      "2022-06-19 16:45:26.187507: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 727763a00 of size 9437184 next 179\n",
      "2022-06-19 16:45:26.187510: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728063a00 of size 2359296 next 180\n",
      "2022-06-19 16:45:26.187513: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7282a3a00 of size 3072 next 181\n",
      "2022-06-19 16:45:26.187515: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7282a4600 of size 3072 next 182\n",
      "2022-06-19 16:45:26.187518: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7282a5200 of size 3072 next 183\n",
      "2022-06-19 16:45:26.187521: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7282a5e00 of size 2359296 next 184\n",
      "2022-06-19 16:45:26.187525: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7284e5e00 of size 3072 next 185\n",
      "2022-06-19 16:45:26.187529: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7284e6a00 of size 2359296 next 186\n",
      "2022-06-19 16:45:26.187531: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728726a00 of size 3072 next 187\n",
      "2022-06-19 16:45:26.187534: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728727600 of size 2359296 next 188\n",
      "2022-06-19 16:45:26.187537: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728967600 of size 3072 next 189\n",
      "2022-06-19 16:45:26.187541: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728968200 of size 2359296 next 190\n",
      "2022-06-19 16:45:26.187543: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728ba8200 of size 3072 next 191\n",
      "2022-06-19 16:45:26.187546: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728ba8e00 of size 3072 next 192\n",
      "2022-06-19 16:45:26.187549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728ba9a00 of size 3072 next 193\n",
      "2022-06-19 16:45:26.187552: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728baa600 of size 3072 next 194\n",
      "2022-06-19 16:45:26.187555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 728bab200 of size 9437184 next 195\n",
      "2022-06-19 16:45:26.187558: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7294ab200 of size 12288 next 196\n",
      "2022-06-19 16:45:26.187561: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7294ae200 of size 9437184 next 197\n",
      "2022-06-19 16:45:26.187564: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 729dae200 of size 3072 next 198\n",
      "2022-06-19 16:45:26.187567: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 729daee00 of size 3072 next 199\n",
      "2022-06-19 16:45:26.187570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 729dafa00 of size 3072 next 200\n",
      "2022-06-19 16:45:26.187573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 729db0600 of size 2359296 next 201\n",
      "2022-06-19 16:45:26.187576: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 729ff0600 of size 2359296 next 202\n",
      "2022-06-19 16:45:26.187579: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a230600 of size 3072 next 203\n",
      "2022-06-19 16:45:26.187582: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a231200 of size 2359296 next 204\n",
      "2022-06-19 16:45:26.187585: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a471200 of size 3072 next 205\n",
      "2022-06-19 16:45:26.187588: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a471e00 of size 2359296 next 206\n",
      "2022-06-19 16:45:26.187592: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a6b1e00 of size 3072 next 207\n",
      "2022-06-19 16:45:26.187595: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a6b2a00 of size 2359296 next 208\n",
      "2022-06-19 16:45:26.187598: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a8f2a00 of size 3072 next 209\n",
      "2022-06-19 16:45:26.187601: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a8f3600 of size 3072 next 210\n",
      "2022-06-19 16:45:26.187604: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a8f4200 of size 3072 next 211\n",
      "2022-06-19 16:45:26.187607: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72a8f4e00 of size 9437184 next 212\n",
      "2022-06-19 16:45:26.187610: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72b1f4e00 of size 3072 next 213\n",
      "2022-06-19 16:45:26.187613: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72b1f5a00 of size 12288 next 214\n",
      "2022-06-19 16:45:26.187616: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72b1f8a00 of size 9437184 next 215\n",
      "2022-06-19 16:45:26.187619: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72baf8a00 of size 3072 next 216\n",
      "2022-06-19 16:45:26.187623: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72baf9600 of size 3072 next 217\n",
      "2022-06-19 16:45:26.187626: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72bafa200 of size 3072 next 218\n",
      "2022-06-19 16:45:26.187629: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72bafae00 of size 2359296 next 219\n",
      "2022-06-19 16:45:26.187632: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72bd3ae00 of size 3072 next 220\n",
      "2022-06-19 16:45:26.187635: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72bd3ba00 of size 2359296 next 221\n",
      "2022-06-19 16:45:26.187638: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72bf7ba00 of size 3072 next 222\n",
      "2022-06-19 16:45:26.187641: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72bf7c600 of size 2359296 next 223\n",
      "2022-06-19 16:45:26.187644: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c1bc600 of size 2359296 next 224\n",
      "2022-06-19 16:45:26.187647: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c3fc600 of size 3072 next 225\n",
      "2022-06-19 16:45:26.187650: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c3fd200 of size 2359296 next 226\n",
      "2022-06-19 16:45:26.187653: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c63d200 of size 3072 next 227\n",
      "2022-06-19 16:45:26.187656: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c63de00 of size 3072 next 228\n",
      "2022-06-19 16:45:26.187659: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c63ea00 of size 3072 next 229\n",
      "2022-06-19 16:45:26.187662: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72c63f600 of size 9437184 next 230\n",
      "2022-06-19 16:45:26.187666: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72cf3f600 of size 12288 next 231\n",
      "2022-06-19 16:45:26.187669: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72cf42600 of size 9437184 next 232\n",
      "2022-06-19 16:45:26.187672: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d842600 of size 3072 next 233\n",
      "2022-06-19 16:45:26.187676: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d843200 of size 3072 next 234\n",
      "2022-06-19 16:45:26.187679: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d843e00 of size 256 next 235\n",
      "2022-06-19 16:45:26.187683: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d843f00 of size 256 next 236\n",
      "2022-06-19 16:45:26.187686: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844000 of size 256 next 237\n",
      "2022-06-19 16:45:26.187689: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844100 of size 256 next 238\n",
      "2022-06-19 16:45:26.187692: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844200 of size 256 next 239\n",
      "2022-06-19 16:45:26.187696: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844300 of size 256 next 240\n",
      "2022-06-19 16:45:26.187699: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844400 of size 256 next 241\n",
      "2022-06-19 16:45:26.187703: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844500 of size 256 next 242\n",
      "2022-06-19 16:45:26.187706: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844600 of size 256 next 243\n",
      "2022-06-19 16:45:26.187709: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d844700 of size 1581056 next 247\n",
      "2022-06-19 16:45:26.187713: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6700 of size 256 next 258\n",
      "2022-06-19 16:45:26.187716: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6800 of size 256 next 262\n",
      "2022-06-19 16:45:26.187719: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6900 of size 256 next 259\n",
      "2022-06-19 16:45:26.187722: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6a00 of size 256 next 261\n",
      "2022-06-19 16:45:26.187726: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6b00 of size 256 next 472\n",
      "2022-06-19 16:45:26.187729: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6c00 of size 256 next 265\n",
      "2022-06-19 16:45:26.187733: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6d00 of size 256 next 269\n",
      "2022-06-19 16:45:26.187736: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6e00 of size 256 next 366\n",
      "2022-06-19 16:45:26.187739: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c6f00 of size 256 next 266\n",
      "2022-06-19 16:45:26.187742: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c7000 of size 256 next 264\n",
      "2022-06-19 16:45:26.187746: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c7100 of size 256 next 268\n",
      "2022-06-19 16:45:26.187749: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c7200 of size 256 next 260\n",
      "2022-06-19 16:45:26.187752: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c7300 of size 3072 next 252\n",
      "2022-06-19 16:45:26.187755: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c7f00 of size 256 next 473\n",
      "2022-06-19 16:45:26.187757: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8000 of size 256 next 271\n",
      "2022-06-19 16:45:26.187760: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8100 of size 256 next 272\n",
      "2022-06-19 16:45:26.187763: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8200 of size 256 next 280\n",
      "2022-06-19 16:45:26.187767: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8300 of size 256 next 704\n",
      "2022-06-19 16:45:26.187770: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8400 of size 256 next 480\n",
      "2022-06-19 16:45:26.187773: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8500 of size 256 next 477\n",
      "2022-06-19 16:45:26.187776: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8600 of size 256 next 277\n",
      "2022-06-19 16:45:26.187779: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8700 of size 256 next 279\n",
      "2022-06-19 16:45:26.187782: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c8800 of size 3072 next 448\n",
      "2022-06-19 16:45:26.187785: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9c9400 of size 3072 next 446\n",
      "2022-06-19 16:45:26.187788: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9ca000 of size 3072 next 443\n",
      "2022-06-19 16:45:26.187792: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9cac00 of size 12288 next 441\n",
      "2022-06-19 16:45:26.187795: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9cdc00 of size 3072 next 439\n",
      "2022-06-19 16:45:26.187798: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9ce800 of size 3072 next 437\n",
      "2022-06-19 16:45:26.187800: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9cf400 of size 3072 next 434\n",
      "2022-06-19 16:45:26.187803: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d0000 of size 3072 next 345\n",
      "2022-06-19 16:45:26.187808: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d0c00 of size 3072 next 344\n",
      "2022-06-19 16:45:26.187811: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d1800 of size 3072 next 342\n",
      "2022-06-19 16:45:26.187814: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d2400 of size 3072 next 343\n",
      "2022-06-19 16:45:26.187818: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d3000 of size 3072 next 336\n",
      "2022-06-19 16:45:26.187821: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d3c00 of size 3072 next 338\n",
      "2022-06-19 16:45:26.187824: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d4800 of size 3072 next 339\n",
      "2022-06-19 16:45:26.187826: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d5400 of size 12288 next 335\n",
      "2022-06-19 16:45:26.187830: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d8400 of size 3072 next 333\n",
      "2022-06-19 16:45:26.187833: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d9000 of size 3072 next 332\n",
      "2022-06-19 16:45:26.187836: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9d9c00 of size 3072 next 331\n",
      "2022-06-19 16:45:26.187840: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9da800 of size 3072 next 330\n",
      "2022-06-19 16:45:26.187843: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9db400 of size 3072 next 325\n",
      "2022-06-19 16:45:26.187846: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9dc000 of size 3072 next 292\n",
      "2022-06-19 16:45:26.187849: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9dcc00 of size 3072 next 291\n",
      "2022-06-19 16:45:26.187852: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9dd800 of size 3072 next 288\n",
      "2022-06-19 16:45:26.187856: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9de400 of size 3072 next 290\n",
      "2022-06-19 16:45:26.187859: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9df000 of size 3072 next 287\n",
      "2022-06-19 16:45:26.187862: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9dfc00 of size 3072 next 286\n",
      "2022-06-19 16:45:26.187865: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e0800 of size 12288 next 283\n",
      "2022-06-19 16:45:26.187869: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e3800 of size 3072 next 284\n",
      "2022-06-19 16:45:26.187872: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e4400 of size 3072 next 270\n",
      "2022-06-19 16:45:26.187875: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e5000 of size 3072 next 263\n",
      "2022-06-19 16:45:26.187877: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e5c00 of size 3072 next 267\n",
      "2022-06-19 16:45:26.187881: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e6800 of size 3072 next 281\n",
      "2022-06-19 16:45:26.187884: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e7400 of size 3072 next 406\n",
      "2022-06-19 16:45:26.187887: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e8000 of size 3072 next 395\n",
      "2022-06-19 16:45:26.187890: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e8c00 of size 3072 next 310\n",
      "2022-06-19 16:45:26.187893: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9e9800 of size 3072 next 311\n",
      "2022-06-19 16:45:26.187896: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9ea400 of size 12288 next 308\n",
      "2022-06-19 16:45:26.187899: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9ed400 of size 12288 next 305\n",
      "2022-06-19 16:45:26.187902: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f0400 of size 3072 next 304\n",
      "2022-06-19 16:45:26.187905: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f1000 of size 3072 next 306\n",
      "2022-06-19 16:45:26.187909: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f1c00 of size 3072 next 301\n",
      "2022-06-19 16:45:26.187912: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f2800 of size 3072 next 302\n",
      "2022-06-19 16:45:26.187915: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f3400 of size 3072 next 299\n",
      "2022-06-19 16:45:26.187918: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f4000 of size 3072 next 297\n",
      "2022-06-19 16:45:26.187921: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f4c00 of size 3072 next 295\n",
      "2022-06-19 16:45:26.187924: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f5800 of size 3072 next 363\n",
      "2022-06-19 16:45:26.187927: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f6400 of size 3072 next 364\n",
      "2022-06-19 16:45:26.187930: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9f7000 of size 12288 next 362\n",
      "2022-06-19 16:45:26.187934: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fa000 of size 3072 next 358\n",
      "2022-06-19 16:45:26.187937: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fac00 of size 3072 next 360\n",
      "2022-06-19 16:45:26.187940: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fb800 of size 3072 next 357\n",
      "2022-06-19 16:45:26.187943: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fc400 of size 3072 next 354\n",
      "2022-06-19 16:45:26.187947: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fd000 of size 3072 next 355\n",
      "2022-06-19 16:45:26.187950: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fdc00 of size 3072 next 352\n",
      "2022-06-19 16:45:26.187954: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9fe800 of size 3072 next 349\n",
      "2022-06-19 16:45:26.187957: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72d9ff400 of size 3072 next 348\n",
      "2022-06-19 16:45:26.187960: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da00000 of size 3072 next 347\n",
      "2022-06-19 16:45:26.187963: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da00c00 of size 3072 next 282\n",
      "2022-06-19 16:45:26.187966: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da01800 of size 3072 next 436\n",
      "2022-06-19 16:45:26.187969: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da02400 of size 12288 next 433\n",
      "2022-06-19 16:45:26.187972: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da05400 of size 3072 next 431\n",
      "2022-06-19 16:45:26.187976: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da06000 of size 3072 next 427\n",
      "2022-06-19 16:45:26.187979: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da06c00 of size 3072 next 430\n",
      "2022-06-19 16:45:26.187982: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da07800 of size 3072 next 428\n",
      "2022-06-19 16:45:26.187986: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08400 of size 256 next 1340\n",
      "2022-06-19 16:45:26.187989: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08500 of size 256 next 1221\n",
      "2022-06-19 16:45:26.187992: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08600 of size 256 next 1279\n",
      "2022-06-19 16:45:26.187995: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08700 of size 256 next 1228\n",
      "2022-06-19 16:45:26.187998: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08800 of size 256 next 1322\n",
      "2022-06-19 16:45:26.188001: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08900 of size 256 next 1246\n",
      "2022-06-19 16:45:26.188004: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08a00 of size 256 next 1247\n",
      "2022-06-19 16:45:26.188008: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08b00 of size 256 next 1305\n",
      "2022-06-19 16:45:26.188011: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08c00 of size 256 next 1306\n",
      "2022-06-19 16:45:26.188014: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08d00 of size 256 next 1294\n",
      "2022-06-19 16:45:26.188017: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08e00 of size 256 next 1230\n",
      "2022-06-19 16:45:26.188020: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da08f00 of size 256 next 1226\n",
      "2022-06-19 16:45:26.188024: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 72da09000 of size 256 next 456\n",
      "2022-06-19 16:45:26.188029: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da09100 of size 256 next 321\n",
      "2022-06-19 16:45:26.188038: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 72da09200 of size 2560 next 425\n",
      "2022-06-19 16:45:26.188042: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da09c00 of size 3072 next 424\n",
      "2022-06-19 16:45:26.188046: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0a800 of size 3072 next 423\n",
      "2022-06-19 16:45:26.188049: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0b400 of size 3072 next 421\n",
      "2022-06-19 16:45:26.188052: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0c000 of size 3072 next 417\n",
      "2022-06-19 16:45:26.188055: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0cc00 of size 3072 next 384\n",
      "2022-06-19 16:45:26.188058: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0d800 of size 3072 next 381\n",
      "2022-06-19 16:45:26.188062: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0e400 of size 3072 next 378\n",
      "2022-06-19 16:45:26.188065: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0f000 of size 3072 next 382\n",
      "2022-06-19 16:45:26.188068: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da0fc00 of size 12288 next 326\n",
      "2022-06-19 16:45:26.188071: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da12c00 of size 3072 next 323\n",
      "2022-06-19 16:45:26.188075: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da13800 of size 3072 next 322\n",
      "2022-06-19 16:45:26.188078: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da14400 of size 3072 next 318\n",
      "2022-06-19 16:45:26.188081: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da15000 of size 3072 next 320\n",
      "2022-06-19 16:45:26.188085: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da15c00 of size 3072 next 316\n",
      "2022-06-19 16:45:26.188088: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da16800 of size 3072 next 315\n",
      "2022-06-19 16:45:26.188092: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da17400 of size 3072 next 314\n",
      "2022-06-19 16:45:26.188095: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da18000 of size 3072 next 312\n",
      "2022-06-19 16:45:26.188098: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da18c00 of size 3072 next 401\n",
      "2022-06-19 16:45:26.188101: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da19800 of size 3072 next 402\n",
      "2022-06-19 16:45:26.188104: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da1a400 of size 12288 next 398\n",
      "2022-06-19 16:45:26.188108: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da1d400 of size 3072 next 396\n",
      "2022-06-19 16:45:26.188111: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da1e000 of size 3072 next 392\n",
      "2022-06-19 16:45:26.188115: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da1ec00 of size 3072 next 393\n",
      "2022-06-19 16:45:26.188118: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da1f800 of size 3072 next 390\n",
      "2022-06-19 16:45:26.188121: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da20400 of size 3072 next 388\n",
      "2022-06-19 16:45:26.188124: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da21000 of size 3072 next 386\n",
      "2022-06-19 16:45:26.188127: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da21c00 of size 3072 next 273\n",
      "2022-06-19 16:45:26.188130: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da22800 of size 3072 next 470\n",
      "2022-06-19 16:45:26.188136: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da23400 of size 3072 next 471\n",
      "2022-06-19 16:45:26.188144: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da24000 of size 3072 next 468\n",
      "2022-06-19 16:45:26.188147: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da24c00 of size 12288 next 466\n",
      "2022-06-19 16:45:26.188150: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da27c00 of size 3072 next 465\n",
      "2022-06-19 16:45:26.188154: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da28800 of size 3072 next 464\n",
      "2022-06-19 16:45:26.188157: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da29400 of size 3072 next 462\n",
      "2022-06-19 16:45:26.188160: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2a000 of size 3072 next 458\n",
      "2022-06-19 16:45:26.188164: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2ac00 of size 3072 next 457\n",
      "2022-06-19 16:45:26.188167: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2b800 of size 3072 next 419\n",
      "2022-06-19 16:45:26.188170: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2c400 of size 3072 next 415\n",
      "2022-06-19 16:45:26.188173: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2d000 of size 3072 next 414\n",
      "2022-06-19 16:45:26.188177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2dc00 of size 3072 next 416\n",
      "2022-06-19 16:45:26.188180: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2e800 of size 3072 next 410\n",
      "2022-06-19 16:45:26.188183: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da2f400 of size 12288 next 412\n",
      "2022-06-19 16:45:26.188190: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da32400 of size 3072 next 409\n",
      "2022-06-19 16:45:26.188197: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da33000 of size 3072 next 408\n",
      "2022-06-19 16:45:26.188201: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da33c00 of size 3072 next 407\n",
      "2022-06-19 16:45:26.188204: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da34800 of size 3072 next 403\n",
      "2022-06-19 16:45:26.188208: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da35400 of size 3072 next 379\n",
      "2022-06-19 16:45:26.188211: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da36000 of size 3072 next 375\n",
      "2022-06-19 16:45:26.188215: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da36c00 of size 3072 next 374\n",
      "2022-06-19 16:45:26.188218: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da37800 of size 3072 next 372\n",
      "2022-06-19 16:45:26.188221: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da38400 of size 3072 next 373\n",
      "2022-06-19 16:45:26.188224: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da39000 of size 12288 next 369\n",
      "2022-06-19 16:45:26.188228: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3c000 of size 3072 next 368\n",
      "2022-06-19 16:45:26.188231: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3cc00 of size 3072 next 367\n",
      "2022-06-19 16:45:26.188234: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3d800 of size 256 next 488\n",
      "2022-06-19 16:45:26.188238: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3d900 of size 256 next 479\n",
      "2022-06-19 16:45:26.188241: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3da00 of size 256 next 483\n",
      "2022-06-19 16:45:26.188244: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3db00 of size 256 next 706\n",
      "2022-06-19 16:45:26.188248: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3dc00 of size 256 next 707\n",
      "2022-06-19 16:45:26.188251: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3dd00 of size 256 next 693\n",
      "2022-06-19 16:45:26.188254: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3de00 of size 256 next 708\n",
      "2022-06-19 16:45:26.188258: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3df00 of size 256 next 703\n",
      "2022-06-19 16:45:26.188261: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e000 of size 256 next 711\n",
      "2022-06-19 16:45:26.188265: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e100 of size 256 next 486\n",
      "2022-06-19 16:45:26.188269: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e200 of size 256 next 701\n",
      "2022-06-19 16:45:26.188272: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e300 of size 256 next 695\n",
      "2022-06-19 16:45:26.188276: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e400 of size 256 next 495\n",
      "2022-06-19 16:45:26.188279: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e500 of size 256 next 476\n",
      "2022-06-19 16:45:26.188289: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e600 of size 256 next 699\n",
      "2022-06-19 16:45:26.188293: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e700 of size 256 next 698\n",
      "2022-06-19 16:45:26.188296: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da3e800 of size 6144 next 705\n",
      "2022-06-19 16:45:26.188300: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da40000 of size 3072 next 712\n",
      "2022-06-19 16:45:26.188304: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da40c00 of size 3328 next 496\n",
      "2022-06-19 16:45:26.188312: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da41900 of size 256 next 490\n",
      "2022-06-19 16:45:26.188317: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da41a00 of size 3072 next 484\n",
      "2022-06-19 16:45:26.188321: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da42600 of size 3072 next 485\n",
      "2022-06-19 16:45:26.188324: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da43200 of size 4608 next 475\n",
      "2022-06-19 16:45:26.188328: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da44400 of size 3072 next 453\n",
      "2022-06-19 16:45:26.188331: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da45000 of size 3072 next 474\n",
      "2022-06-19 16:45:26.188335: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da45c00 of size 3072 next 487\n",
      "2022-06-19 16:45:26.188338: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da46800 of size 3072 next 491\n",
      "2022-06-19 16:45:26.188341: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da47400 of size 3072 next 493\n",
      "2022-06-19 16:45:26.188344: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da48000 of size 3072 next 494\n",
      "2022-06-19 16:45:26.188348: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da48c00 of size 3072 next 500\n",
      "2022-06-19 16:45:26.188351: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da49800 of size 12288 next 501\n",
      "2022-06-19 16:45:26.188354: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da4c800 of size 3072 next 503\n",
      "2022-06-19 16:45:26.188357: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da4d400 of size 3072 next 504\n",
      "2022-06-19 16:45:26.188360: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da4e000 of size 3072 next 505\n",
      "2022-06-19 16:45:26.188363: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da4ec00 of size 3072 next 507\n",
      "2022-06-19 16:45:26.188366: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da4f800 of size 3072 next 509\n",
      "2022-06-19 16:45:26.188370: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da50400 of size 3072 next 510\n",
      "2022-06-19 16:45:26.188377: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da51000 of size 3072 next 512\n",
      "2022-06-19 16:45:26.188383: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da51c00 of size 3072 next 514\n",
      "2022-06-19 16:45:26.188387: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da52800 of size 3072 next 515\n",
      "2022-06-19 16:45:26.188390: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da53400 of size 3072 next 516\n",
      "2022-06-19 16:45:26.188394: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da54000 of size 12288 next 518\n",
      "2022-06-19 16:45:26.188401: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da57000 of size 3072 next 520\n",
      "2022-06-19 16:45:26.188408: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da57c00 of size 3072 next 521\n",
      "2022-06-19 16:45:26.188412: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da58800 of size 3072 next 522\n",
      "2022-06-19 16:45:26.188415: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da59400 of size 3072 next 523\n",
      "2022-06-19 16:45:26.188419: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5a000 of size 3072 next 525\n",
      "2022-06-19 16:45:26.188422: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5ac00 of size 3072 next 527\n",
      "2022-06-19 16:45:26.188425: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5b800 of size 3072 next 529\n",
      "2022-06-19 16:45:26.188429: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5c400 of size 3072 next 531\n",
      "2022-06-19 16:45:26.188432: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5d000 of size 3072 next 532\n",
      "2022-06-19 16:45:26.188435: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5dc00 of size 3072 next 533\n",
      "2022-06-19 16:45:26.188438: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5e800 of size 3072 next 534\n",
      "2022-06-19 16:45:26.188442: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da5f400 of size 12288 next 536\n",
      "2022-06-19 16:45:26.188448: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da62400 of size 3072 next 538\n",
      "2022-06-19 16:45:26.188456: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da63000 of size 3072 next 539\n",
      "2022-06-19 16:45:26.188460: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da63c00 of size 3072 next 540\n",
      "2022-06-19 16:45:26.188463: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da64800 of size 3072 next 543\n",
      "2022-06-19 16:45:26.188466: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da65400 of size 3072 next 545\n",
      "2022-06-19 16:45:26.188470: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da66000 of size 3072 next 547\n",
      "2022-06-19 16:45:26.188473: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da66c00 of size 3072 next 549\n",
      "2022-06-19 16:45:26.188477: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da67800 of size 3072 next 550\n",
      "2022-06-19 16:45:26.188480: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da68400 of size 3072 next 551\n",
      "2022-06-19 16:45:26.188483: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da69000 of size 12288 next 553\n",
      "2022-06-19 16:45:26.188487: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da6c000 of size 12288 next 554\n",
      "2022-06-19 16:45:26.188490: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da6f000 of size 3072 next 556\n",
      "2022-06-19 16:45:26.188494: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da6fc00 of size 3072 next 557\n",
      "2022-06-19 16:45:26.188497: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da70800 of size 3072 next 558\n",
      "2022-06-19 16:45:26.188501: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da71400 of size 3072 next 560\n",
      "2022-06-19 16:45:26.188504: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da72000 of size 3072 next 562\n",
      "2022-06-19 16:45:26.188507: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da72c00 of size 3072 next 565\n",
      "2022-06-19 16:45:26.188511: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da73800 of size 3072 next 567\n",
      "2022-06-19 16:45:26.188514: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da74400 of size 3072 next 568\n",
      "2022-06-19 16:45:26.188518: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da75000 of size 3072 next 569\n",
      "2022-06-19 16:45:26.188522: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da75c00 of size 12288 next 571\n",
      "2022-06-19 16:45:26.188525: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da78c00 of size 3072 next 573\n",
      "2022-06-19 16:45:26.188528: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da79800 of size 3072 next 574\n",
      "2022-06-19 16:45:26.188531: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7a400 of size 3072 next 575\n",
      "2022-06-19 16:45:26.188535: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7b000 of size 3072 next 576\n",
      "2022-06-19 16:45:26.188538: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7bc00 of size 3072 next 578\n",
      "2022-06-19 16:45:26.188542: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7c800 of size 3072 next 580\n",
      "2022-06-19 16:45:26.188545: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7d400 of size 3072 next 582\n",
      "2022-06-19 16:45:26.188549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7e000 of size 3072 next 584\n",
      "2022-06-19 16:45:26.188552: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7ec00 of size 3072 next 585\n",
      "2022-06-19 16:45:26.188556: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da7f800 of size 3072 next 586\n",
      "2022-06-19 16:45:26.188559: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da80400 of size 3072 next 587\n",
      "2022-06-19 16:45:26.188563: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da81000 of size 12288 next 589\n",
      "2022-06-19 16:45:26.188566: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da84000 of size 3072 next 591\n",
      "2022-06-19 16:45:26.188570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da84c00 of size 3072 next 592\n",
      "2022-06-19 16:45:26.188573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da85800 of size 3072 next 593\n",
      "2022-06-19 16:45:26.188576: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da86400 of size 3072 next 595\n",
      "2022-06-19 16:45:26.188579: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da87000 of size 6144 next 596\n",
      "2022-06-19 16:45:26.188583: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da88800 of size 3072 next 597\n",
      "2022-06-19 16:45:26.188586: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da89400 of size 3072 next 599\n",
      "2022-06-19 16:45:26.188589: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8a000 of size 3072 next 601\n",
      "2022-06-19 16:45:26.188592: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8ac00 of size 3072 next 603\n",
      "2022-06-19 16:45:26.188595: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8b800 of size 3072 next 605\n",
      "2022-06-19 16:45:26.188599: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8c400 of size 3072 next 606\n",
      "2022-06-19 16:45:26.188602: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8d000 of size 3072 next 607\n",
      "2022-06-19 16:45:26.188605: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8dc00 of size 3072 next 608\n",
      "2022-06-19 16:45:26.188608: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da8e800 of size 12288 next 610\n",
      "2022-06-19 16:45:26.188612: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da91800 of size 3072 next 612\n",
      "2022-06-19 16:45:26.188615: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da92400 of size 3072 next 613\n",
      "2022-06-19 16:45:26.188618: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da93000 of size 3072 next 614\n",
      "2022-06-19 16:45:26.188622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da93c00 of size 3072 next 616\n",
      "2022-06-19 16:45:26.188630: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da94800 of size 3072 next 618\n",
      "2022-06-19 16:45:26.188637: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da95400 of size 3072 next 619\n",
      "2022-06-19 16:45:26.188641: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da96000 of size 3072 next 621\n",
      "2022-06-19 16:45:26.188644: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da96c00 of size 3072 next 623\n",
      "2022-06-19 16:45:26.188648: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da97800 of size 3072 next 624\n",
      "2022-06-19 16:45:26.188651: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da98400 of size 3072 next 625\n",
      "2022-06-19 16:45:26.188654: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da99000 of size 12288 next 627\n",
      "2022-06-19 16:45:26.188658: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da9c000 of size 3072 next 630\n",
      "2022-06-19 16:45:26.188661: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da9cc00 of size 3072 next 631\n",
      "2022-06-19 16:45:26.188665: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da9d800 of size 3072 next 632\n",
      "2022-06-19 16:45:26.188668: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da9e400 of size 3072 next 634\n",
      "2022-06-19 16:45:26.188671: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da9f000 of size 3072 next 636\n",
      "2022-06-19 16:45:26.188674: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72da9fc00 of size 3072 next 638\n",
      "2022-06-19 16:45:26.188677: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa0800 of size 3072 next 640\n",
      "2022-06-19 16:45:26.188681: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa1400 of size 3072 next 641\n",
      "2022-06-19 16:45:26.188684: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa2000 of size 3072 next 642\n",
      "2022-06-19 16:45:26.188688: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa2c00 of size 3072 next 643\n",
      "2022-06-19 16:45:26.188691: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa3800 of size 12288 next 645\n",
      "2022-06-19 16:45:26.188694: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa6800 of size 3072 next 647\n",
      "2022-06-19 16:45:26.188698: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa7400 of size 3072 next 648\n",
      "2022-06-19 16:45:26.188701: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa8000 of size 3072 next 649\n",
      "2022-06-19 16:45:26.188704: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa8c00 of size 3072 next 652\n",
      "2022-06-19 16:45:26.188708: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daa9800 of size 3072 next 654\n",
      "2022-06-19 16:45:26.188711: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daaa400 of size 3072 next 656\n",
      "2022-06-19 16:45:26.188714: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daab000 of size 3072 next 658\n",
      "2022-06-19 16:45:26.188718: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daabc00 of size 3072 next 659\n",
      "2022-06-19 16:45:26.188722: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daac800 of size 3072 next 660\n",
      "2022-06-19 16:45:26.188725: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daad400 of size 3072 next 662\n",
      "2022-06-19 16:45:26.188729: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daae000 of size 12288 next 663\n",
      "2022-06-19 16:45:26.188732: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab1000 of size 3072 next 665\n",
      "2022-06-19 16:45:26.188735: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab1c00 of size 3072 next 666\n",
      "2022-06-19 16:45:26.188738: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab2800 of size 3072 next 667\n",
      "2022-06-19 16:45:26.188741: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab3400 of size 3072 next 669\n",
      "2022-06-19 16:45:26.188745: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab4000 of size 3072 next 671\n",
      "2022-06-19 16:45:26.188748: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab4c00 of size 3072 next 674\n",
      "2022-06-19 16:45:26.188752: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab5800 of size 3072 next 676\n",
      "2022-06-19 16:45:26.188759: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab6400 of size 3072 next 677\n",
      "2022-06-19 16:45:26.188766: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab7000 of size 3072 next 678\n",
      "2022-06-19 16:45:26.188769: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dab7c00 of size 12288 next 680\n",
      "2022-06-19 16:45:26.188772: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabac00 of size 3072 next 682\n",
      "2022-06-19 16:45:26.188775: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabb800 of size 3072 next 683\n",
      "2022-06-19 16:45:26.188779: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabc400 of size 256 next 684\n",
      "2022-06-19 16:45:26.188782: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabc500 of size 256 next 685\n",
      "2022-06-19 16:45:26.188785: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabc600 of size 256 next 688\n",
      "2022-06-19 16:45:26.188789: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabc700 of size 256 next 692\n",
      "2022-06-19 16:45:26.188796: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabc800 of size 256 next 702\n",
      "2022-06-19 16:45:26.188803: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabc900 of size 256 next 694\n",
      "2022-06-19 16:45:26.188806: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabca00 of size 256 next 696\n",
      "2022-06-19 16:45:26.188808: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabcb00 of size 256 next 697\n",
      "2022-06-19 16:45:26.188810: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabcc00 of size 256 next 689\n",
      "2022-06-19 16:45:26.188813: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabcd00 of size 256 next 691\n",
      "2022-06-19 16:45:26.188815: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabce00 of size 256 next 709\n",
      "2022-06-19 16:45:26.188817: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabcf00 of size 256 next 710\n",
      "2022-06-19 16:45:26.188820: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabd000 of size 3072 next 449\n",
      "2022-06-19 16:45:26.188822: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabdc00 of size 3072 next 450\n",
      "2022-06-19 16:45:26.188824: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabe800 of size 3328 next 686\n",
      "2022-06-19 16:45:26.188826: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dabf500 of size 6144 next 687\n",
      "2022-06-19 16:45:26.188829: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac0d00 of size 6144 next 365\n",
      "2022-06-19 16:45:26.188831: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac2500 of size 3072 next 714\n",
      "2022-06-19 16:45:26.188833: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac3100 of size 3072 next 716\n",
      "2022-06-19 16:45:26.188835: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac3d00 of size 3072 next 718\n",
      "2022-06-19 16:45:26.188838: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac4900 of size 3072 next 720\n",
      "2022-06-19 16:45:26.188840: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac5500 of size 3072 next 721\n",
      "2022-06-19 16:45:26.188842: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac6100 of size 3072 next 722\n",
      "2022-06-19 16:45:26.188844: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac6d00 of size 12288 next 724\n",
      "2022-06-19 16:45:26.188847: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dac9d00 of size 3072 next 726\n",
      "2022-06-19 16:45:26.188849: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daca900 of size 3072 next 727\n",
      "2022-06-19 16:45:26.188851: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dacb500 of size 3072 next 728\n",
      "2022-06-19 16:45:26.188854: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dacc100 of size 3072 next 730\n",
      "2022-06-19 16:45:26.188856: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daccd00 of size 3072 next 732\n",
      "2022-06-19 16:45:26.188858: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dacd900 of size 3072 next 734\n",
      "2022-06-19 16:45:26.188861: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dace500 of size 3072 next 736\n",
      "2022-06-19 16:45:26.188863: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dacf100 of size 3072 next 737\n",
      "2022-06-19 16:45:26.188865: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dacfd00 of size 3072 next 738\n",
      "2022-06-19 16:45:26.188867: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad0900 of size 12288 next 740\n",
      "2022-06-19 16:45:26.188869: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad3900 of size 3072 next 742\n",
      "2022-06-19 16:45:26.188872: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad4500 of size 3072 next 743\n",
      "2022-06-19 16:45:26.188874: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad5100 of size 3072 next 744\n",
      "2022-06-19 16:45:26.188876: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad5d00 of size 3072 next 746\n",
      "2022-06-19 16:45:26.188878: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad6900 of size 3072 next 748\n",
      "2022-06-19 16:45:26.188881: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad7500 of size 3072 next 750\n",
      "2022-06-19 16:45:26.188883: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad8100 of size 3072 next 752\n",
      "2022-06-19 16:45:26.188885: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad8d00 of size 3072 next 753\n",
      "2022-06-19 16:45:26.188887: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dad9900 of size 3072 next 754\n",
      "2022-06-19 16:45:26.188889: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dada500 of size 12288 next 756\n",
      "2022-06-19 16:45:26.188892: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dadd500 of size 3072 next 758\n",
      "2022-06-19 16:45:26.188894: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dade100 of size 3072 next 759\n",
      "2022-06-19 16:45:26.188896: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daded00 of size 3072 next 760\n",
      "2022-06-19 16:45:26.188898: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dadf900 of size 3072 next 762\n",
      "2022-06-19 16:45:26.188901: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae0500 of size 3072 next 764\n",
      "2022-06-19 16:45:26.188903: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae1100 of size 3072 next 766\n",
      "2022-06-19 16:45:26.188905: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae1d00 of size 3072 next 768\n",
      "2022-06-19 16:45:26.188907: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae2900 of size 3072 next 769\n",
      "2022-06-19 16:45:26.188909: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae3500 of size 3072 next 770\n",
      "2022-06-19 16:45:26.188912: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae4100 of size 12288 next 772\n",
      "2022-06-19 16:45:26.188914: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae7100 of size 3072 next 774\n",
      "2022-06-19 16:45:26.188916: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae7d00 of size 3072 next 775\n",
      "2022-06-19 16:45:26.188919: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae8900 of size 3072 next 776\n",
      "2022-06-19 16:45:26.188921: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dae9500 of size 3072 next 778\n",
      "2022-06-19 16:45:26.188924: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daea100 of size 3072 next 780\n",
      "2022-06-19 16:45:26.188926: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daead00 of size 3072 next 782\n",
      "2022-06-19 16:45:26.188928: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daeb900 of size 3072 next 784\n",
      "2022-06-19 16:45:26.188930: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daec500 of size 3072 next 785\n",
      "2022-06-19 16:45:26.188932: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daed100 of size 3072 next 786\n",
      "2022-06-19 16:45:26.188935: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daedd00 of size 12288 next 788\n",
      "2022-06-19 16:45:26.188937: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf0d00 of size 3072 next 790\n",
      "2022-06-19 16:45:26.188939: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf1900 of size 3072 next 791\n",
      "2022-06-19 16:45:26.188941: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf2500 of size 3072 next 792\n",
      "2022-06-19 16:45:26.188944: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf3100 of size 3072 next 794\n",
      "2022-06-19 16:45:26.188946: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf3d00 of size 3072 next 796\n",
      "2022-06-19 16:45:26.188948: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf4900 of size 3072 next 798\n",
      "2022-06-19 16:45:26.188950: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf5500 of size 3072 next 800\n",
      "2022-06-19 16:45:26.188953: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf6100 of size 3072 next 801\n",
      "2022-06-19 16:45:26.188955: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf6d00 of size 3072 next 802\n",
      "2022-06-19 16:45:26.188957: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daf7900 of size 12288 next 804\n",
      "2022-06-19 16:45:26.188959: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dafa900 of size 3072 next 806\n",
      "2022-06-19 16:45:26.188961: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dafb500 of size 3072 next 807\n",
      "2022-06-19 16:45:26.188964: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dafc100 of size 3072 next 808\n",
      "2022-06-19 16:45:26.188966: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dafcd00 of size 3072 next 810\n",
      "2022-06-19 16:45:26.188968: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dafd900 of size 3072 next 812\n",
      "2022-06-19 16:45:26.188970: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dafe500 of size 3072 next 814\n",
      "2022-06-19 16:45:26.188973: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daff100 of size 3072 next 816\n",
      "2022-06-19 16:45:26.188975: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72daffd00 of size 3072 next 817\n",
      "2022-06-19 16:45:26.188977: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db00900 of size 3072 next 818\n",
      "2022-06-19 16:45:26.188979: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db01500 of size 12288 next 820\n",
      "2022-06-19 16:45:26.188981: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db04500 of size 3072 next 822\n",
      "2022-06-19 16:45:26.188984: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db05100 of size 3072 next 823\n",
      "2022-06-19 16:45:26.188986: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db05d00 of size 3072 next 824\n",
      "2022-06-19 16:45:26.188988: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db06900 of size 3072 next 826\n",
      "2022-06-19 16:45:26.190412: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db07500 of size 3072 next 828\n",
      "2022-06-19 16:45:26.190429: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db08100 of size 3072 next 830\n",
      "2022-06-19 16:45:26.190432: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db08d00 of size 3072 next 832\n",
      "2022-06-19 16:45:26.190435: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db09900 of size 3072 next 833\n",
      "2022-06-19 16:45:26.190437: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db0a500 of size 3072 next 834\n",
      "2022-06-19 16:45:26.190440: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db0b100 of size 12288 next 836\n",
      "2022-06-19 16:45:26.190442: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db0e100 of size 3072 next 838\n",
      "2022-06-19 16:45:26.190444: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db0ed00 of size 3072 next 839\n",
      "2022-06-19 16:45:26.190446: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db0f900 of size 3072 next 840\n",
      "2022-06-19 16:45:26.190449: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db10500 of size 3072 next 842\n",
      "2022-06-19 16:45:26.190451: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db11100 of size 3072 next 844\n",
      "2022-06-19 16:45:26.190453: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db11d00 of size 3072 next 846\n",
      "2022-06-19 16:45:26.190456: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db12900 of size 3072 next 848\n",
      "2022-06-19 16:45:26.190458: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db13500 of size 3072 next 849\n",
      "2022-06-19 16:45:26.190460: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db14100 of size 3072 next 850\n",
      "2022-06-19 16:45:26.190462: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db14d00 of size 12288 next 852\n",
      "2022-06-19 16:45:26.190465: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db17d00 of size 3072 next 854\n",
      "2022-06-19 16:45:26.190467: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db18900 of size 3072 next 855\n",
      "2022-06-19 16:45:26.190469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db19500 of size 3072 next 856\n",
      "2022-06-19 16:45:26.190471: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1a100 of size 3072 next 858\n",
      "2022-06-19 16:45:26.190474: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1ad00 of size 3072 next 860\n",
      "2022-06-19 16:45:26.190476: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1b900 of size 3072 next 862\n",
      "2022-06-19 16:45:26.190478: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1c500 of size 3072 next 864\n",
      "2022-06-19 16:45:26.190480: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1d100 of size 3072 next 865\n",
      "2022-06-19 16:45:26.190483: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1dd00 of size 3072 next 866\n",
      "2022-06-19 16:45:26.190485: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db1e900 of size 12288 next 868\n",
      "2022-06-19 16:45:26.190487: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db21900 of size 3072 next 870\n",
      "2022-06-19 16:45:26.190489: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db22500 of size 3072 next 871\n",
      "2022-06-19 16:45:26.190491: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db23100 of size 3072 next 872\n",
      "2022-06-19 16:45:26.190494: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db23d00 of size 3072 next 874\n",
      "2022-06-19 16:45:26.190496: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db24900 of size 3072 next 876\n",
      "2022-06-19 16:45:26.190498: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db25500 of size 3072 next 878\n",
      "2022-06-19 16:45:26.190928: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db26100 of size 3072 next 880\n",
      "2022-06-19 16:45:26.190941: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db26d00 of size 3072 next 881\n",
      "2022-06-19 16:45:26.190946: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db27900 of size 3072 next 882\n",
      "2022-06-19 16:45:26.190950: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db28500 of size 12288 next 884\n",
      "2022-06-19 16:45:26.190953: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2b500 of size 3072 next 886\n",
      "2022-06-19 16:45:26.190957: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2c100 of size 3072 next 887\n",
      "2022-06-19 16:45:26.190961: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2cd00 of size 3072 next 888\n",
      "2022-06-19 16:45:26.190967: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2d900 of size 3072 next 890\n",
      "2022-06-19 16:45:26.190976: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2e500 of size 3072 next 892\n",
      "2022-06-19 16:45:26.190980: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2f100 of size 3072 next 894\n",
      "2022-06-19 16:45:26.190984: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db2fd00 of size 3072 next 896\n",
      "2022-06-19 16:45:26.190993: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db30900 of size 3072 next 897\n",
      "2022-06-19 16:45:26.190996: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db31500 of size 3072 next 898\n",
      "2022-06-19 16:45:26.190998: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db32100 of size 12288 next 900\n",
      "2022-06-19 16:45:26.191000: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db35100 of size 3072 next 902\n",
      "2022-06-19 16:45:26.191003: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db35d00 of size 3072 next 903\n",
      "2022-06-19 16:45:26.191005: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db36900 of size 3072 next 904\n",
      "2022-06-19 16:45:26.191007: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db37500 of size 3072 next 906\n",
      "2022-06-19 16:45:26.191010: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db38100 of size 6144 next 907\n",
      "2022-06-19 16:45:26.191012: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db39900 of size 256 next 908\n",
      "2022-06-19 16:45:26.191014: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db39a00 of size 6144 next 911\n",
      "2022-06-19 16:45:26.191017: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3b200 of size 3072 next 912\n",
      "2022-06-19 16:45:26.191019: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3be00 of size 3072 next 913\n",
      "2022-06-19 16:45:26.191021: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3ca00 of size 3072 next 915\n",
      "2022-06-19 16:45:26.191023: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3d600 of size 3072 next 917\n",
      "2022-06-19 16:45:26.191026: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3e200 of size 3072 next 919\n",
      "2022-06-19 16:45:26.191028: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3ee00 of size 3072 next 921\n",
      "2022-06-19 16:45:26.191030: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db3fa00 of size 3072 next 922\n",
      "2022-06-19 16:45:26.191033: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db40600 of size 3072 next 923\n",
      "2022-06-19 16:45:26.191036: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db41200 of size 21760 next 249\n",
      "2022-06-19 16:45:26.191038: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72db46700 of size 1572864 next 248\n",
      "2022-06-19 16:45:26.191041: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dcc6700 of size 1572864 next 244\n",
      "2022-06-19 16:45:26.191500: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72de46700 of size 1572864 next 245\n",
      "2022-06-19 16:45:26.191509: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72dfc6700 of size 1572864 next 250\n",
      "2022-06-19 16:45:26.191512: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72e146700 of size 1572864 next 246\n",
      "2022-06-19 16:45:26.191514: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72e2c6700 of size 1572864 next 251\n",
      "2022-06-19 16:45:26.191517: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72e446700 of size 1572864 next 253\n",
      "2022-06-19 16:45:26.191519: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72e5c6700 of size 1572864 next 254\n",
      "2022-06-19 16:45:26.191521: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72e746700 of size 1572864 next 255\n",
      "2022-06-19 16:45:26.191523: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72e8c6700 of size 1572864 next 256\n",
      "2022-06-19 16:45:26.191526: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72ea46700 of size 1572864 next 257\n",
      "2022-06-19 16:45:26.191528: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72ebc6700 of size 9437184 next 1324\n",
      "2022-06-19 16:45:26.191531: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 72f4c6700 of size 13369344 next 1232\n",
      "2022-06-19 16:45:26.191533: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 730186700 of size 9437184 next 440\n",
      "2022-06-19 16:45:26.191536: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 730a86700 of size 9437184 next 346\n",
      "2022-06-19 16:45:26.191538: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 731386700 of size 2359296 next 334\n",
      "2022-06-19 16:45:26.191540: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7315c6700 of size 9437184 next 328\n",
      "2022-06-19 16:45:26.191543: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 731ec6700 of size 2359296 next 329\n",
      "2022-06-19 16:45:26.191545: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 732106700 of size 2359296 next 293\n",
      "2022-06-19 16:45:26.191547: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 732346700 of size 2359296 next 341\n",
      "2022-06-19 16:45:26.191549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 732586700 of size 2359296 next 285\n",
      "2022-06-19 16:45:26.191552: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7327c6700 of size 16515072 next 274\n",
      "2022-06-19 16:45:26.191554: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 733786700 of size 2359296 next 275\n",
      "2022-06-19 16:45:26.191557: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7339c6700 of size 2359296 next 278\n",
      "2022-06-19 16:45:26.191559: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 733c06700 of size 2359296 next 276\n",
      "2022-06-19 16:45:26.191561: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 733e46700 of size 2359296 next 404\n",
      "2022-06-19 16:45:26.191564: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 734086700 of size 2359296 next 394\n",
      "2022-06-19 16:45:26.191566: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7342c6700 of size 9437184 next 309\n",
      "2022-06-19 16:45:26.191568: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 734bc6700 of size 2359296 next 1335\n",
      "2022-06-19 16:45:26.191571: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 734e06700 of size 2359296 next 327\n",
      "2022-06-19 16:45:26.191573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 735046700 of size 2359296 next 467\n",
      "2022-06-19 16:45:26.191575: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 735286700 of size 2359296 next 307\n",
      "2022-06-19 16:45:26.191578: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7354c6700 of size 9437184 next 303\n",
      "2022-06-19 16:45:26.192174: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 735dc6700 of size 2359296 next 300\n",
      "2022-06-19 16:45:26.192183: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 736006700 of size 9437184 next 294\n",
      "2022-06-19 16:45:26.192185: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 736906700 of size 2359296 next 361\n",
      "2022-06-19 16:45:26.192188: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 736b46700 of size 9437184 next 359\n",
      "2022-06-19 16:45:26.192190: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 737446700 of size 2359296 next 356\n",
      "2022-06-19 16:45:26.192192: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 737686700 of size 2359296 next 353\n",
      "2022-06-19 16:45:26.192195: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7378c6700 of size 2359296 next 350\n",
      "2022-06-19 16:45:26.192197: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 737b06700 of size 2359296 next 351\n",
      "2022-06-19 16:45:26.192199: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 737d46700 of size 2359296 next 435\n",
      "2022-06-19 16:45:26.192201: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 737f86700 of size 2359296 next 432\n",
      "2022-06-19 16:45:26.192204: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7381c6700 of size 9437184 next 340\n",
      "2022-06-19 16:45:26.192206: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 738ac6700 of size 2424832 next 1325\n",
      "2022-06-19 16:45:26.192209: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 738d16700 of size 9437184 next 1240\n",
      "2022-06-19 16:45:26.192211: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 739616700 of size 2359296 next 1245\n",
      "2022-06-19 16:45:26.192213: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 739856700 of size 2359296 next 1254\n",
      "2022-06-19 16:45:26.192216: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 739a96700 of size 2359296 next 1275\n",
      "2022-06-19 16:45:26.192218: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 739cd6700 of size 9437184 next 1255\n",
      "2022-06-19 16:45:26.192220: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73a5d6700 of size 2359296 next 1256\n",
      "2022-06-19 16:45:26.192223: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73a816700 of size 2359296 next 1241\n",
      "2022-06-19 16:45:26.192225: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73aa56700 of size 9437184 next 1250\n",
      "2022-06-19 16:45:26.192227: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73b356700 of size 10289152 next 1318\n",
      "2022-06-19 16:45:26.192230: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73bd26700 of size 1572864 next 1242\n",
      "2022-06-19 16:45:26.192232: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73bea6700 of size 2359296 next 1262\n",
      "2022-06-19 16:45:26.192235: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73c0e6700 of size 9437184 next 1267\n",
      "2022-06-19 16:45:26.192237: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73c9e6700 of size 50331648 next 1328\n",
      "2022-06-19 16:45:26.192239: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 73f9e6700 of size 50331648 next 1333\n",
      "2022-06-19 16:45:26.192242: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7429e6700 of size 50331648 next 1295\n",
      "2022-06-19 16:45:26.192244: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7459e6700 of size 53524480 next 469\n",
      "2022-06-19 16:45:26.192246: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 748cf1f00 of size 93763584 next 497\n",
      "2022-06-19 16:45:26.192249: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74e65d700 of size 1572864 next 489\n",
      "2022-06-19 16:45:26.192251: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74e7dd700 of size 2359296 next 482\n",
      "2022-06-19 16:45:26.192555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74ea1d700 of size 2359296 next 481\n",
      "2022-06-19 16:45:26.192569: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74ec5d700 of size 2359296 next 478\n",
      "2022-06-19 16:45:26.192578: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74ee9d700 of size 2359296 next 492\n",
      "2022-06-19 16:45:26.192583: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74f0dd700 of size 2359296 next 498\n",
      "2022-06-19 16:45:26.192586: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74f31d700 of size 9437184 next 499\n",
      "2022-06-19 16:45:26.192588: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 74fc1d700 of size 9437184 next 502\n",
      "2022-06-19 16:45:26.192590: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75051d700 of size 2359296 next 506\n",
      "2022-06-19 16:45:26.192593: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75075d700 of size 2359296 next 508\n",
      "2022-06-19 16:45:26.192595: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75099d700 of size 2359296 next 511\n",
      "2022-06-19 16:45:26.192597: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 750bdd700 of size 2359296 next 513\n",
      "2022-06-19 16:45:26.192600: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 750e1d700 of size 9437184 next 517\n",
      "2022-06-19 16:45:26.192602: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75171d700 of size 9437184 next 519\n",
      "2022-06-19 16:45:26.192604: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75201d700 of size 2359296 next 524\n",
      "2022-06-19 16:45:26.192606: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75225d700 of size 2359296 next 526\n",
      "2022-06-19 16:45:26.192609: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75249d700 of size 2359296 next 528\n",
      "2022-06-19 16:45:26.192611: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7526dd700 of size 2359296 next 530\n",
      "2022-06-19 16:45:26.192613: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75291d700 of size 9437184 next 535\n",
      "2022-06-19 16:45:26.192615: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75321d700 of size 9437184 next 537\n",
      "2022-06-19 16:45:26.192618: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 753b1d700 of size 2359296 next 541\n",
      "2022-06-19 16:45:26.192620: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 753d5d700 of size 9437184 next 542\n",
      "2022-06-19 16:45:26.192622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75465d700 of size 2359296 next 544\n",
      "2022-06-19 16:45:26.192624: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75489d700 of size 2359296 next 546\n",
      "2022-06-19 16:45:26.192627: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 754add700 of size 2359296 next 548\n",
      "2022-06-19 16:45:26.192629: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 754d1d700 of size 9437184 next 552\n",
      "2022-06-19 16:45:26.192631: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75561d700 of size 9437184 next 555\n",
      "2022-06-19 16:45:26.192633: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 755f1d700 of size 2359296 next 559\n",
      "2022-06-19 16:45:26.192635: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75615d700 of size 2359296 next 561\n",
      "2022-06-19 16:45:26.192638: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75639d700 of size 2359296 next 563\n",
      "2022-06-19 16:45:26.192640: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7565dd700 of size 9437184 next 564\n",
      "2022-06-19 16:45:26.192642: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 756edd700 of size 2359296 next 566\n",
      "2022-06-19 16:45:26.192644: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75711d700 of size 9437184 next 570\n",
      "2022-06-19 16:45:26.192647: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 757a1d700 of size 9437184 next 572\n",
      "2022-06-19 16:45:26.192697: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75831d700 of size 2359296 next 577\n",
      "2022-06-19 16:45:26.192704: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75855d700 of size 2359296 next 579\n",
      "2022-06-19 16:45:26.192706: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75879d700 of size 2359296 next 581\n",
      "2022-06-19 16:45:26.192709: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7589dd700 of size 2359296 next 583\n",
      "2022-06-19 16:45:26.192711: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 758c1d700 of size 9437184 next 588\n",
      "2022-06-19 16:45:26.192713: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75951d700 of size 9437184 next 590\n",
      "2022-06-19 16:45:26.192716: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 759e1d700 of size 2359296 next 594\n",
      "2022-06-19 16:45:26.192718: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75a05d700 of size 2359296 next 598\n",
      "2022-06-19 16:45:26.192721: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75a29d700 of size 2359296 next 600\n",
      "2022-06-19 16:45:26.192723: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75a4dd700 of size 2359296 next 602\n",
      "2022-06-19 16:45:26.192726: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75a71d700 of size 2359296 next 604\n",
      "2022-06-19 16:45:26.192730: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75a95d700 of size 9437184 next 609\n",
      "2022-06-19 16:45:26.192733: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75b25d700 of size 9437184 next 611\n",
      "2022-06-19 16:45:26.192742: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75bb5d700 of size 2359296 next 615\n",
      "2022-06-19 16:45:26.192746: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75bd9d700 of size 2359296 next 617\n",
      "2022-06-19 16:45:26.192750: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75bfdd700 of size 2359296 next 620\n",
      "2022-06-19 16:45:26.192759: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75c21d700 of size 2359296 next 622\n",
      "2022-06-19 16:45:26.192764: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75c45d700 of size 9437184 next 626\n",
      "2022-06-19 16:45:26.192766: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75cd5d700 of size 9437184 next 628\n",
      "2022-06-19 16:45:26.192768: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75d65d700 of size 2359296 next 629\n",
      "2022-06-19 16:45:26.192770: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75d89d700 of size 2359296 next 633\n",
      "2022-06-19 16:45:26.192773: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75dadd700 of size 2359296 next 635\n",
      "2022-06-19 16:45:26.192775: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75dd1d700 of size 2359296 next 637\n",
      "2022-06-19 16:45:26.192777: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75df5d700 of size 2359296 next 639\n",
      "2022-06-19 16:45:26.192780: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75e19d700 of size 9437184 next 644\n",
      "2022-06-19 16:45:26.192782: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75ea9d700 of size 9437184 next 646\n",
      "2022-06-19 16:45:26.192784: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75f39d700 of size 2359296 next 650\n",
      "2022-06-19 16:45:26.192786: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75f5dd700 of size 2359296 next 651\n",
      "2022-06-19 16:45:26.192788: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75f81d700 of size 2359296 next 653\n",
      "2022-06-19 16:45:26.192791: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75fa5d700 of size 2359296 next 655\n",
      "2022-06-19 16:45:26.192793: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75fc9d700 of size 2359296 next 657\n",
      "2022-06-19 16:45:26.192795: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 75fedd700 of size 9437184 next 661\n",
      "2022-06-19 16:45:26.193712: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7607dd700 of size 9437184 next 664\n",
      "2022-06-19 16:45:26.193723: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7610dd700 of size 2359296 next 668\n",
      "2022-06-19 16:45:26.193726: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76131d700 of size 2359296 next 670\n",
      "2022-06-19 16:45:26.193729: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76155d700 of size 2359296 next 672\n",
      "2022-06-19 16:45:26.193731: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76179d700 of size 2359296 next 673\n",
      "2022-06-19 16:45:26.193733: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7619dd700 of size 2359296 next 675\n",
      "2022-06-19 16:45:26.193736: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 761c1d700 of size 9437184 next 679\n",
      "2022-06-19 16:45:26.193738: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76251d700 of size 9437184 next 681\n",
      "2022-06-19 16:45:26.193741: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 762e1d700 of size 65536 next 1235\n",
      "2022-06-19 16:45:26.193744: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 762e2d700 of size 65536 next 1319\n",
      "2022-06-19 16:45:26.193746: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 762e3d700 of size 65536 next 1223\n",
      "2022-06-19 16:45:26.193749: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 762e4d700 of size 65536 next 1265\n",
      "2022-06-19 16:45:26.193751: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 762e5d700 of size 65536 next 1218\n",
      "2022-06-19 16:45:26.193753: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 762e6d700 of size 1245184 next 1332\n",
      "2022-06-19 16:45:26.193756: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 762f9d700 of size 2359296 next 1327\n",
      "2022-06-19 16:45:26.193758: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7631dd700 of size 9437184 next 1321\n",
      "2022-06-19 16:45:26.193760: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 763add700 of size 9437184 next 1334\n",
      "2022-06-19 16:45:26.193762: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7643dd700 of size 9437184 next 1224\n",
      "2022-06-19 16:45:26.193765: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 764cdd700 of size 2359296 next 1257\n",
      "2022-06-19 16:45:26.193767: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 764f1d700 of size 9437184 next 1315\n",
      "2022-06-19 16:45:26.193769: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76581d700 of size 2359296 next 1261\n",
      "2022-06-19 16:45:26.193772: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 765a5d700 of size 2359296 next 1258\n",
      "2022-06-19 16:45:26.193774: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 765c9d700 of size 9437184 next 1316\n",
      "2022-06-19 16:45:26.193776: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76659d700 of size 2359296 next 1264\n",
      "2022-06-19 16:45:26.193778: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7667dd700 of size 9437184 next 1263\n",
      "2022-06-19 16:45:26.193781: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7670dd700 of size 9437184 next 1271\n",
      "2022-06-19 16:45:26.193783: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7679dd700 of size 2359296 next 1274\n",
      "2022-06-19 16:45:26.193785: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 767c1d700 of size 2359296 next 1317\n",
      "2022-06-19 16:45:26.193787: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 767e5d700 of size 2359296 next 1268\n",
      "2022-06-19 16:45:26.193790: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76809d700 of size 2359296 next 1272\n",
      "2022-06-19 16:45:26.193792: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7682dd700 of size 2359296 next 1273\n",
      "2022-06-19 16:45:26.194124: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76851d700 of size 2537472 next 690\n",
      "2022-06-19 16:45:26.194133: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 768788f00 of size 1572864 next 700\n",
      "2022-06-19 16:45:26.194136: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 768908f00 of size 2359296 next 713\n",
      "2022-06-19 16:45:26.194138: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 768b48f00 of size 2359296 next 715\n",
      "2022-06-19 16:45:26.194141: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 768d88f00 of size 2359296 next 717\n",
      "2022-06-19 16:45:26.194143: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 768fc8f00 of size 2359296 next 719\n",
      "2022-06-19 16:45:26.194146: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 769208f00 of size 9437184 next 723\n",
      "2022-06-19 16:45:26.194148: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 769b08f00 of size 9437184 next 725\n",
      "2022-06-19 16:45:26.194150: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76a408f00 of size 2359296 next 729\n",
      "2022-06-19 16:45:26.194153: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76a648f00 of size 2359296 next 731\n",
      "2022-06-19 16:45:26.194155: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76a888f00 of size 2359296 next 733\n",
      "2022-06-19 16:45:26.194157: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76aac8f00 of size 2359296 next 735\n",
      "2022-06-19 16:45:26.194159: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76ad08f00 of size 9437184 next 739\n",
      "2022-06-19 16:45:26.194162: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76b608f00 of size 9437184 next 741\n",
      "2022-06-19 16:45:26.194164: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76bf08f00 of size 2359296 next 745\n",
      "2022-06-19 16:45:26.194166: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76c148f00 of size 2359296 next 747\n",
      "2022-06-19 16:45:26.194168: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76c388f00 of size 2359296 next 749\n",
      "2022-06-19 16:45:26.194171: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76c5c8f00 of size 2359296 next 751\n",
      "2022-06-19 16:45:26.194173: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76c808f00 of size 9437184 next 755\n",
      "2022-06-19 16:45:26.194175: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76d108f00 of size 9437184 next 757\n",
      "2022-06-19 16:45:26.194177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76da08f00 of size 2359296 next 761\n",
      "2022-06-19 16:45:26.194180: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76dc48f00 of size 2359296 next 763\n",
      "2022-06-19 16:45:26.194182: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76de88f00 of size 2359296 next 765\n",
      "2022-06-19 16:45:26.194184: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76e0c8f00 of size 2359296 next 767\n",
      "2022-06-19 16:45:26.194186: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76e308f00 of size 9437184 next 771\n",
      "2022-06-19 16:45:26.194189: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76ec08f00 of size 9437184 next 773\n",
      "2022-06-19 16:45:26.194191: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76f508f00 of size 2359296 next 777\n",
      "2022-06-19 16:45:26.194193: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76f748f00 of size 2359296 next 779\n",
      "2022-06-19 16:45:26.194195: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76f988f00 of size 2359296 next 781\n",
      "2022-06-19 16:45:26.194198: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76fbc8f00 of size 2359296 next 783\n",
      "2022-06-19 16:45:26.194200: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 76fe08f00 of size 9437184 next 787\n",
      "2022-06-19 16:45:26.194776: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 770708f00 of size 9437184 next 789\n",
      "2022-06-19 16:45:26.194785: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 771008f00 of size 2359296 next 793\n",
      "2022-06-19 16:45:26.194788: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 771248f00 of size 2359296 next 795\n",
      "2022-06-19 16:45:26.194790: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 771488f00 of size 2359296 next 797\n",
      "2022-06-19 16:45:26.194792: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7716c8f00 of size 2359296 next 799\n",
      "2022-06-19 16:45:26.194795: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 771908f00 of size 9437184 next 803\n",
      "2022-06-19 16:45:26.194797: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 772208f00 of size 9437184 next 805\n",
      "2022-06-19 16:45:26.194800: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 772b08f00 of size 2359296 next 809\n",
      "2022-06-19 16:45:26.194802: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 772d48f00 of size 2359296 next 811\n",
      "2022-06-19 16:45:26.194804: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 772f88f00 of size 2359296 next 813\n",
      "2022-06-19 16:45:26.194806: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7731c8f00 of size 2359296 next 815\n",
      "2022-06-19 16:45:26.194809: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 773408f00 of size 9437184 next 819\n",
      "2022-06-19 16:45:26.194811: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 773d08f00 of size 9437184 next 821\n",
      "2022-06-19 16:45:26.194813: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 774608f00 of size 2359296 next 825\n",
      "2022-06-19 16:45:26.194815: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 774848f00 of size 2359296 next 827\n",
      "2022-06-19 16:45:26.194818: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 774a88f00 of size 2359296 next 829\n",
      "2022-06-19 16:45:26.194820: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 774cc8f00 of size 2359296 next 831\n",
      "2022-06-19 16:45:26.194822: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 774f08f00 of size 9437184 next 835\n",
      "2022-06-19 16:45:26.194824: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 775808f00 of size 9437184 next 837\n",
      "2022-06-19 16:45:26.194827: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 776108f00 of size 2359296 next 841\n",
      "2022-06-19 16:45:26.194829: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 776348f00 of size 2359296 next 843\n",
      "2022-06-19 16:45:26.194831: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 776588f00 of size 2359296 next 845\n",
      "2022-06-19 16:45:26.194892: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7767c8f00 of size 2359296 next 847\n",
      "2022-06-19 16:45:26.194897: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 776a08f00 of size 9437184 next 851\n",
      "2022-06-19 16:45:26.194900: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 777308f00 of size 9437184 next 853\n",
      "2022-06-19 16:45:26.194902: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 777c08f00 of size 2359296 next 857\n",
      "2022-06-19 16:45:26.194904: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 777e48f00 of size 2359296 next 859\n",
      "2022-06-19 16:45:26.194907: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 778088f00 of size 2359296 next 861\n",
      "2022-06-19 16:45:26.194910: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7782c8f00 of size 2359296 next 863\n",
      "2022-06-19 16:45:26.194912: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 778508f00 of size 9437184 next 867\n",
      "2022-06-19 16:45:26.194914: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 778e08f00 of size 9437184 next 869\n",
      "2022-06-19 16:45:26.194916: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 779708f00 of size 2359296 next 873\n",
      "2022-06-19 16:45:26.195413: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 779948f00 of size 2359296 next 875\n",
      "2022-06-19 16:45:26.195421: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 779b88f00 of size 2359296 next 877\n",
      "2022-06-19 16:45:26.195424: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 779dc8f00 of size 2359296 next 879\n",
      "2022-06-19 16:45:26.195426: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77a008f00 of size 9437184 next 883\n",
      "2022-06-19 16:45:26.195429: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77a908f00 of size 9437184 next 885\n",
      "2022-06-19 16:45:26.195431: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77b208f00 of size 2359296 next 889\n",
      "2022-06-19 16:45:26.195433: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77b448f00 of size 2359296 next 891\n",
      "2022-06-19 16:45:26.195436: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77b688f00 of size 2359296 next 893\n",
      "2022-06-19 16:45:26.195438: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77b8c8f00 of size 2359296 next 895\n",
      "2022-06-19 16:45:26.195440: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77bb08f00 of size 9437184 next 899\n",
      "2022-06-19 16:45:26.195442: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77c408f00 of size 9437184 next 901\n",
      "2022-06-19 16:45:26.195445: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77cd08f00 of size 2359296 next 905\n",
      "2022-06-19 16:45:26.195447: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77cf48f00 of size 9437184 next 1220\n",
      "2022-06-19 16:45:26.195449: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77d848f00 of size 2359296 next 1337\n",
      "2022-06-19 16:45:26.195452: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77da88f00 of size 11796480 next 1330\n",
      "2022-06-19 16:45:26.195455: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77e5c8f00 of size 11796480 next 324\n",
      "2022-06-19 16:45:26.195457: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77f108f00 of size 2359296 next 319\n",
      "2022-06-19 16:45:26.195459: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77f348f00 of size 2359296 next 317\n",
      "2022-06-19 16:45:26.195462: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77f588f00 of size 9437184 next 313\n",
      "2022-06-19 16:45:26.195464: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 77fe88f00 of size 2359296 next 400\n",
      "2022-06-19 16:45:26.195466: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7800c8f00 of size 2359296 next 397\n",
      "2022-06-19 16:45:26.195469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 780308f00 of size 2359296 next 391\n",
      "2022-06-19 16:45:26.195471: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 780548f00 of size 2359296 next 389\n",
      "2022-06-19 16:45:26.195473: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 780788f00 of size 2359296 next 399\n",
      "2022-06-19 16:45:26.195475: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7809c8f00 of size 2359296 next 387\n",
      "2022-06-19 16:45:26.195478: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 780c08f00 of size 9437184 next 385\n",
      "2022-06-19 16:45:26.195480: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 781508f00 of size 9437184 next 383\n",
      "2022-06-19 16:45:26.195482: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 781e08f00 of size 2359296 next 418\n",
      "2022-06-19 16:45:26.195484: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 782048f00 of size 2359296 next 411\n",
      "2022-06-19 16:45:26.195487: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 782288f00 of size 2359296 next 444\n",
      "2022-06-19 16:45:26.195489: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7824c8f00 of size 4110336 next 909\n",
      "2022-06-19 16:45:26.195976: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7828b4700 of size 1572864 next 910\n",
      "2022-06-19 16:45:26.195984: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 782a34700 of size 2359296 next 914\n",
      "2022-06-19 16:45:26.195986: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 782c74700 of size 2359296 next 916\n",
      "2022-06-19 16:45:26.195989: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 782eb4700 of size 2359296 next 918\n",
      "2022-06-19 16:45:26.195991: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7830f4700 of size 2359296 next 920\n",
      "2022-06-19 16:45:26.195994: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 783334700 of size 9437184 next 924\n",
      "2022-06-19 16:45:26.195996: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 783c34700 of size 9437184 next 925\n",
      "2022-06-19 16:45:26.195999: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784534700 of size 3072 next 926\n",
      "2022-06-19 16:45:26.196001: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784535300 of size 3072 next 927\n",
      "2022-06-19 16:45:26.196003: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784535f00 of size 3072 next 928\n",
      "2022-06-19 16:45:26.196006: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784536b00 of size 2359296 next 929\n",
      "2022-06-19 16:45:26.196008: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784776b00 of size 3072 next 930\n",
      "2022-06-19 16:45:26.196010: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784777700 of size 2359296 next 931\n",
      "2022-06-19 16:45:26.196012: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7849b7700 of size 3072 next 932\n",
      "2022-06-19 16:45:26.196015: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7849b8300 of size 2359296 next 933\n",
      "2022-06-19 16:45:26.196017: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784bf8300 of size 3072 next 934\n",
      "2022-06-19 16:45:26.196019: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784bf8f00 of size 2359296 next 935\n",
      "2022-06-19 16:45:26.196022: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784e38f00 of size 3072 next 936\n",
      "2022-06-19 16:45:26.196024: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784e39b00 of size 3072 next 937\n",
      "2022-06-19 16:45:26.196026: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784e3a700 of size 3072 next 938\n",
      "2022-06-19 16:45:26.196028: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 784e3b300 of size 9437184 next 939\n",
      "2022-06-19 16:45:26.196031: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78573b300 of size 12288 next 940\n",
      "2022-06-19 16:45:26.196033: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78573e300 of size 9437184 next 941\n",
      "2022-06-19 16:45:26.196035: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78603e300 of size 3072 next 942\n",
      "2022-06-19 16:45:26.196038: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78603ef00 of size 3072 next 943\n",
      "2022-06-19 16:45:26.196040: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78603fb00 of size 3072 next 944\n",
      "2022-06-19 16:45:26.196042: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786040700 of size 2359296 next 945\n",
      "2022-06-19 16:45:26.196044: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786280700 of size 3072 next 946\n",
      "2022-06-19 16:45:26.196047: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786281300 of size 2359296 next 947\n",
      "2022-06-19 16:45:26.196049: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7864c1300 of size 3072 next 948\n",
      "2022-06-19 16:45:26.196051: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7864c1f00 of size 2359296 next 949\n",
      "2022-06-19 16:45:26.196053: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786701f00 of size 3072 next 950\n",
      "2022-06-19 16:45:26.196625: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786702b00 of size 2359296 next 951\n",
      "2022-06-19 16:45:26.196633: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786942b00 of size 3072 next 952\n",
      "2022-06-19 16:45:26.196635: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786943700 of size 3072 next 953\n",
      "2022-06-19 16:45:26.196638: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786944300 of size 3072 next 954\n",
      "2022-06-19 16:45:26.196640: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 786944f00 of size 9437184 next 955\n",
      "2022-06-19 16:45:26.196642: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787244f00 of size 12288 next 956\n",
      "2022-06-19 16:45:26.196645: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787247f00 of size 9437184 next 957\n",
      "2022-06-19 16:45:26.196647: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787b47f00 of size 3072 next 958\n",
      "2022-06-19 16:45:26.196649: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787b48b00 of size 3072 next 959\n",
      "2022-06-19 16:45:26.196652: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787b49700 of size 3072 next 960\n",
      "2022-06-19 16:45:26.196654: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787b4a300 of size 2359296 next 961\n",
      "2022-06-19 16:45:26.196656: I tensorflow/core/common_runtime/bfc_"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[32,512,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/layer_0/dropout_1/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_181233]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb Cell 62'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining model with \u001b[39m\u001b[39m{\u001b[39;00mtfhub_encoder\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m classifier_model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_ds, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=2'>3</a>\u001b[0m                                batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=3'>4</a>\u001b[0m                                epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=4'>5</a>\u001b[0m                                validation_data\u001b[39m=\u001b[39;49mvalid_ds, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=5'>6</a>\u001b[0m                                verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000072vscode-remote?line=6'>7</a>\u001b[0m                                callbacks\u001b[39m=\u001b[39;49m[callback_es, callback_mcp])\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/bert_finetune/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,512,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/layer_0/dropout_1/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_181233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "allocator.cc:1083] InUse at 787d8a300 of size 3072 next 962\n",
      "2022-06-19 16:45:26.196658: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787d8af00 of size 2359296 next 963\n",
      "2022-06-19 16:45:26.196661: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787fcaf00 of size 3072 next 964\n",
      "2022-06-19 16:45:26.196663: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 787fcbb00 of size 2359296 next 965\n",
      "2022-06-19 16:45:26.196665: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78820bb00 of size 3072 next 966\n",
      "2022-06-19 16:45:26.196667: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78820c700 of size 2359296 next 967\n",
      "2022-06-19 16:45:26.196670: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78844c700 of size 3072 next 968\n",
      "2022-06-19 16:45:26.196672: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78844d300 of size 3072 next 969\n",
      "2022-06-19 16:45:26.196674: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78844df00 of size 3072 next 970\n",
      "2022-06-19 16:45:26.196676: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78844eb00 of size 9437184 next 971\n",
      "2022-06-19 16:45:26.196679: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 788d4eb00 of size 12288 next 972\n",
      "2022-06-19 16:45:26.196681: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 788d51b00 of size 9437184 next 973\n",
      "2022-06-19 16:45:26.196684: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789651b00 of size 3072 next 974\n",
      "2022-06-19 16:45:26.196686: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789652700 of size 3072 next 975\n",
      "2022-06-19 16:45:26.196688: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789653300 of size 3072 next 976\n",
      "2022-06-19 16:45:26.196690: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789653f00 of size 2359296 next 977\n",
      "2022-06-19 16:45:26.196693: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789893f00 of size 3072 next 978\n",
      "2022-06-19 16:45:26.196695: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789894b00 of size 2359296 next 979\n",
      "2022-06-19 16:45:26.196697: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789ad4b00 of size 3072 next 980\n",
      "2022-06-19 16:45:26.196699: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789ad5700 of size 2359296 next 981\n",
      "2022-06-19 16:45:26.196702: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789d15700 of size 3072 next 982\n",
      "2022-06-19 16:45:26.196971: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789d16300 of size 2359296 next 983\n",
      "2022-06-19 16:45:26.196981: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789f56300 of size 3072 next 984\n",
      "2022-06-19 16:45:26.196984: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789f56f00 of size 3072 next 985\n",
      "2022-06-19 16:45:26.196986: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789f57b00 of size 3072 next 986\n",
      "2022-06-19 16:45:26.196989: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 789f58700 of size 9437184 next 987\n",
      "2022-06-19 16:45:26.196991: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78a858700 of size 12288 next 988\n",
      "2022-06-19 16:45:26.196994: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78a85b700 of size 9437184 next 989\n",
      "2022-06-19 16:45:26.196996: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b15b700 of size 3072 next 990\n",
      "2022-06-19 16:45:26.196998: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b15c300 of size 3072 next 991\n",
      "2022-06-19 16:45:26.197000: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b15cf00 of size 3072 next 992\n",
      "2022-06-19 16:45:26.197003: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b15db00 of size 2359296 next 993\n",
      "2022-06-19 16:45:26.197005: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b39db00 of size 3072 next 994\n",
      "2022-06-19 16:45:26.197007: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b39e700 of size 2359296 next 995\n",
      "2022-06-19 16:45:26.197010: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b5de700 of size 3072 next 996\n",
      "2022-06-19 16:45:26.197012: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b5df300 of size 2359296 next 997\n",
      "2022-06-19 16:45:26.197014: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b81f300 of size 3072 next 998\n",
      "2022-06-19 16:45:26.197016: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78b81ff00 of size 2359296 next 999\n",
      "2022-06-19 16:45:26.197019: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ba5ff00 of size 3072 next 1000\n",
      "2022-06-19 16:45:26.197021: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ba60b00 of size 3072 next 1001\n",
      "2022-06-19 16:45:26.197023: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ba61700 of size 3072 next 1002\n",
      "2022-06-19 16:45:26.197025: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ba62300 of size 9437184 next 1003\n",
      "2022-06-19 16:45:26.197028: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78c362300 of size 12288 next 1004\n",
      "2022-06-19 16:45:26.197030: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78c365300 of size 9437184 next 1005\n",
      "2022-06-19 16:45:26.197032: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78cc65300 of size 3072 next 1006\n",
      "2022-06-19 16:45:26.197034: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78cc65f00 of size 3072 next 1007\n",
      "2022-06-19 16:45:26.197037: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78cc66b00 of size 3072 next 1008\n",
      "2022-06-19 16:45:26.197039: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78cc67700 of size 2359296 next 1009\n",
      "2022-06-19 16:45:26.197041: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78cea7700 of size 3072 next 1010\n",
      "2022-06-19 16:45:26.197043: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78cea8300 of size 2359296 next 1011\n",
      "2022-06-19 16:45:26.197046: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d0e8300 of size 3072 next 1012\n",
      "2022-06-19 16:45:26.197048: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d0e8f00 of size 2359296 next 1013\n",
      "2022-06-19 16:45:26.197050: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d328f00 of size 3072 next 1014\n",
      "2022-06-19 16:45:26.197772: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d329b00 of size 2359296 next 1015\n",
      "2022-06-19 16:45:26.197781: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d569b00 of size 3072 next 1016\n",
      "2022-06-19 16:45:26.197784: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d56a700 of size 3072 next 1017\n",
      "2022-06-19 16:45:26.197787: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d56b300 of size 3072 next 1018\n",
      "2022-06-19 16:45:26.197789: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78d56bf00 of size 9437184 next 1019\n",
      "2022-06-19 16:45:26.197791: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78de6bf00 of size 12288 next 1020\n",
      "2022-06-19 16:45:26.197794: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78de6ef00 of size 9437184 next 1021\n",
      "2022-06-19 16:45:26.197796: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78e76ef00 of size 3072 next 1022\n",
      "2022-06-19 16:45:26.197798: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78e76fb00 of size 3072 next 1023\n",
      "2022-06-19 16:45:26.197801: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78e770700 of size 3072 next 1024\n",
      "2022-06-19 16:45:26.197803: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78e771300 of size 2359296 next 1025\n",
      "2022-06-19 16:45:26.197805: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78e9b1300 of size 3072 next 1026\n",
      "2022-06-19 16:45:26.197808: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78e9b1f00 of size 2359296 next 1027\n",
      "2022-06-19 16:45:26.197810: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ebf1f00 of size 3072 next 1028\n",
      "2022-06-19 16:45:26.197812: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ebf2b00 of size 2359296 next 1029\n",
      "2022-06-19 16:45:26.197814: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ee32b00 of size 3072 next 1030\n",
      "2022-06-19 16:45:26.197817: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78ee33700 of size 2359296 next 1031\n",
      "2022-06-19 16:45:26.197819: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78f073700 of size 3072 next 1032\n",
      "2022-06-19 16:45:26.197821: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78f074300 of size 3072 next 1033\n",
      "2022-06-19 16:45:26.197824: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78f074f00 of size 3072 next 1034\n",
      "2022-06-19 16:45:26.197826: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78f075b00 of size 9437184 next 1035\n",
      "2022-06-19 16:45:26.197828: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78f975b00 of size 12288 next 1036\n",
      "2022-06-19 16:45:26.197830: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 78f978b00 of size 9437184 next 1037\n",
      "2022-06-19 16:45:26.197833: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 790278b00 of size 3072 next 1038\n",
      "2022-06-19 16:45:26.197835: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 790279700 of size 3072 next 1039\n",
      "2022-06-19 16:45:26.197837: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79027a300 of size 3072 next 1040\n",
      "2022-06-19 16:45:26.197839: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79027af00 of size 2359296 next 1041\n",
      "2022-06-19 16:45:26.197842: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7904baf00 of size 3072 next 1042\n",
      "2022-06-19 16:45:26.197844: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7904bbb00 of size 2359296 next 1043\n",
      "2022-06-19 16:45:26.197846: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7906fbb00 of size 3072 next 1044\n",
      "2022-06-19 16:45:26.197848: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7906fc700 of size 2359296 next 1045\n",
      "2022-06-19 16:45:26.197851: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79093c700 of size 3072 next 1046\n",
      "2022-06-19 16:45:26.198393: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79093d300 of size 2359296 next 1047\n",
      "2022-06-19 16:45:26.198401: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 790b7d300 of size 3072 next 1048\n",
      "2022-06-19 16:45:26.198403: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 790b7df00 of size 3072 next 1049\n",
      "2022-06-19 16:45:26.198406: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 790b7eb00 of size 3072 next 1050\n",
      "2022-06-19 16:45:26.198408: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 790b7f700 of size 9437184 next 1051\n",
      "2022-06-19 16:45:26.198411: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79147f700 of size 12288 next 1052\n",
      "2022-06-19 16:45:26.198413: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791482700 of size 9437184 next 1053\n",
      "2022-06-19 16:45:26.198415: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791d82700 of size 3072 next 1054\n",
      "2022-06-19 16:45:26.198418: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791d83300 of size 3072 next 1055\n",
      "2022-06-19 16:45:26.198420: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791d83f00 of size 3072 next 1056\n",
      "2022-06-19 16:45:26.198424: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791d84b00 of size 2359296 next 1057\n",
      "2022-06-19 16:45:26.198427: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791fc4b00 of size 3072 next 1058\n",
      "2022-06-19 16:45:26.198486: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 791fc5700 of size 2359296 next 1059\n",
      "2022-06-19 16:45:26.198495: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792205700 of size 3072 next 1060\n",
      "2022-06-19 16:45:26.198497: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792206300 of size 2359296 next 1061\n",
      "2022-06-19 16:45:26.198500: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792446300 of size 3072 next 1062\n",
      "2022-06-19 16:45:26.198502: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792446f00 of size 2359296 next 1063\n",
      "2022-06-19 16:45:26.198505: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792686f00 of size 3072 next 1064\n",
      "2022-06-19 16:45:26.198507: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792687b00 of size 3072 next 1065\n",
      "2022-06-19 16:45:26.198509: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792688700 of size 3072 next 1066\n",
      "2022-06-19 16:45:26.198511: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792689300 of size 9437184 next 1067\n",
      "2022-06-19 16:45:26.198514: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792f89300 of size 12288 next 1068\n",
      "2022-06-19 16:45:26.198516: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 792f8c300 of size 9437184 next 1069\n",
      "2022-06-19 16:45:26.198519: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79388c300 of size 3072 next 1070\n",
      "2022-06-19 16:45:26.198521: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79388cf00 of size 3072 next 1071\n",
      "2022-06-19 16:45:26.198523: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79388db00 of size 3072 next 1072\n",
      "2022-06-19 16:45:26.198525: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79388e700 of size 2359296 next 1073\n",
      "2022-06-19 16:45:26.198528: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 793ace700 of size 3072 next 1074\n",
      "2022-06-19 16:45:26.198530: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 793acf300 of size 2359296 next 1075\n",
      "2022-06-19 16:45:26.198532: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 793d0f300 of size 3072 next 1076\n",
      "2022-06-19 16:45:26.198534: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 793d0ff00 of size 2359296 next 1077\n",
      "2022-06-19 16:45:26.198536: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 793f4ff00 of size 3072 next 1078\n",
      "2022-06-19 16:45:26.199120: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 793f50b00 of size 2359296 next 1079\n",
      "2022-06-19 16:45:26.199131: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 794190b00 of size 3072 next 1080\n",
      "2022-06-19 16:45:26.199134: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 794191700 of size 3072 next 1081\n",
      "2022-06-19 16:45:26.199137: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 794192300 of size 3072 next 1082\n",
      "2022-06-19 16:45:26.199139: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 794192f00 of size 9437184 next 1083\n",
      "2022-06-19 16:45:26.199142: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 794a92f00 of size 12288 next 1084\n",
      "2022-06-19 16:45:26.199144: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 794a95f00 of size 9437184 next 1085\n",
      "2022-06-19 16:45:26.199146: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795395f00 of size 3072 next 1086\n",
      "2022-06-19 16:45:26.199149: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795396b00 of size 3072 next 1087\n",
      "2022-06-19 16:45:26.199151: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795397700 of size 3072 next 1088\n",
      "2022-06-19 16:45:26.199153: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795398300 of size 2359296 next 1089\n",
      "2022-06-19 16:45:26.199155: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7955d8300 of size 3072 next 1090\n",
      "2022-06-19 16:45:26.199158: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7955d8f00 of size 2359296 next 1091\n",
      "2022-06-19 16:45:26.199160: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795818f00 of size 3072 next 1092\n",
      "2022-06-19 16:45:26.199162: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795819b00 of size 2359296 next 1093\n",
      "2022-06-19 16:45:26.199165: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795a59b00 of size 3072 next 1094\n",
      "2022-06-19 16:45:26.199167: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795a5a700 of size 2359296 next 1095\n",
      "2022-06-19 16:45:26.199169: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795c9a700 of size 3072 next 1096\n",
      "2022-06-19 16:45:26.199171: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795c9b300 of size 3072 next 1097\n",
      "2022-06-19 16:45:26.199174: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795c9bf00 of size 3072 next 1098\n",
      "2022-06-19 16:45:26.199176: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 795c9cb00 of size 9437184 next 1099\n",
      "2022-06-19 16:45:26.199178: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79659cb00 of size 12288 next 1100\n",
      "2022-06-19 16:45:26.199181: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79659fb00 of size 9437184 next 1101\n",
      "2022-06-19 16:45:26.199183: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 796e9fb00 of size 3072 next 1102\n",
      "2022-06-19 16:45:26.199185: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 796ea0700 of size 3072 next 1103\n",
      "2022-06-19 16:45:26.199187: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 796ea1300 of size 3072 next 1104\n",
      "2022-06-19 16:45:26.199190: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 796ea1f00 of size 2359296 next 1105\n",
      "2022-06-19 16:45:26.199192: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e1f00 of size 3072 next 1106\n",
      "2022-06-19 16:45:26.199194: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e2b00 of size 6144 next 1107\n",
      "2022-06-19 16:45:26.199197: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4300 of size 256 next 1108\n",
      "2022-06-19 16:45:26.199199: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4400 of size 256 next 1109\n",
      "2022-06-19 16:45:26.199201: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4500 of size 256 next 1110\n",
      "2022-06-19 16:45:26.199806: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4600 of size 256 next 1111\n",
      "2022-06-19 16:45:26.199875: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4700 of size 256 next 1112\n",
      "2022-06-19 16:45:26.199878: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4800 of size 256 next 1113\n",
      "2022-06-19 16:45:26.199881: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4900 of size 256 next 1114\n",
      "2022-06-19 16:45:26.199883: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4a00 of size 256 next 1115\n",
      "2022-06-19 16:45:26.199885: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4b00 of size 256 next 1116\n",
      "2022-06-19 16:45:26.199888: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4c00 of size 256 next 1117\n",
      "2022-06-19 16:45:26.199890: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4d00 of size 256 next 1118\n",
      "2022-06-19 16:45:26.199892: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4e00 of size 256 next 1119\n",
      "2022-06-19 16:45:26.199895: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e4f00 of size 256 next 1120\n",
      "2022-06-19 16:45:26.199897: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5000 of size 256 next 1121\n",
      "2022-06-19 16:45:26.199899: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5100 of size 256 next 1122\n",
      "2022-06-19 16:45:26.199901: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5200 of size 256 next 1123\n",
      "2022-06-19 16:45:26.199904: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5300 of size 256 next 1124\n",
      "2022-06-19 16:45:26.199906: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5400 of size 256 next 1125\n",
      "2022-06-19 16:45:26.199908: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5500 of size 256 next 1126\n",
      "2022-06-19 16:45:26.199910: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5600 of size 256 next 1127\n",
      "2022-06-19 16:45:26.199913: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5700 of size 256 next 1128\n",
      "2022-06-19 16:45:26.199915: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5800 of size 256 next 1129\n",
      "2022-06-19 16:45:26.199917: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5900 of size 256 next 1130\n",
      "2022-06-19 16:45:26.199919: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5a00 of size 256 next 1131\n",
      "2022-06-19 16:45:26.199922: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5b00 of size 256 next 1132\n",
      "2022-06-19 16:45:26.199924: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5c00 of size 256 next 1133\n",
      "2022-06-19 16:45:26.199926: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5d00 of size 256 next 1134\n",
      "2022-06-19 16:45:26.199928: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5e00 of size 256 next 1135\n",
      "2022-06-19 16:45:26.199931: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e5f00 of size 256 next 1136\n",
      "2022-06-19 16:45:26.199933: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6000 of size 256 next 1137\n",
      "2022-06-19 16:45:26.199991: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6100 of size 256 next 1138\n",
      "2022-06-19 16:45:26.199994: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6200 of size 256 next 1139\n",
      "2022-06-19 16:45:26.199996: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6300 of size 256 next 1140\n",
      "2022-06-19 16:45:26.199998: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6400 of size 256 next 1141\n",
      "2022-06-19 16:45:26.200001: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6500 of size 256 next 1142\n",
      "2022-06-19 16:45:26.200241: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6600 of size 256 next 1143\n",
      "2022-06-19 16:45:26.200254: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6700 of size 256 next 1144\n",
      "2022-06-19 16:45:26.200259: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6800 of size 256 next 1145\n",
      "2022-06-19 16:45:26.200263: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6900 of size 256 next 1146\n",
      "2022-06-19 16:45:26.200269: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6a00 of size 256 next 1147\n",
      "2022-06-19 16:45:26.200277: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6b00 of size 256 next 1148\n",
      "2022-06-19 16:45:26.200281: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6c00 of size 256 next 1149\n",
      "2022-06-19 16:45:26.200284: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6d00 of size 256 next 1150\n",
      "2022-06-19 16:45:26.200291: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6e00 of size 256 next 1151\n",
      "2022-06-19 16:45:26.200297: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e6f00 of size 256 next 1152\n",
      "2022-06-19 16:45:26.200300: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7000 of size 256 next 1153\n",
      "2022-06-19 16:45:26.200303: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7100 of size 256 next 1154\n",
      "2022-06-19 16:45:26.200305: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7200 of size 256 next 1155\n",
      "2022-06-19 16:45:26.200307: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7300 of size 256 next 1156\n",
      "2022-06-19 16:45:26.200310: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7400 of size 256 next 1157\n",
      "2022-06-19 16:45:26.200312: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7500 of size 256 next 1158\n",
      "2022-06-19 16:45:26.200314: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7600 of size 256 next 1159\n",
      "2022-06-19 16:45:26.200316: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7700 of size 256 next 1160\n",
      "2022-06-19 16:45:26.200319: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7800 of size 256 next 1161\n",
      "2022-06-19 16:45:26.200321: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7900 of size 256 next 1162\n",
      "2022-06-19 16:45:26.200323: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7a00 of size 256 next 1163\n",
      "2022-06-19 16:45:26.200326: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7b00 of size 256 next 1164\n",
      "2022-06-19 16:45:26.200328: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7c00 of size 256 next 1165\n",
      "2022-06-19 16:45:26.200330: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7d00 of size 256 next 1166\n",
      "2022-06-19 16:45:26.200332: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7e00 of size 256 next 1167\n",
      "2022-06-19 16:45:26.200335: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e7f00 of size 256 next 1168\n",
      "2022-06-19 16:45:26.200337: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8000 of size 256 next 1169\n",
      "2022-06-19 16:45:26.200339: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8100 of size 256 next 1170\n",
      "2022-06-19 16:45:26.200341: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8200 of size 256 next 1171\n",
      "2022-06-19 16:45:26.200343: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8300 of size 256 next 1172\n",
      "2022-06-19 16:45:26.200346: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8400 of size 256 next 1173\n",
      "2022-06-19 16:45:26.200348: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8500 of size 256 next 1174\n",
      "2022-06-19 16:45:26.200984: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8600 of size 256 next 1175\n",
      "2022-06-19 16:45:26.200992: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8700 of size 256 next 1176\n",
      "2022-06-19 16:45:26.200995: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8800 of size 256 next 1177\n",
      "2022-06-19 16:45:26.200997: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8900 of size 256 next 1178\n",
      "2022-06-19 16:45:26.201000: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8a00 of size 256 next 1179\n",
      "2022-06-19 16:45:26.201002: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8b00 of size 256 next 1180\n",
      "2022-06-19 16:45:26.201004: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8c00 of size 256 next 1181\n",
      "2022-06-19 16:45:26.201007: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8d00 of size 256 next 1182\n",
      "2022-06-19 16:45:26.201009: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8e00 of size 256 next 1183\n",
      "2022-06-19 16:45:26.201011: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e8f00 of size 256 next 1184\n",
      "2022-06-19 16:45:26.201014: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9000 of size 256 next 1185\n",
      "2022-06-19 16:45:26.201016: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9100 of size 256 next 1186\n",
      "2022-06-19 16:45:26.201018: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9200 of size 256 next 1187\n",
      "2022-06-19 16:45:26.201020: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9300 of size 256 next 1188\n",
      "2022-06-19 16:45:26.201023: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9400 of size 256 next 1189\n",
      "2022-06-19 16:45:26.201025: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9500 of size 256 next 1190\n",
      "2022-06-19 16:45:26.201027: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9600 of size 256 next 1191\n",
      "2022-06-19 16:45:26.201029: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9700 of size 256 next 1192\n",
      "2022-06-19 16:45:26.201032: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9800 of size 256 next 1193\n",
      "2022-06-19 16:45:26.201034: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9900 of size 256 next 1194\n",
      "2022-06-19 16:45:26.201036: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9a00 of size 256 next 1195\n",
      "2022-06-19 16:45:26.201038: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9b00 of size 256 next 1196\n",
      "2022-06-19 16:45:26.201041: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9c00 of size 256 next 1197\n",
      "2022-06-19 16:45:26.201043: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9d00 of size 256 next 1198\n",
      "2022-06-19 16:45:26.201151: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9e00 of size 256 next 1199\n",
      "2022-06-19 16:45:26.201155: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970e9f00 of size 256 next 1200\n",
      "2022-06-19 16:45:26.201157: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea000 of size 256 next 1201\n",
      "2022-06-19 16:45:26.201160: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea100 of size 256 next 1202\n",
      "2022-06-19 16:45:26.201162: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea200 of size 256 next 1203\n",
      "2022-06-19 16:45:26.201164: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea300 of size 256 next 1204\n",
      "2022-06-19 16:45:26.201167: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea400 of size 256 next 1205\n",
      "2022-06-19 16:45:26.201169: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea500 of size 256 next 1206\n",
      "2022-06-19 16:45:26.201487: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea600 of size 256 next 1207\n",
      "2022-06-19 16:45:26.201549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea700 of size 256 next 1208\n",
      "2022-06-19 16:45:26.201553: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea800 of size 256 next 1209\n",
      "2022-06-19 16:45:26.201555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ea900 of size 256 next 1210\n",
      "2022-06-19 16:45:26.201558: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970eaa00 of size 256 next 1211\n",
      "2022-06-19 16:45:26.201560: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970eab00 of size 256 next 1212\n",
      "2022-06-19 16:45:26.201562: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970eac00 of size 256 next 1213\n",
      "2022-06-19 16:45:26.201565: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970ead00 of size 256 next 1214\n",
      "2022-06-19 16:45:26.201568: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7970eae00 of size 94004992 next 1251\n",
      "2022-06-19 16:45:26.201570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79ca91500 of size 6656 next 1236\n",
      "2022-06-19 16:45:26.201573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79ca92f00 of size 9437184 next 1303\n",
      "2022-06-19 16:45:26.201575: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79d392f00 of size 9437184 next 1307\n",
      "2022-06-19 16:45:26.201578: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79dc92f00 of size 2359296 next 1238\n",
      "2022-06-19 16:45:26.201581: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79ded2f00 of size 2359296 next 1259\n",
      "2022-06-19 16:45:26.201583: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79e112f00 of size 2359296 next 298\n",
      "2022-06-19 16:45:26.201586: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79e352f00 of size 2359296 next 1323\n",
      "2022-06-19 16:45:26.201588: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79e592f00 of size 9437184 next 1219\n",
      "2022-06-19 16:45:26.201590: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79ee92f00 of size 2555904 next 1297\n",
      "2022-06-19 16:45:26.201593: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79f102f00 of size 65536 next 1227\n",
      "2022-06-19 16:45:26.201596: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 79f112f00 of size 50693376 next 1313\n",
      "2022-06-19 16:45:26.201598: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a216b400 of size 131072 next 1260\n",
      "2022-06-19 16:45:26.201601: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a218b400 of size 78674688 next 1269\n",
      "2022-06-19 16:45:26.201604: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a6c92f00 of size 2359296 next 1270\n",
      "2022-06-19 16:45:26.201606: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a6ed2f00 of size 2359296 next 1336\n",
      "2022-06-19 16:45:26.201608: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a7112f00 of size 2359296 next 454\n",
      "2022-06-19 16:45:26.201611: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a7352f00 of size 2359296 next 1248\n",
      "2022-06-19 16:45:26.201613: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a7592f00 of size 9437184 next 1249\n",
      "2022-06-19 16:45:26.201615: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a7e92f00 of size 2359296 next 1234\n",
      "2022-06-19 16:45:26.201618: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a80d2f00 of size 2359296 next 1237\n",
      "2022-06-19 16:45:26.201620: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a8312f00 of size 2359296 next 1244\n",
      "2022-06-19 16:45:26.201622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a8552f00 of size 2359296 next 1253\n",
      "2022-06-19 16:45:26.201625: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a8792f00 of size 2359296 next 1276\n",
      "2022-06-19 16:45:26.202432: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a89d2f00 of size 9437184 next 1277\n",
      "2022-06-19 16:45:26.202443: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7a92d2f00 of size 2359296 next 1216\n",
      "2022-06-19 16:45:26.202447: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a9512f00 of size 2359296 next 1309\n",
      "2022-06-19 16:45:26.202450: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a9752f00 of size 2359296 next 1281\n",
      "2022-06-19 16:45:26.202453: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a9992f00 of size 2359296 next 1282\n",
      "2022-06-19 16:45:26.202518: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7a9bd2f00 of size 9437184 next 1280\n",
      "2022-06-19 16:45:26.202526: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7aa4d2f00 of size 9437184 next 1285\n",
      "2022-06-19 16:45:26.202529: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7aadd2f00 of size 2359296 next 1286\n",
      "2022-06-19 16:45:26.202531: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7ab012f00 of size 9437184 next 1296\n",
      "2022-06-19 16:45:26.202534: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ab912f00 of size 2359296 next 1289\n",
      "2022-06-19 16:45:26.202536: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7abb52f00 of size 2359296 next 1290\n",
      "2022-06-19 16:45:26.202538: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7abd92f00 of size 2359296 next 1283\n",
      "2022-06-19 16:45:26.202540: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7abfd2f00 of size 9437184 next 1284\n",
      "2022-06-19 16:45:26.202543: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ac8d2f00 of size 2359296 next 1293\n",
      "2022-06-19 16:45:26.202545: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7acb12f00 of size 2359296 next 1287\n",
      "2022-06-19 16:45:26.202547: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7acd52f00 of size 9437184 next 1291\n",
      "2022-06-19 16:45:26.202549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ad652f00 of size 2359296 next 1292\n",
      "2022-06-19 16:45:26.202552: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ad892f00 of size 9437184 next 1301\n",
      "2022-06-19 16:45:26.202554: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ae192f00 of size 2359296 next 1302\n",
      "2022-06-19 16:45:26.202556: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ae3d2f00 of size 2359296 next 1299\n",
      "2022-06-19 16:45:26.202558: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ae612f00 of size 2359296 next 1300\n",
      "2022-06-19 16:45:26.202561: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7ae852f00 of size 2359296 next 1311\n",
      "2022-06-19 16:45:26.202563: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7aea92f00 of size 2359296 next 1312\n",
      "2022-06-19 16:45:26.202565: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7aecd2f00 of size 9437184 next 1298\n",
      "2022-06-19 16:45:26.202567: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7af5d2f00 of size 9437184 next 1314\n",
      "2022-06-19 16:45:26.202570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7afed2f00 of size 9437184 next 1243\n",
      "2022-06-19 16:45:26.202572: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b07d2f00 of size 2359296 next 1239\n",
      "2022-06-19 16:45:26.202574: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b0a12f00 of size 2359296 next 1304\n",
      "2022-06-19 16:45:26.202576: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b0c52f00 of size 2359296 next 1231\n",
      "2022-06-19 16:45:26.202579: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b0e92f00 of size 3932160 next 1308\n",
      "2022-06-19 16:45:26.202582: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b1252f00 of size 2359296 next 459\n",
      "2022-06-19 16:45:26.203101: I tensorflow/core/common_runtime/bfc_allocat"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "or.cc:1083] InUse at 7b1492f00 of size 9437184 next 460\n",
      "2022-06-19 16:45:26.203120: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b1d92f00 of size 2359296 next 461\n",
      "2022-06-19 16:45:26.203125: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b1fd2f00 of size 9437184 next 463\n",
      "2022-06-19 16:45:26.203129: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b28d2f00 of size 14155776 next 413\n",
      "2022-06-19 16:45:26.203193: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b3652f00 of size 11796480 next 405\n",
      "2022-06-19 16:45:26.203202: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b4192f00 of size 9437184 next 380\n",
      "2022-06-19 16:45:26.203205: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b4a92f00 of size 2359296 next 377\n",
      "2022-06-19 16:45:26.203208: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b4cd2f00 of size 2359296 next 376\n",
      "2022-06-19 16:45:26.203210: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b4f12f00 of size 2359296 next 371\n",
      "2022-06-19 16:45:26.203213: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5152f00 of size 2359296 next 370\n",
      "2022-06-19 16:45:26.203215: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5392f00 of size 2359296 next 451\n",
      "2022-06-19 16:45:26.203217: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b55d2f00 of size 2359296 next 452\n",
      "2022-06-19 16:45:26.203220: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5812f00 of size 6144 next 1225\n",
      "2022-06-19 16:45:26.203223: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5814700 of size 15616 next 1278\n",
      "2022-06-19 16:45:26.203225: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7b5818400 of size 2337536 next 455\n",
      "2022-06-19 16:45:26.203228: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5a52f00 of size 2359296 next 445\n",
      "2022-06-19 16:45:26.203230: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5c92f00 of size 2359296 next 447\n",
      "2022-06-19 16:45:26.203233: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b5ed2f00 of size 11796480 next 442\n",
      "2022-06-19 16:45:26.203235: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b6a12f00 of size 2359296 next 438\n",
      "2022-06-19 16:45:26.203237: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b6c52f00 of size 3932160 next 337\n",
      "2022-06-19 16:45:26.203240: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7b7012f00 of size 96253952 next 1310\n",
      "2022-06-19 16:45:26.203242: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7bcbde700 of size 93763584 next 1339\n",
      "2022-06-19 16:45:26.203245: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7c2549f00 of size 93763584 next 1252\n",
      "2022-06-19 16:45:26.203247: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7c7eb5700 of size 33554432 next 1331\n",
      "2022-06-19 16:45:26.203250: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7c9eb5700 of size 469762048 next 1229\n",
      "2022-06-19 16:45:26.203253: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7e5eb5700 of size 402653184 next 1266\n",
      "2022-06-19 16:45:26.203256: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fdeb5700 of size 402653184 next 1288\n",
      "2022-06-19 16:45:26.203259: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 815eb5700 of size 50331648 next 1320\n",
      "2022-06-19 16:45:26.203262: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 818eb5700 of size 50331648 next 1326\n",
      "2022-06-19 16:45:26.203265: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 81beb5700 of size 50331648 next 1338\n",
      "2022-06-19 16:45:26.203267: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 81eeb5700 of size 50331648 next 1217\n",
      "2022-06-19 16:45:26.203818: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 821eb5700 of size 50331648 next 289\n",
      "2022-06-19 16:45:26.203828: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 824eb5700 of size 50331648 next 1329\n",
      "2022-06-19 16:45:26.203831: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 827eb5700 of size 201326592 next 426\n",
      "2022-06-19 16:45:26.203834: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 833eb5700 of size 201326592 next 429\n",
      "2022-06-19 16:45:26.203837: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 83feb5700 of size 201326592 next 420\n",
      "2022-06-19 16:45:26.203839: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 84beb5700 of size 201326592 next 422\n",
      "2022-06-19 16:45:26.203842: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 857eb5700 of size 247113984 next 18446744073709551615\n",
      "2022-06-19 16:45:26.203845: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-06-19 16:45:26.203855: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 212 Chunks of size 256 totalling 53.0KiB\n",
      "2022-06-19 16:45:26.203858: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-06-19 16:45:26.203861: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 553 Chunks of size 3072 totalling 1.62MiB\n",
      "2022-06-19 16:45:26.203863: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 3328 totalling 6.5KiB\n",
      "2022-06-19 16:45:26.203866: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4608 totalling 4.5KiB\n",
      "2022-06-19 16:45:26.203869: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 9 Chunks of size 6144 totalling 54.0KiB\n",
      "2022-06-19 16:45:26.203871: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 6656 totalling 6.5KiB\n",
      "2022-06-19 16:45:26.203874: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 58 Chunks of size 12288 totalling 696.0KiB\n",
      "2022-06-19 16:45:26.203877: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 15616 totalling 15.2KiB\n",
      "2022-06-19 16:45:26.203880: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 21248 totalling 20.8KiB\n",
      "2022-06-19 16:45:26.203883: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 21760 totalling 21.2KiB\n",
      "2022-06-19 16:45:26.203886: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 5 Chunks of size 65536 totalling 320.0KiB\n",
      "2022-06-19 16:45:26.203888: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2022-06-19 16:45:26.203891: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 416000 totalling 812.5KiB\n",
      "2022-06-19 16:45:26.203894: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 16 Chunks of size 1572864 totalling 24.00MiB\n",
      "2022-06-19 16:45:26.203896: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1581056 totalling 1.51MiB\n",
      "2022-06-19 16:45:26.203899: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 288 Chunks of size 2359296 totalling 648.00MiB\n",
      "2022-06-19 16:45:26.203902: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2424832 totalling 2.31MiB\n",
      "2022-06-19 16:45:26.203905: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2537472 totalling 2.42MiB\n",
      "2022-06-19 16:45:26.203907: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2555904 totalling 2.44MiB\n",
      "2022-06-19 16:45:26.203910: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 3932160 totalling 7.50MiB\n",
      "2022-06-19 16:45:26.203912: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4110336 totalling 3.92MiB\n",
      "2022-06-19 16:45:26.203915: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 136 Chunks of size 9437184 totalling 1.20GiB\n",
      "2022-06-19 16:45:26.203918: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 10289152 totalling 9.81MiB\n",
      "2022-06-19 16:45:26.204269: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 11796480 totalling 45.00MiB\n",
      "2022-06-19 16:45:26.204278: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 13369344 totalling 12.75MiB\n",
      "2022-06-19 16:45:26.204281: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 14155776 totalling 13.50MiB\n",
      "2022-06-19 16:45:26.204284: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 16515072 totalling 15.75MiB\n",
      "2022-06-19 16:45:26.204287: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 33554432 totalling 32.00MiB\n",
      "2022-06-19 16:45:26.204290: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 8 Chunks of size 50331648 totalling 384.00MiB\n",
      "2022-06-19 16:45:26.204292: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 50693376 totalling 48.34MiB\n",
      "2022-06-19 16:45:26.204295: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 53524480 totalling 51.04MiB\n",
      "2022-06-19 16:45:26.204298: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 78674688 totalling 75.03MiB\n",
      "2022-06-19 16:45:26.204301: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 93763584 totalling 357.68MiB\n",
      "2022-06-19 16:45:26.204303: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 94004992 totalling 89.65MiB\n",
      "2022-06-19 16:45:26.204306: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 96253952 totalling 91.79MiB\n",
      "2022-06-19 16:45:26.204309: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 201326592 totalling 768.00MiB\n",
      "2022-06-19 16:45:26.204311: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 247113984 totalling 235.67MiB\n",
      "2022-06-19 16:45:26.204314: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 402653184 totalling 768.00MiB\n",
      "2022-06-19 16:45:26.204317: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 469762048 totalling 448.00MiB\n",
      "2022-06-19 16:45:26.204320: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 5.24GiB\n",
      "2022-06-19 16:45:26.204324: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 5692260352 memory_limit_: 5692260352 available bytes: 0 curr_region_allocation_bytes_: 11384520704\n",
      "2022-06-19 16:45:26.204332: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                      5692260352\n",
      "InUse:                      5626481152\n",
      "MaxInUse:                   5628750336\n",
      "NumAllocs:                       19306\n",
      "MaxAllocSize:                469762048\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-06-19 16:45:26.204365: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *************************************************************x**************************************\n",
      "2022-06-19 16:45:26.204397: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,512,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_encoder}')\n",
    "history = classifier_model.fit(x=train_ds, \n",
    "                               batch_size=2, \n",
    "                               epochs=epochs,\n",
    "                               validation_data=valid_ds, \n",
    "                               verbose=1,\n",
    "                               callbacks=[callback_es, callback_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBthMlTSV8kn"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Let's see how the model performs. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:37:37.235151Z",
     "iopub.status.busy": "2022-03-29T12:37:37.234581Z",
     "iopub.status.idle": "2022-03-29T12:38:36.128910Z",
     "shell.execute_reply": "2022-03-29T12:38:36.128342Z"
    },
    "id": "slqB-urBV9sP"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uttWpgmSfzq9"
   },
   "source": [
    "### Plot the accuracy and loss over time\n",
    "\n",
    "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:36.132081Z",
     "iopub.status.busy": "2022-03-29T12:38:36.131630Z",
     "iopub.status.idle": "2022-03-29T12:38:36.424503Z",
     "shell.execute_reply": "2022-03-29T12:38:36.424018Z"
    },
    "id": "fiythcODf0xo"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# r is for \"solid red line\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzJZCo-cf-Jf"
   },
   "source": [
    "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rtn7jewb6dg4"
   },
   "source": [
    "## Export for inference\n",
    "\n",
    "Now you just save your fine-tuned model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:36.428146Z",
     "iopub.status.busy": "2022-03-29T12:38:36.427717Z",
     "iopub.status.idle": "2022-03-29T12:38:42.015407Z",
     "shell.execute_reply": "2022-03-29T12:38:42.014764Z"
    },
    "id": "ShcvqJAgVera"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'imdb'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbI25bS1vD7s"
   },
   "source": [
    "Let's reload the model, so you can try it side by side with the model that is still in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:42.019271Z",
     "iopub.status.busy": "2022-03-29T12:38:42.018826Z",
     "iopub.status.idle": "2022-03-29T12:38:48.305286Z",
     "shell.execute_reply": "2022-03-29T12:38:48.304688Z"
    },
    "id": "gUEWVskZjEF0"
   },
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyTappHTvNCz"
   },
   "source": [
    "Here you can test your model on any sentence you want, just add to the examples variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:48.309376Z",
     "iopub.status.busy": "2022-03-29T12:38:48.308953Z",
     "iopub.status.idle": "2022-03-29T12:38:48.694457Z",
     "shell.execute_reply": "2022-03-29T12:38:48.693822Z"
    },
    "id": "VBWzH6exlCPS"
   },
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
    "    'The movie was great!',\n",
    "    'The movie was meh.',\n",
    "    'The movie was okish.',\n",
    "    'The movie was terrible...'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "print('Results from the model in memory:')\n",
    "print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cOmih754Y_M"
   },
   "source": [
    "If you want to use your model on [TF Serving](https://www.tensorflow.org/tfx/guide/serving), remember that it will call your SavedModel through one of its named signatures. In Python, you can test them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:38:48.697594Z",
     "iopub.status.busy": "2022-03-29T12:38:48.697394Z",
     "iopub.status.idle": "2022-03-29T12:38:48.996870Z",
     "shell.execute_reply": "2022-03-29T12:38:48.996220Z"
    },
    "id": "0FdVD3973S-O"
   },
   "outputs": [],
   "source": [
    "serving_results = reloaded_model \\\n",
    "            .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4gN1KwReLPN"
   },
   "source": [
    "# __FAILED STEPS__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _[Gave up on this] Convert training dataframe to dataset_\n",
    "\n",
    "Try many different ways, was trying not to slit text records into different files then load as a dataset like the tutorial. But converting from dataframe always missed something that I cannot quite put my finger on. Moving on. Revisit this later...\n",
    "\n",
    "- See the [pd_dataframe_to_tf_dataset](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/pd_dataframe_to_tf_dataset) function, but this needs tf 2.9, conflict with tensorflow_text.\n",
    "- See [this](https://www.tensorflow.org/tutorials/load_data/pandas_dataframe): See the shuffle and batch functions. Does not work...\n",
    "- See [this post](https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168):  Was able to create SicedDataset, then BatchDatabase after applying the batch function, then PrefetchDataset. But trying to retreive a test example from trainin dataset lead to:\n",
    "  - InvalidArgumentError: Index out of range using input dim 0; input has only 0 dims [Op:StridedSlice] name: strided_slice/\n",
    "  - Ok, as I was implmenting the next solution, realize that I did not call the right obj for prefetch. Can be the reason why.\n",
    "- Ah, see [this post](https://stackoverflow.com/questions/58461609/how-to-convert-pandas-dataframe-to-tensorflow-dataset): key is to turn train_data to dictionary before calling from_tensor_slices.\n",
    "  - A little comment below say need to do .to_dict() instead which make sense. Because if just do dict(train), the thing finish in 0.1 sec which does not make sense. But this fails and throw:\n",
    "    - ValueError: Unbatching a tensor is only supported for rank >= 1\n",
    "  - Found [this post](https://stackoverflow.com/questions/55560620/valueerror-unbatching-a-tensor-is-only-supported-for-rank-1): Now try to uses this syntax. Still does not work..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following DOES NOT work\n",
    "\n",
    "```Python\n",
    "raw_train_ds = (tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(train['txt'].values, tf.string),\n",
    "         tf.cast(train['label'].values, tf.int32),)))\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices(train)\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices(dict(train))\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices(train.to_dict())\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices((y_train,X_train))\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices((i_train, \n",
    "                                                   y_train.values,\n",
    "                                                   X_train.values))\n",
    "\n",
    "The last one is almost working, but at later stage when I try to pack the input, it breaks. Upon closer examination, the train_ds looks like:\n",
    "\n",
    "```\n",
    "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n",
    "```\n",
    "\n",
    "But what I need is more like:\n",
    "\n",
    "```\n",
    "<PrefetchDataset element_spec={'idx': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'label': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'sentence1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'sentence2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = train.iloc[:3,:]\n",
    "raw_trial_ds = (tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(trial['txt'].values, tf.string),\n",
    "         tf.cast(trial['label'].values, tf.int32),)))\n",
    "raw_trial_ds\n",
    "# Does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec={'idx': TensorSpec(shape=(), dtype=tf.int32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int32, name=None), 'txt': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call \"trial\" so it does not mix with the testing set\n",
    "trial_dict   = {\"idx\":[123,322], \"label\":[0,1], \n",
    "               \"txt\":[\"The 1st sentence\", \"The second\"]}\n",
    "\n",
    "# This creates a TensorSliceDataset\n",
    "raw_trial_ds =  tf.data.Dataset.from_tensor_slices(trial_dict)\n",
    "\n",
    "# Now this has the right structure!!!\n",
    "raw_trial_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;32m/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000105vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m index_batch, label_batch, text_batch \u001b[39min\u001b[39;00m raw_trial_ds\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000105vscode-remote?line=1'>2</a>\u001b[0m   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000105vscode-remote?line=2'>3</a>\u001b[0m     label \u001b[39m=\u001b[39m label_batch\u001b[39m.\u001b[39;49mnumpy()[i]\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000105vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLabel : \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mclass_names[label]\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shinhan/github/plant_sci_hist/2_text_classify/script_text_classify-tensorflow_bert.ipynb#ch0000105vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReview: \u001b[39m\u001b[39m{\u001b[39;00mtext_batch\u001b[39m.\u001b[39mnumpy()[i]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "for index_batch, label_batch, text_batch in raw_trial_ds.take(1):\n",
    "  for i in range(1):\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_trial_ds_batch = raw_trial_ds.batch(batch_size)\n",
    "type(raw_trial_ds_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial_ds = raw_trial_ds_batch.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "len(trial_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(None,), dtype=tf.string, name=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Still have the right structure.\n",
    "trial_ds.element_spec['txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:15.751221Z",
     "iopub.status.busy": "2022-03-29T12:30:15.750998Z",
     "iopub.status.idle": "2022-03-29T12:30:15.778963Z",
     "shell.execute_reply": "2022-03-29T12:30:15.778411Z"
    },
    "id": "JuxDkcvVIoev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TakeDataset in module tensorflow.python.data.ops.dataset_ops object:\n",
      "\n",
      "class TakeDataset(UnaryUnchangedStructureDataset)\n",
      " |  TakeDataset(input_dataset, count, name=None)\n",
      " |  \n",
      " |  A `Dataset` containing the first `count` elements from its input.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TakeDataset\n",
      " |      UnaryUnchangedStructureDataset\n",
      " |      UnaryDataset\n",
      " |      DatasetV2\n",
      " |      collections.abc.Iterable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_dataset, count, name=None)\n",
      " |      See `Dataset.take()` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from UnaryUnchangedStructureDataset:\n",
      " |  \n",
      " |  element_spec\n",
      " |      The type specification of an element of this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset.element_spec\n",
      " |      TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      " |      \n",
      " |      For more information,\n",
      " |      read [this guide](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A (nested) structure of `tf.TypeSpec` objects matching the structure of an\n",
      " |        element of this dataset and specifying the type of individual components.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DatasetV2:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __debug_string__(self)\n",
      " |      Returns a string showing the type of the dataset and its inputs.\n",
      " |      \n",
      " |      This string is intended only for debugging purposes, and may change without\n",
      " |      warning.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Creates an iterator for elements of this dataset.\n",
      " |      \n",
      " |      The returned iterator implements the Python Iterator protocol.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An `tf.data.Iterator` for the elements of this dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If not inside of tf.function and not executing eagerly.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the dataset if it is known and finite.\n",
      " |      \n",
      " |      This method requires that you are running in eager mode, and that the\n",
      " |      length of the dataset is known and non-infinite. When the length may be\n",
      " |      unknown or infinite, or if you are running in graph mode, use\n",
      " |      `tf.data.Dataset.cardinality` instead.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An integer representing the length of the dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the dataset length is unknown or infinite, or if eager\n",
      " |          execution is not enabled.\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  apply(self, transformation_func)\n",
      " |      Applies a transformation function to this dataset.\n",
      " |      \n",
      " |      `apply` enables chaining of custom `Dataset` transformations, which are\n",
      " |      represented as functions that take one `Dataset` argument and return a\n",
      " |      transformed `Dataset`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(100)\n",
      " |      >>> def dataset_fn(ds):\n",
      " |      ...   return ds.filter(lambda x: x < 5)\n",
      " |      >>> dataset = dataset.apply(dataset_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        transformation_func: A function that takes one `Dataset` argument and\n",
      " |          returns a `Dataset`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` returned by applying `transformation_func` to this\n",
      " |            dataset.\n",
      " |  \n",
      " |  as_numpy_iterator(self)\n",
      " |      Returns an iterator which converts all elements of the dataset to numpy.\n",
      " |      \n",
      " |      Use `as_numpy_iterator` to inspect the content of your dataset. To see\n",
      " |      element shapes and types, print dataset elements directly instead of using\n",
      " |      `as_numpy_iterator`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset:\n",
      " |      ...   print(element)\n",
      " |      tf.Tensor(1, shape=(), dtype=int32)\n",
      " |      tf.Tensor(2, shape=(), dtype=int32)\n",
      " |      tf.Tensor(3, shape=(), dtype=int32)\n",
      " |      \n",
      " |      This method requires that you are running in eager mode and the dataset's\n",
      " |      element_spec contains only `TensorSpec` components.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      1\n",
      " |      2\n",
      " |      3\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> print(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      `as_numpy_iterator()` will preserve the nested structure of dataset\n",
      " |      elements.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
      " |      ...                                               'b': [5, 6]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
      " |      ...                                       {'a': (2, 4), 'b': 6}]\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        An iterable over the elements of the dataset, with their tensors converted\n",
      " |        to numpy arrays.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: if an element contains a non-`Tensor` value.\n",
      " |        RuntimeError: if eager execution is not enabled.\n",
      " |  \n",
      " |  batch(self, batch_size, drop_remainder=False, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Combines consecutive elements of this dataset into batches.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3, drop_remainder=True)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5])]\n",
      " |      \n",
      " |      The components of the resulting element will have an additional outer\n",
      " |      dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
      " |      element if `batch_size` does not divide the number of input elements `N`\n",
      " |      evenly and `drop_remainder` is `False`). If your program depends on the\n",
      " |      batches having the same outer dimension, you should set the `drop_remainder`\n",
      " |      argument to `True` to prevent the smaller batch from being produced.\n",
      " |      \n",
      " |      Note: If your program requires data to have a statically known shape (e.g.,\n",
      " |      when using XLA), you should use `drop_remainder=True`. Without\n",
      " |      `drop_remainder=True` the shape of the output dataset will have an unknown\n",
      " |      leading dimension due to the possibility of a smaller final batch.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      " |          representing the number of batches to compute asynchronously in\n",
      " |          parallel.\n",
      " |          If not specified, batches will be computed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available resources.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  bucket_by_sequence_length(self, element_length_func, bucket_boundaries, bucket_batch_sizes, padded_shapes=None, padding_values=None, pad_to_bucket_boundary=False, no_padding=False, drop_remainder=False, name=None)\n",
      " |      A transformation that buckets elements in a `Dataset` by length.\n",
      " |      \n",
      " |      Elements of the `Dataset` are grouped together by length and then are padded\n",
      " |      and batched.\n",
      " |      \n",
      " |      This is useful for sequence tasks in which the elements have variable\n",
      " |      length. Grouping together elements that have similar lengths reduces the\n",
      " |      total fraction of padding in a batch which increases training step\n",
      " |      efficiency.\n",
      " |      \n",
      " |      Below is an example to bucketize the input data to the 3 buckets\n",
      " |      \"[0, 3), [3, 5), [5, inf)\" based on sequence length, with batch size 2.\n",
      " |      \n",
      " |      >>> elements = [\n",
      " |      ...   [0], [1, 2, 3, 4], [5, 6, 7],\n",
      " |      ...   [7, 8, 9, 10, 11], [13, 14, 15, 16, 19, 20], [21, 22]]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, tf.int64, output_shapes=[None])\n",
      " |      >>> dataset = dataset.bucket_by_sequence_length(\n",
      " |      ...         element_length_func=lambda elem: tf.shape(elem)[0],\n",
      " |      ...         bucket_boundaries=[3, 5],\n",
      " |      ...         bucket_batch_sizes=[2, 2, 2])\n",
      " |      >>> for elem in dataset.as_numpy_iterator():\n",
      " |      ...   print(elem)\n",
      " |      [[1 2 3 4]\n",
      " |      [5 6 7 0]]\n",
      " |      [[ 7  8  9 10 11  0]\n",
      " |      [13 14 15 16 19 20]]\n",
      " |      [[ 0  0]\n",
      " |      [21 22]]\n",
      " |      \n",
      " |      Args:\n",
      " |        element_length_func: function from element in `Dataset` to `tf.int32`,\n",
      " |          determines the length of the element, which will determine the bucket it\n",
      " |          goes into.\n",
      " |        bucket_boundaries: `list<int>`, upper length boundaries of the buckets.\n",
      " |        bucket_batch_sizes: `list<int>`, batch size per bucket. Length should be\n",
      " |          `len(bucket_boundaries) + 1`.\n",
      " |        padded_shapes: Nested structure of `tf.TensorShape` to pass to\n",
      " |          `tf.data.Dataset.padded_batch`. If not provided, will use\n",
      " |          `dataset.output_shapes`, which will result in variable length dimensions\n",
      " |          being padded out to the maximum length in each batch.\n",
      " |        padding_values: Values to pad with, passed to\n",
      " |          `tf.data.Dataset.padded_batch`. Defaults to padding with 0.\n",
      " |        pad_to_bucket_boundary: bool, if `False`, will pad dimensions with unknown\n",
      " |          size to maximum length in batch. If `True`, will pad dimensions with\n",
      " |          unknown size to bucket boundary minus 1 (i.e., the maximum length in\n",
      " |          each bucket), and caller must ensure that the source `Dataset` does not\n",
      " |          contain any elements with length longer than `max(bucket_boundaries)`.\n",
      " |        no_padding: `bool`, indicates whether to pad the batch features (features\n",
      " |          need to be either of type `tf.sparse.SparseTensor` or of same shape).\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if `len(bucket_batch_sizes) != len(bucket_boundaries) + 1`.\n",
      " |  \n",
      " |  cache(self, filename='', name=None)\n",
      " |      Caches the elements in this dataset.\n",
      " |      \n",
      " |      The first time the dataset is iterated over, its elements will be cached\n",
      " |      either in the specified file or in memory. Subsequent iterations will\n",
      " |      use the cached data.\n",
      " |      \n",
      " |      Note: For the cache to be finalized, the input dataset must be iterated\n",
      " |      through in its entirety. Otherwise, subsequent iterations will not use\n",
      " |      cached data.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(5)\n",
      " |      >>> dataset = dataset.map(lambda x: x**2)\n",
      " |      >>> dataset = dataset.cache()\n",
      " |      >>> # The first time reading through the data will generate the data using\n",
      " |      >>> # `range` and `map`.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      >>> # Subsequent iterations read from the cache.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      \n",
      " |      When caching to a file, the cached data will persist across runs. Even the\n",
      " |      first iteration through the data will read from the cache file. Changing\n",
      " |      the input pipeline before the call to `.cache()` will have no effect until\n",
      " |      the cache file is removed or the filename is changed.\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(5)\n",
      " |      dataset = dataset.cache(\"/path/to/file\")\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [0, 1, 2, 3, 4]\n",
      " |      dataset = tf.data.Dataset.range(10)\n",
      " |      dataset = dataset.cache(\"/path/to/file\")  # Same file!\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [0, 1, 2, 3, 4]\n",
      " |      ```\n",
      " |      \n",
      " |      Note: `cache` will produce exactly the same elements during each iteration\n",
      " |      through the dataset. If you wish to randomize the iteration order, make sure\n",
      " |      to call `shuffle` *after* calling `cache`.\n",
      " |      \n",
      " |      Args:\n",
      " |        filename: A `tf.string` scalar `tf.Tensor`, representing the name of a\n",
      " |          directory on the filesystem to use for caching elements in this Dataset.\n",
      " |          If a filename is not provided, the dataset will be cached in memory.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  cardinality(self)\n",
      " |      Returns the cardinality of the dataset, if known.\n",
      " |      \n",
      " |      `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\n",
      " |      contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\n",
      " |      the analysis fails to determine the number of elements in the dataset\n",
      " |      (e.g. when the dataset source is a file).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(42)\n",
      " |      >>> print(dataset.cardinality().numpy())\n",
      " |      42\n",
      " |      >>> dataset = dataset.repeat()\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.INFINITE_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      >>> dataset = dataset.filter(lambda x: True)\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.UNKNOWN_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A scalar `tf.int64` `Tensor` representing the cardinality of the dataset.\n",
      " |        If the cardinality is infinite or unknown, `cardinality` returns the\n",
      " |        named constants `tf.data.INFINITE_CARDINALITY` and\n",
      " |        `tf.data.UNKNOWN_CARDINALITY` respectively.\n",
      " |  \n",
      " |  concatenate(self, dataset, name=None)\n",
      " |      Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      " |      \n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\n",
      " |      >>> ds = a.concatenate(b)\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7]\n",
      " |      >>> # The input dataset and dataset to be concatenated should have\n",
      " |      >>> # compatible element specs.\n",
      " |      >>> c = tf.data.Dataset.zip((a, b))\n",
      " |      >>> a.concatenate(c)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and (tf.int64, tf.int64)\n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\"])\n",
      " |      >>> a.concatenate(d)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and <dtype: 'string'>\n",
      " |      \n",
      " |      Args:\n",
      " |        dataset: `Dataset` to be concatenated.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  enumerate(self, start=0, name=None)\n",
      " |      Enumerates the elements of this dataset.\n",
      " |      \n",
      " |      It is similar to python's `enumerate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.enumerate(start=5)\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (5, 1)\n",
      " |      (6, 2)\n",
      " |      (7, 3)\n",
      " |      \n",
      " |      >>> # The (nested) structure of the input dataset determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\n",
      " |      >>> dataset = dataset.enumerate()\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (0, array([7, 8], dtype=int32))\n",
      " |      (1, array([ 9, 10], dtype=int32))\n",
      " |      \n",
      " |      Args:\n",
      " |        start: A `tf.int64` scalar `tf.Tensor`, representing the start value for\n",
      " |          enumeration.\n",
      " |        name: Optional. A name for the tf.data operations used by `enumerate`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  filter(self, predicate, name=None)\n",
      " |      Filters this dataset according to `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.filter(lambda x: x < 3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2]\n",
      " |      >>> # `tf.math.equal(x, y)` is required for equality comparison\n",
      " |      >>> def filter_fn(x):\n",
      " |      ...   return tf.math.equal(x, 1)\n",
      " |      >>> dataset = dataset.filter(filter_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function mapping a dataset element to a boolean.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` containing the elements of this dataset for which\n",
      " |            `predicate` is `True`.\n",
      " |  \n",
      " |  flat_map(self, map_func, name=None)\n",
      " |      Maps `map_func` across this dataset and flattens the result.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def flat_map(\n",
      " |        self: Dataset[T],\n",
      " |        map_func: Callable[[T], Dataset[S]]\n",
      " |      ) -> Dataset[S]\n",
      " |      ```\n",
      " |      \n",
      " |      Use `flat_map` if you want to make sure that the order of your dataset\n",
      " |      stays the same. For example, to flatten a dataset of batches into a\n",
      " |      dataset of their elements:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(\n",
      " |      ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      " |      >>> dataset = dataset.flat_map(\n",
      " |      ...     lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      " |      \n",
      " |      `tf.data.Dataset.interleave()` is a generalization of `flat_map`, since\n",
      " |      `flat_map` produces the same output as\n",
      " |      `tf.data.Dataset.interleave(cycle_length=1)`\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to a dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  get_single_element(self, name=None)\n",
      " |      Returns the single element of the `dataset`.\n",
      " |      \n",
      " |      The function enables you to use a `tf.data.Dataset` in a stateless\n",
      " |      \"tensor-in tensor-out\" expression, without creating an iterator.\n",
      " |      This facilitates the ease of data transformation on tensors using the\n",
      " |      optimized `tf.data.Dataset` abstraction on top of them.\n",
      " |      \n",
      " |      For example, lets consider a `preprocessing_fn` which would take as an\n",
      " |      input the raw features and returns the processed feature along with\n",
      " |      it's label.\n",
      " |      \n",
      " |      ```python\n",
      " |      def preprocessing_fn(raw_feature):\n",
      " |        # ... the raw_feature is preprocessed as per the use-case\n",
      " |        return feature\n",
      " |      \n",
      " |      raw_features = ...  # input batch of BATCH_SIZE elements.\n",
      " |      dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      " |                .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |                .batch(BATCH_SIZE))\n",
      " |      \n",
      " |      processed_features = dataset.get_single_element()\n",
      " |      ```\n",
      " |      \n",
      " |      In the above example, the `raw_features` tensor of length=BATCH_SIZE\n",
      " |      was converted to a `tf.data.Dataset`. Next, each of the `raw_feature` was\n",
      " |      mapped using the `preprocessing_fn` and the processed features were\n",
      " |      grouped into a single batch. The final `dataset` contains only one element\n",
      " |      which is a batch of all the processed features.\n",
      " |      \n",
      " |      NOTE: The `dataset` should contain only one element.\n",
      " |      \n",
      " |      Now, instead of creating an iterator for the `dataset` and retrieving the\n",
      " |      batch of features, the `tf.data.get_single_element()` function is used\n",
      " |      to skip the iterator creation process and directly output the batch of\n",
      " |      features.\n",
      " |      \n",
      " |      This can be particularly useful when your tensor transformations are\n",
      " |      expressed as `tf.data.Dataset` operations, and you want to use those\n",
      " |      transformations while serving your model.\n",
      " |      \n",
      " |      #### Keras\n",
      " |      \n",
      " |      ```python\n",
      " |      \n",
      " |      model = ... # A pre-built or custom model\n",
      " |      \n",
      " |      class PreprocessingModel(tf.keras.Model):\n",
      " |        def __init__(self, model):\n",
      " |          super().__init__(self)\n",
      " |          self.model = model\n",
      " |      \n",
      " |        @tf.function(input_signature=[...])\n",
      " |        def serving_fn(self, data):\n",
      " |          ds = tf.data.Dataset.from_tensor_slices(data)\n",
      " |          ds = ds.map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |          ds = ds.batch(batch_size=BATCH_SIZE)\n",
      " |          return tf.argmax(self.model(ds.get_single_element()), axis=-1)\n",
      " |      \n",
      " |      preprocessing_model = PreprocessingModel(model)\n",
      " |      your_exported_model_dir = ... # save the model to this path.\n",
      " |      tf.saved_model.save(preprocessing_model, your_exported_model_dir,\n",
      " |                    signatures={'serving_default': preprocessing_model.serving_fn}\n",
      " |                    )\n",
      " |      ```\n",
      " |      \n",
      " |      #### Estimator\n",
      " |      \n",
      " |      In the case of estimators, you need to generally define a `serving_input_fn`\n",
      " |      which would require the features to be processed by the model while\n",
      " |      inferencing.\n",
      " |      \n",
      " |      ```python\n",
      " |      def serving_input_fn():\n",
      " |      \n",
      " |        raw_feature_spec = ... # Spec for the raw_features\n",
      " |        input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
      " |            raw_feature_spec, default_batch_size=None)\n",
      " |        )\n",
      " |        serving_input_receiver = input_fn()\n",
      " |        raw_features = serving_input_receiver.features\n",
      " |      \n",
      " |        def preprocessing_fn(raw_feature):\n",
      " |          # ... the raw_feature is preprocessed as per the use-case\n",
      " |          return feature\n",
      " |      \n",
      " |        dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      " |                  .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |                  .batch(BATCH_SIZE))\n",
      " |      \n",
      " |        processed_features = dataset.get_single_element()\n",
      " |      \n",
      " |        # Please note that the value of `BATCH_SIZE` should be equal to\n",
      " |        # the size of the leading dimension of `raw_features`. This ensures\n",
      " |        # that `dataset` has only element, which is a pre-requisite for\n",
      " |        # using `dataset.get_single_element()`.\n",
      " |      \n",
      " |        return tf.estimator.export.ServingInputReceiver(\n",
      " |            processed_features, serving_input_receiver.receiver_tensors)\n",
      " |      \n",
      " |      estimator = ... # A pre-built or custom estimator\n",
      " |      estimator.export_saved_model(your_exported_model_dir, serving_input_fn)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested structure of `tf.Tensor` objects, corresponding to the single\n",
      " |        element of `dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: (at runtime) if `dataset` does not contain exactly\n",
      " |          one element.\n",
      " |  \n",
      " |  group_by_window(self, key_func, reduce_func, window_size=None, window_size_func=None, name=None)\n",
      " |      Groups windows of elements by key and reduces them.\n",
      " |      \n",
      " |      This transformation maps each consecutive element in a dataset to a key\n",
      " |      using `key_func` and groups the elements by key. It then applies\n",
      " |      `reduce_func` to at most `window_size_func(key)` elements matching the same\n",
      " |      key. All except the final window for each key will contain\n",
      " |      `window_size_func(key)` elements; the final window may be smaller.\n",
      " |      \n",
      " |      You may provide either a constant `window_size` or a window size determined\n",
      " |      by the key through `window_size_func`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> window_size = 5\n",
      " |      >>> key_func = lambda x: x%2\n",
      " |      >>> reduce_func = lambda key, dataset: dataset.batch(window_size)\n",
      " |      >>> dataset = dataset.group_by_window(\n",
      " |      ...           key_func=key_func,\n",
      " |      ...           reduce_func=reduce_func,\n",
      " |      ...           window_size=window_size)\n",
      " |      >>> for elem in dataset.as_numpy_iterator():\n",
      " |      ...   print(elem)\n",
      " |      [0 2 4 6 8]\n",
      " |      [1 3 5 7 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        key_func: A function mapping a nested structure of tensors (having shapes\n",
      " |          and types defined by `self.output_shapes` and `self.output_types`) to a\n",
      " |          scalar `tf.int64` tensor.\n",
      " |        reduce_func: A function mapping a key and a dataset of up to `window_size`\n",
      " |          consecutive elements matching that key to another dataset.\n",
      " |        window_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements matching the same key to combine in a single batch,\n",
      " |          which will be passed to `reduce_func`. Mutually exclusive with\n",
      " |          `window_size_func`.\n",
      " |        window_size_func: A function mapping a key to a `tf.int64` scalar\n",
      " |          `tf.Tensor`, representing the number of consecutive elements matching\n",
      " |          the same key to combine in a single batch, which will be passed to\n",
      " |          `reduce_func`. Mutually exclusive with `window_size`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if neither or both of {`window_size`, `window_size_func`} are\n",
      " |          passed.\n",
      " |  \n",
      " |  interleave(self, map_func, cycle_length=None, block_length=None, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Maps `map_func` across this dataset, and interleaves the results.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def interleave(\n",
      " |        self: Dataset[T],\n",
      " |        map_func: Callable[[T], Dataset[S]]\n",
      " |      ) -> Dataset[S]\n",
      " |      ```\n",
      " |      \n",
      " |      For example, you can use `Dataset.interleave()` to process many input files\n",
      " |      concurrently:\n",
      " |      \n",
      " |      >>> # Preprocess 4 files concurrently, and interleave blocks of 16 records\n",
      " |      >>> # from each file.\n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> def parse_fn(filename):\n",
      " |      ...   return tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.interleave(lambda x:\n",
      " |      ...     tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\n",
      " |      ...     cycle_length=4, block_length=16)\n",
      " |      \n",
      " |      The `cycle_length` and `block_length` arguments control the order in which\n",
      " |      elements are produced. `cycle_length` controls the number of input elements\n",
      " |      that are processed concurrently. If you set `cycle_length` to 1, this\n",
      " |      transformation will handle one input element at a time, and will produce\n",
      " |      identical results to `tf.data.Dataset.flat_map`. In general,\n",
      " |      this transformation will apply `map_func` to `cycle_length` input elements,\n",
      " |      open iterators on the returned `Dataset` objects, and cycle through them\n",
      " |      producing `block_length` consecutive elements from each iterator, and\n",
      " |      consuming the next input element each time it reaches the end of an\n",
      " |      iterator.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> # NOTE: New lines indicate \"block\" boundaries.\n",
      " |      >>> dataset = dataset.interleave(\n",
      " |      ...     lambda x: Dataset.from_tensors(x).repeat(6),\n",
      " |      ...     cycle_length=2, block_length=4)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 1, 1, 1,\n",
      " |       2, 2, 2, 2,\n",
      " |       1, 1,\n",
      " |       2, 2,\n",
      " |       3, 3, 3, 3,\n",
      " |       4, 4, 4, 4,\n",
      " |       3, 3,\n",
      " |       4, 4,\n",
      " |       5, 5, 5, 5,\n",
      " |       5, 5]\n",
      " |      \n",
      " |      Note: The order of elements yielded by this transformation is\n",
      " |      deterministic, as long as `map_func` is a pure function and\n",
      " |      `deterministic=True`. If `map_func` contains any stateful operations, the\n",
      " |      order in which that state is accessed is undefined.\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `interleave` will use multiple threads to fetch elements. If determinism\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x),\n",
      " |      ...     cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function that takes a dataset element and returns a\n",
      " |          `tf.data.Dataset`.\n",
      " |        cycle_length: (Optional.) The number of input elements that will be\n",
      " |          processed concurrently. If not set, the tf.data runtime decides what it\n",
      " |          should be based on available CPU. If `num_parallel_calls` is set to\n",
      " |          `tf.data.AUTOTUNE`, the `cycle_length` argument identifies\n",
      " |          the maximum degree of parallelism.\n",
      " |        block_length: (Optional.) The number of consecutive elements to produce\n",
      " |          from each input element before cycling to another input element. If not\n",
      " |          set, defaults to 1.\n",
      " |        num_parallel_calls: (Optional.) If specified, the implementation creates a\n",
      " |          threadpool, which is used to fetch inputs from cycle elements\n",
      " |          asynchronously and in parallel. The default behavior is to fetch inputs\n",
      " |          from cycle elements synchronously with no parallelism. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  map(self, map_func, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Maps `map_func` across the elements of this dataset.\n",
      " |      \n",
      " |      This transformation applies `map_func` to each element of this dataset, and\n",
      " |      returns a new dataset containing the transformed elements, in the same\n",
      " |      order as they appeared in the input. `map_func` can be used to change both\n",
      " |      the values and the structure of a dataset's elements. Supported structure\n",
      " |      constructs are documented\n",
      " |      [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      For example, `map` can be used for adding 1 to each element, or projecting a\n",
      " |      subset of element components.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [2, 3, 4, 5, 6]\n",
      " |      \n",
      " |      The input signature of `map_func` is determined by the structure of each\n",
      " |      element in this dataset.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(5)\n",
      " |      >>> # `map_func` takes a single argument of type `tf.Tensor` with the same\n",
      " |      >>> # shape and dtype.\n",
      " |      >>> result = dataset.map(lambda x: x + 1)\n",
      " |      \n",
      " |      >>> # Each element is a tuple containing two `tf.Tensor` objects.\n",
      " |      >>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, (tf.int32, tf.string))\n",
      " |      >>> # `map_func` takes two arguments of type `tf.Tensor`. This function\n",
      " |      >>> # projects out just the first component.\n",
      " |      >>> result = dataset.map(lambda x_int, y_str: x_int)\n",
      " |      >>> list(result.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\n",
      " |      >>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
      " |      ...               {\"a\": 2, \"b\": \"bar\"},\n",
      " |      ...               {\"a\": 3, \"b\": \"baz\"}])\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
      " |      >>> # `map_func` takes a single argument of type `dict` with the same keys\n",
      " |      >>> # as the elements.\n",
      " |      >>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
      " |      \n",
      " |      The value or values returned by `map_func` determine the structure of each\n",
      " |      element in the returned dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> # `map_func` returns two `tf.Tensor` objects.\n",
      " |      >>> def g(x):\n",
      " |      ...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
      " |      >>> result = dataset.map(g)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.string, name=None))\n",
      " |      >>> # Python primitives, lists, and NumPy arrays are implicitly converted to\n",
      " |      >>> # `tf.Tensor`.\n",
      " |      >>> def h(x):\n",
      " |      ...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\n",
      " |      >>> result = dataset.map(h)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, name=None))\n",
      " |      >>> # `map_func` can return nested structures.\n",
      " |      >>> def i(x):\n",
      " |      ...   return (37.0, [42, 16]), \"foo\"\n",
      " |      >>> result = dataset.map(i)\n",
      " |      >>> result.element_spec\n",
      " |      ((TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
      " |        TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\n",
      " |       TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      " |      \n",
      " |      `map_func` can accept as arguments and return any type of dataset element.\n",
      " |      \n",
      " |      Note that irrespective of the context in which `map_func` is defined (eager\n",
      " |      vs. graph), tf.data traces the function and executes it as a graph. To use\n",
      " |      Python code inside of the function you have a few options:\n",
      " |      \n",
      " |      1) Rely on AutoGraph to convert Python code into an equivalent graph\n",
      " |      computation. The downside of this approach is that AutoGraph can convert\n",
      " |      some but not all Python code.\n",
      " |      \n",
      " |      2) Use `tf.py_function`, which allows you to write arbitrary Python code but\n",
      " |      will generally result in worse performance than 1). For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> # transform a string tensor to upper case string using a Python function\n",
      " |      >>> def upper_case_fn(t: tf.Tensor):\n",
      " |      ...   return t.numpy().decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      3) Use `tf.numpy_function`, which also allows you to write arbitrary\n",
      " |      Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\n",
      " |      `tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\n",
      " |      For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> def upper_case_fn(t: np.ndarray):\n",
      " |      ...   return t.decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      Note that the use of `tf.numpy_function` and `tf.py_function`\n",
      " |      in general precludes the possibility of executing user-defined\n",
      " |      transformations in parallel (because of Python GIL).\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `map` will use multiple threads to process elements. If deterministic order\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1,\n",
      " |      ...     num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      The order of elements yielded by this transformation is deterministic if\n",
      " |      `deterministic=True`. If `map_func` contains stateful operations and\n",
      " |      `num_parallel_calls > 1`, the order in which that state is accessed is\n",
      " |      undefined, so the values of output elements may not be deterministic\n",
      " |      regardless of the `deterministic` flag value.\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to another dataset element.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      " |          representing the number elements to process asynchronously in parallel.\n",
      " |          If not specified, elements will be processed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  options(self)\n",
      " |      Returns the options for this dataset and its inputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.data.Options` object representing the dataset options.\n",
      " |  \n",
      " |  padded_batch(self, batch_size, padded_shapes=None, padding_values=None, drop_remainder=False, name=None)\n",
      " |      Combines consecutive elements of this dataset into padded batches.\n",
      " |      \n",
      " |      This transformation combines multiple consecutive elements of the input\n",
      " |      dataset into a single element.\n",
      " |      \n",
      " |      Like `tf.data.Dataset.batch`, the components of the resulting element will\n",
      " |      have an additional outer dimension, which will be `batch_size` (or\n",
      " |      `N % batch_size` for the last element if `batch_size` does not divide the\n",
      " |      number of input elements `N` evenly and `drop_remainder` is `False`). If\n",
      " |      your program depends on the batches having the same outer dimension, you\n",
      " |      should set the `drop_remainder` argument to `True` to prevent the smaller\n",
      " |      batch from being produced.\n",
      " |      \n",
      " |      Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\n",
      " |      different shapes, and this transformation will pad each component to the\n",
      " |      respective shape in `padded_shapes`. The `padded_shapes` argument\n",
      " |      determines the resulting shape for each dimension of each component in an\n",
      " |      output element:\n",
      " |      \n",
      " |      * If the dimension is a constant, the component will be padded out to that\n",
      " |        length in that dimension.\n",
      " |      * If the dimension is unknown, the component will be padded out to the\n",
      " |        maximum length of all elements in that dimension.\n",
      " |      \n",
      " |      >>> A = (tf.data.Dataset\n",
      " |      ...      .range(1, 5, output_type=tf.int32)\n",
      " |      ...      .map(lambda x: tf.fill([x], x)))\n",
      " |      >>> # Pad to the smallest per-batch size that fits all elements.\n",
      " |      >>> B = A.padded_batch(2)\n",
      " |      >>> for element in B.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0]\n",
      " |       [2 2]]\n",
      " |      [[3 3 3 0]\n",
      " |       [4 4 4 4]]\n",
      " |      >>> # Pad to a fixed size.\n",
      " |      >>> C = A.padded_batch(2, padded_shapes=5)\n",
      " |      >>> for element in C.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0 0 0 0]\n",
      " |       [2 2 0 0 0]]\n",
      " |      [[3 3 3 0 0]\n",
      " |       [4 4 4 4 0]]\n",
      " |      >>> # Pad with a custom value.\n",
      " |      >>> D = A.padded_batch(2, padded_shapes=5, padding_values=-1)\n",
      " |      >>> for element in D.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[ 1 -1 -1 -1 -1]\n",
      " |       [ 2  2 -1 -1 -1]]\n",
      " |      [[ 3  3  3 -1 -1]\n",
      " |       [ 4  4  4  4 -1]]\n",
      " |      >>> # Components of nested elements can be padded independently.\n",
      " |      >>> elements = [([1, 2, 3], [10]),\n",
      " |      ...             ([4, 5], [11, 12])]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: iter(elements), (tf.int32, tf.int32))\n",
      " |      >>> # Pad the first component of the tuple to length 4, and the second\n",
      " |      >>> # component to the smallest size that fits.\n",
      " |      >>> dataset = dataset.padded_batch(2,\n",
      " |      ...     padded_shapes=([4], [None]),\n",
      " |      ...     padding_values=(-1, 100))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([[ 1,  2,  3, -1], [ 4,  5, -1, -1]], dtype=int32),\n",
      " |        array([[ 10, 100], [ 11,  12]], dtype=int32))]\n",
      " |      >>> # Pad with a single value and multiple components.\n",
      " |      >>> E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\n",
      " |      >>> for element in E.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32), array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32))\n",
      " |      (array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32), array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32))\n",
      " |      \n",
      " |      See also `tf.data.experimental.dense_to_sparse_batch`, which combines\n",
      " |      elements that may have different shapes into a `tf.sparse.SparseTensor`.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        padded_shapes: (Optional.) A (nested) structure of `tf.TensorShape` or\n",
      " |          `tf.int64` vector tensor-like objects representing the shape to which\n",
      " |          the respective component of each input element should be padded prior\n",
      " |          to batching. Any unknown dimensions will be padded to the maximum size\n",
      " |          of that dimension in each batch. If unset, all dimensions of all\n",
      " |          components are padded to the maximum size in the batch. `padded_shapes`\n",
      " |          must be set if any component has an unknown rank.\n",
      " |        padding_values: (Optional.) A (nested) structure of scalar-shaped\n",
      " |          `tf.Tensor`, representing the padding values to use for the respective\n",
      " |          components. None represents that the (nested) structure should be padded\n",
      " |          with default values.  Defaults are `0` for numeric types and the empty\n",
      " |          string for string types. The `padding_values` should have the same\n",
      " |          (nested) structure as the input dataset. If `padding_values` is a single\n",
      " |          element and the input dataset has multiple components, then the same\n",
      " |          `padding_values` will be used to pad every component of the dataset.\n",
      " |          If `padding_values` is a scalar, then its value will be broadcasted\n",
      " |          to match the shape of each component.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If a component has an unknown rank, and the `padded_shapes`\n",
      " |          argument is not set.\n",
      " |        TypeError: If a component is of an unsupported type. The list of supported\n",
      " |          types is documented in\n",
      " |          https://www.tensorflow.org/guide/data#dataset_structure.\n",
      " |  \n",
      " |  prefetch(self, buffer_size, name=None)\n",
      " |      Creates a `Dataset` that prefetches elements from this dataset.\n",
      " |      \n",
      " |      Most dataset input pipelines should end with a call to `prefetch`. This\n",
      " |      allows later elements to be prepared while the current element is being\n",
      " |      processed. This often improves latency and throughput, at the cost of\n",
      " |      using additional memory to store prefetched elements.\n",
      " |      \n",
      " |      Note: Like other `Dataset` methods, prefetch operates on the\n",
      " |      elements of the input dataset. It has no concept of examples vs. batches.\n",
      " |      `examples.prefetch(2)` will prefetch two elements (2 examples),\n",
      " |      while `examples.batch(20).prefetch(2)` will prefetch 2 elements\n",
      " |      (2 batches, of 20 examples each).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.prefetch(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the maximum\n",
      " |          number of elements that will be buffered when prefetching. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the buffer size is dynamically tuned.\n",
      " |        name: Optional. A name for the tf.data transformation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  reduce(self, initial_state, reduce_func, name=None)\n",
      " |      Reduces the input dataset to a single element.\n",
      " |      \n",
      " |      The transformation calls `reduce_func` successively on every element of\n",
      " |      the input dataset until the dataset is exhausted, aggregating information in\n",
      " |      its internal state. The `initial_state` argument is used for the initial\n",
      " |      state and the final state is returned as the result.\n",
      " |      \n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
      " |      5\n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()\n",
      " |      10\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: An element representing the initial state of the\n",
      " |          transformation.\n",
      " |        reduce_func: A function that maps `(old_state, input_element)` to\n",
      " |          `new_state`. It must take two arguments and return a new element\n",
      " |          The structure of `new_state` must match the structure of\n",
      " |          `initial_state`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset element corresponding to the final state of the transformation.\n",
      " |  \n",
      " |  rejection_resample(self, class_func, target_dist, initial_dist=None, seed=None, name=None)\n",
      " |      A transformation that resamples a dataset to a target distribution.\n",
      " |      \n",
      " |      Lets consider the following example where a dataset with an initial data\n",
      " |      distribution of `init_dist` needs to be resampled into a dataset with\n",
      " |      `target_dist` distribution.\n",
      " |      \n",
      " |      >>> initial_dist = [0.6, 0.4]\n",
      " |      >>> num_classes = len(initial_dist)\n",
      " |      >>> num_samples = 1000\n",
      " |      >>> data_np = np.random.choice(num_classes, num_samples, p=initial_dist)\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(data_np)\n",
      " |      \n",
      " |      The value of `x` will be close to `{0: 50000, 1: 50000}` as per the\n",
      " |      `initial_dist` distribution.\n",
      " |      \n",
      " |      >>> target_dist = [0.5, 0.5]\n",
      " |      >>> resampled_dataset = dataset.rejection_resample(\n",
      " |      ...    class_func=lambda x: x,\n",
      " |      ...    target_dist=target_dist,\n",
      " |      ...    initial_dist=initial_dist)\n",
      " |      >>> resampled_dataset = resampled_dataset.map(\n",
      " |      ...     lambda class_func_result, data: data)\n",
      " |      \n",
      " |      \n",
      " |      The value distribution of classes in the resampled_distribution will be now\n",
      " |      be close to the target distribution.\n",
      " |      \n",
      " |      Args:\n",
      " |        class_func: A function mapping an element of the input dataset to a scalar\n",
      " |          `tf.int32` tensor. Values should be in `[0, num_classes)`.\n",
      " |        target_dist: A floating point type tensor, shaped `[num_classes]`.\n",
      " |        initial_dist: (Optional.)  A floating point type tensor, shaped\n",
      " |          `[num_classes]`.  If not provided, the true class distribution is\n",
      " |          estimated live in a streaming fashion.\n",
      " |        seed: (Optional.) Python integer seed for the resampler.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`\n",
      " |  \n",
      " |  repeat(self, count=None, name=None)\n",
      " |      Repeats this dataset so each original value is seen `count` times.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.repeat(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      " |      \n",
      " |      Note: If the input dataset depends on global state (e.g. a random number\n",
      " |      generator) or its output is non-deterministic (e.g. because of upstream\n",
      " |      `shuffle`), then different repetitions may produce different elements.\n",
      " |      \n",
      " |      Args:\n",
      " |        count: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of times the dataset should be repeated. The default behavior (if\n",
      " |          `count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  scan(self, initial_state, scan_func, name=None)\n",
      " |      A transformation that scans a function across an input dataset.\n",
      " |      \n",
      " |      This transformation is a stateful relative of `tf.data.Dataset.map`.\n",
      " |      In addition to mapping `scan_func` across the elements of the input dataset,\n",
      " |      `scan()` accumulates one or more state tensors, whose initial values are\n",
      " |      `initial_state`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> initial_state = tf.constant(0, dtype=tf.int64)\n",
      " |      >>> scan_func = lambda state, i: (state + i, state + i)\n",
      " |      >>> dataset = dataset.scan(initial_state=initial_state, scan_func=scan_func)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: A nested structure of tensors, representing the initial\n",
      " |          state of the accumulator.\n",
      " |        scan_func: A function that maps `(old_state, input_element)` to\n",
      " |          `(new_state, output_element)`. It must take two arguments and return a\n",
      " |          pair of nested structures of tensors. The `new_state` must match the\n",
      " |          structure of `initial_state`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  shard(self, num_shards, index, name=None)\n",
      " |      Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      " |      \n",
      " |      `shard` is deterministic. The Dataset produced by `A.shard(n, i)` will\n",
      " |      contain all elements of A whose index mod n = i.\n",
      " |      \n",
      " |      >>> A = tf.data.Dataset.range(10)\n",
      " |      >>> B = A.shard(num_shards=3, index=0)\n",
      " |      >>> list(B.as_numpy_iterator())\n",
      " |      [0, 3, 6, 9]\n",
      " |      >>> C = A.shard(num_shards=3, index=1)\n",
      " |      >>> list(C.as_numpy_iterator())\n",
      " |      [1, 4, 7]\n",
      " |      >>> D = A.shard(num_shards=3, index=2)\n",
      " |      >>> list(D.as_numpy_iterator())\n",
      " |      [2, 5, 8]\n",
      " |      \n",
      " |      This dataset operator is very useful when running distributed training, as\n",
      " |      it allows each worker to read a unique subset.\n",
      " |      \n",
      " |      When reading a single input file, you can shard elements as follows:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = tf.data.TFRecordDataset(input_file)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Important caveats:\n",
      " |      \n",
      " |      - Be sure to shard before you use any randomizing operator (such as\n",
      " |        shuffle).\n",
      " |      - Generally it is best if the shard operator is used early in the dataset\n",
      " |        pipeline. For example, when reading from a set of TFRecord files, shard\n",
      " |        before converting the dataset to input samples. This avoids reading every\n",
      " |        file on every worker. The following is an example of an efficient\n",
      " |        sharding strategy within a complete pipeline:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = Dataset.list_files(pattern)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.interleave(tf.data.TFRecordDataset,\n",
      " |                       cycle_length=num_readers, block_length=1)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        num_shards: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          shards operating in parallel.\n",
      " |        index: A `tf.int64` scalar `tf.Tensor`, representing the worker index.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: if `num_shards` or `index` are illegal values.\n",
      " |      \n",
      " |          Note: error checking is done on a best-effort basis, and errors aren't\n",
      " |          guaranteed to be caught upon dataset creation. (e.g. providing in a\n",
      " |          placeholder tensor bypasses the early checking, and will instead result\n",
      " |          in an error during a session.run call.)\n",
      " |  \n",
      " |  shuffle(self, buffer_size, seed=None, reshuffle_each_iteration=None, name=None)\n",
      " |      Randomly shuffles the elements of this dataset.\n",
      " |      \n",
      " |      This dataset fills a buffer with `buffer_size` elements, then randomly\n",
      " |      samples elements from this buffer, replacing the selected elements with new\n",
      " |      elements. For perfect shuffling, a buffer size greater than or equal to the\n",
      " |      full size of the dataset is required.\n",
      " |      \n",
      " |      For instance, if your dataset contains 10,000 elements but `buffer_size` is\n",
      " |      set to 1,000, then `shuffle` will initially select a random element from\n",
      " |      only the first 1,000 elements in the buffer. Once an element is selected,\n",
      " |      its space in the buffer is replaced by the next (i.e. 1,001-st) element,\n",
      " |      maintaining the 1,000 element buffer.\n",
      " |      \n",
      " |      `reshuffle_each_iteration` controls whether the shuffle order should be\n",
      " |      different for each epoch. In TF 1.X, the idiomatic way to create epochs\n",
      " |      was through the `repeat` transformation:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      dataset = dataset.repeat(2)\n",
      " |      # [1, 0, 2, 1, 2, 0]\n",
      " |      \n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      dataset = dataset.repeat(2)\n",
      " |      # [1, 0, 2, 1, 0, 2]\n",
      " |      ```\n",
      " |      \n",
      " |      In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it\n",
      " |      possible to also create epochs through Python iteration:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 2, 0]\n",
      " |      ```\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements from this dataset from which the new dataset will sample.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        reshuffle_each_iteration: (Optional.) A boolean, which if true indicates\n",
      " |          that the dataset should be pseudorandomly reshuffled each time it is\n",
      " |          iterated over. (Defaults to `True`.)\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  skip(self, count, name=None)\n",
      " |      Creates a `Dataset` that skips `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.skip(7)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [7, 8, 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be skipped to form the new dataset.\n",
      " |          If `count` is greater than the size of this dataset, the new dataset\n",
      " |          will contain no elements.  If `count` is -1, skips the entire dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  snapshot(self, path, compression='AUTO', reader_func=None, shard_func=None, name=None)\n",
      " |      API to persist the output of the input dataset.\n",
      " |      \n",
      " |      The snapshot API allows users to transparently persist the output of their\n",
      " |      preprocessing pipeline to disk, and materialize the pre-processed data on a\n",
      " |      different training run.\n",
      " |      \n",
      " |      This API enables repeated preprocessing steps to be consolidated, and allows\n",
      " |      re-use of already processed data, trading off disk storage and network\n",
      " |      bandwidth for freeing up more valuable CPU resources and accelerator compute\n",
      " |      time.\n",
      " |      \n",
      " |      https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md\n",
      " |      has detailed design documentation of this feature.\n",
      " |      \n",
      " |      Users can specify various options to control the behavior of snapshot,\n",
      " |      including how snapshots are read from and written to by passing in\n",
      " |      user-defined functions to the `reader_func` and `shard_func` parameters.\n",
      " |      \n",
      " |      `shard_func` is a user specified function that maps input elements to\n",
      " |      snapshot shards.\n",
      " |      \n",
      " |      Users may want to specify this function to control how snapshot files should\n",
      " |      be written to disk. Below is an example of how a potential `shard_func`\n",
      " |      could be written.\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = ...\n",
      " |      dataset = dataset.enumerate()\n",
      " |      dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      " |          shard_func=lambda x, y: x % NUM_SHARDS, ...)\n",
      " |      dataset = dataset.map(lambda x, y: y)\n",
      " |      ```\n",
      " |      \n",
      " |      `reader_func` is a user specified function that accepts a single argument:\n",
      " |      (1) a Dataset of Datasets, each representing a \"split\" of elements of the\n",
      " |      original dataset. The cardinality of the input dataset matches the\n",
      " |      number of the shards specified in the `shard_func` (see above). The function\n",
      " |      should return a Dataset of elements of the original dataset.\n",
      " |      \n",
      " |      Users may want specify this function to control how snapshot files should be\n",
      " |      read from disk, including the amount of shuffling and parallelism.\n",
      " |      \n",
      " |      Here is an example of a standard reader function a user can define. This\n",
      " |      function enables both dataset shuffling and parallel reading of datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      def user_reader_func(datasets):\n",
      " |        # shuffle the datasets splits\n",
      " |        datasets = datasets.shuffle(NUM_CORES)\n",
      " |        # read datasets in parallel and interleave their elements\n",
      " |        return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\n",
      " |      \n",
      " |      dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      " |          reader_func=user_reader_func)\n",
      " |      ```\n",
      " |      \n",
      " |      By default, snapshot parallelizes reads by the number of cores available on\n",
      " |      the system, but will not attempt to shuffle the data.\n",
      " |      \n",
      " |      Args:\n",
      " |        path: Required. A directory to use for storing / loading the snapshot to /\n",
      " |          from.\n",
      " |        compression: Optional. The type of compression to apply to the snapshot\n",
      " |          written to disk. Supported options are `GZIP`, `SNAPPY`, `AUTO` or None.\n",
      " |          Defaults to `AUTO`, which attempts to pick an appropriate compression\n",
      " |          algorithm for the dataset.\n",
      " |        reader_func: Optional. A function to control how to read data from\n",
      " |          snapshot shards.\n",
      " |        shard_func: Optional. A function to control how to shard data when writing\n",
      " |          a snapshot.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  take(self, count, name=None)\n",
      " |      Creates a `Dataset` with at most `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be taken to form the new dataset.\n",
      " |          If `count` is -1, or if `count` is greater than the size of this\n",
      " |          dataset, the new dataset will contain all elements of this dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  take_while(self, predicate, name=None)\n",
      " |      A transformation that stops dataset iteration based on a `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take_while(lambda x: x < 5)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function that maps a nested structure of tensors (having\n",
      " |          shapes and types defined by `self.output_shapes` and\n",
      " |          `self.output_types`) to a scalar `tf.bool` tensor.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  unbatch(self, name=None)\n",
      " |      Splits elements of a dataset into multiple elements.\n",
      " |      \n",
      " |      For example, if elements of the dataset are shaped `[B, a0, a1, ...]`,\n",
      " |      where `B` may vary for each input element, then for each element in the\n",
      " |      dataset, the unbatched dataset will contain `B` consecutive elements\n",
      " |      of shape `[a0, a1, ...]`.\n",
      " |      \n",
      " |      >>> elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
      " |      >>> dataset = dataset.unbatch()\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Note: `unbatch` requires a data copy to slice up the batched tensor into\n",
      " |      smaller, unbatched tensors. When optimizing performance, try to avoid\n",
      " |      unnecessary usage of `unbatch`.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  unique(self, name=None)\n",
      " |      A transformation that discards duplicate elements of a `Dataset`.\n",
      " |      \n",
      " |      Use this transformation to produce a dataset that contains one instance of\n",
      " |      each unique element in the input. For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
      " |      >>> dataset = dataset.unique()\n",
      " |      >>> sorted(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 37]\n",
      " |      \n",
      " |      Note: This transformation only supports datasets which fit into memory\n",
      " |      and have elements of either `tf.int32`, `tf.int64` or `tf.string` type.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  window(self, size, shift=None, stride=1, drop_remainder=False, name=None)\n",
      " |      Returns a dataset of \"windows\".\n",
      " |      \n",
      " |      Each \"window\" is a dataset that contains a subset of elements of the\n",
      " |      input dataset. These are finite datasets of size `size` (or possibly fewer\n",
      " |      if there are not enough input elements to fill the window and\n",
      " |      `drop_remainder` evaluates to `False`).\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(window)\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      \n",
      " |      Since windows are datasets, they can be iterated over:\n",
      " |      \n",
      " |      >>> for window in dataset:\n",
      " |      ...   print([item.numpy() for item in window])\n",
      " |      [0, 1, 2]\n",
      " |      [3, 4, 5]\n",
      " |      [6]\n",
      " |      \n",
      " |      #### Shift\n",
      " |      \n",
      " |      The `shift` argument determines the number of input elements to shift\n",
      " |      between the start of each window. If windows and elements are both numbered\n",
      " |      starting at 0, the first element in window `k` will be element `k * shift`\n",
      " |      of the input dataset. In particular, the first element of the first window\n",
      " |      will always be the first element of the input dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 1, 2]\n",
      " |      [1, 2, 3]\n",
      " |      [2, 3, 4]\n",
      " |      [3, 4, 5]\n",
      " |      [4, 5, 6]\n",
      " |      \n",
      " |      #### Stride\n",
      " |      \n",
      " |      The `stride` argument determines the stride between input elements within a\n",
      " |      window.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 2, 4]\n",
      " |      [1, 3, 5]\n",
      " |      [2, 4, 6]\n",
      " |      \n",
      " |      #### Nested elements\n",
      " |      \n",
      " |      When the `window` transformation is applied to a dataset whos elements are\n",
      " |      nested structures, it produces a dataset where the elements have the same\n",
      " |      nested structure but each leaf is replaced by a window. In other words,\n",
      " |      the nesting is applied outside of the windows as opposed inside of them.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def window(\n",
      " |          self: Dataset[Nest[T]], ...\n",
      " |      ) -> Dataset[Nest[Dataset[T]]]\n",
      " |      ```\n",
      " |      \n",
      " |      Applying `window` to a `Dataset` of tuples gives a tuple of windows:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
      " |      ...                                               [6, 7, 8, 9, 10]))\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> windows = next(iter(dataset))\n",
      " |      >>> windows\n",
      " |      (<...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>,\n",
      " |       <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>)\n",
      " |      \n",
      " |      >>> def to_numpy(ds):\n",
      " |      ...   return list(ds.as_numpy_iterator())\n",
      " |      >>>\n",
      " |      >>> for windows in dataset:\n",
      " |      ...   print(to_numpy(windows[0]), to_numpy(windows[1]))\n",
      " |      [1, 2] [6, 7]\n",
      " |      [3, 4] [8, 9]\n",
      " |      [5] [10]\n",
      " |      \n",
      " |      Applying `window` to a `Dataset` of dictionaries gives a dictionary of\n",
      " |      `Datasets`:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3],\n",
      " |      ...                                               'b': [4, 5, 6],\n",
      " |      ...                                               'c': [7, 8, 9]})\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> def to_numpy(ds):\n",
      " |      ...   return list(ds.as_numpy_iterator())\n",
      " |      >>>\n",
      " |      >>> for windows in dataset:\n",
      " |      ...   print(tf.nest.map_structure(to_numpy, windows))\n",
      " |      {'a': [1, 2], 'b': [4, 5], 'c': [7, 8]}\n",
      " |      {'a': [3], 'b': [6], 'c': [9]}\n",
      " |      \n",
      " |      #### Flatten a dataset of windows\n",
      " |      \n",
      " |      The `Dataset.flat_map` and `Dataset.interleave` methods can be used to\n",
      " |      flatten a dataset of windows into a single dataset.\n",
      " |      \n",
      " |      The argument to `flat_map` is a function that takes an element from the\n",
      " |      dataset and returns a `Dataset`. `flat_map` chains together the resulting\n",
      " |      datasets sequentially.\n",
      " |      \n",
      " |      For example, to turn each window into a dense tensor:\n",
      " |      \n",
      " |      >>> size = 3\n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> batched = dataset.flat_map(lambda x:x.batch(3))\n",
      " |      >>> for batch in batched:\n",
      " |      ...   print(batch.numpy())\n",
      " |      [0 1 2]\n",
      " |      [1 2 3]\n",
      " |      [2 3 4]\n",
      " |      [3 4 5]\n",
      " |      [4 5 6]\n",
      " |      \n",
      " |      Args:\n",
      " |        size: A `tf.int64` scalar `tf.Tensor`, representing the number of elements\n",
      " |          of the input dataset to combine into a window. Must be positive.\n",
      " |        shift: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of input elements by which the window moves in each iteration.\n",
      " |          Defaults to `size`. Must be positive.\n",
      " |        stride: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          stride of the input elements in the sliding window. Must be positive.\n",
      " |          The default value of 1 means \"retain every input element\".\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last windows should be dropped if their size is smaller than\n",
      " |          `size`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` of (nests of) windows. Each window is a finite\n",
      " |          datasets of flat elements.\n",
      " |  \n",
      " |  with_options(self, options, name=None)\n",
      " |      Returns a new `tf.data.Dataset` with the given options set.\n",
      " |      \n",
      " |      The options are \"global\" in the sense they apply to the entire dataset.\n",
      " |      If options are set multiple times, they are merged as long as different\n",
      " |      options do not use different non-default values.\n",
      " |      \n",
      " |      >>> ds = tf.data.Dataset.range(5)\n",
      " |      >>> ds = ds.interleave(lambda x: tf.data.Dataset.range(5),\n",
      " |      ...                    cycle_length=3,\n",
      " |      ...                    num_parallel_calls=3)\n",
      " |      >>> options = tf.data.Options()\n",
      " |      >>> # This will make the interleave order non-deterministic.\n",
      " |      >>> options.deterministic = False\n",
      " |      >>> ds = ds.with_options(options)\n",
      " |      \n",
      " |      Args:\n",
      " |        options: A `tf.data.Options` that identifies the options the use.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` with the given options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: when an option is set more than once to a non-default value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from DatasetV2:\n",
      " |  \n",
      " |  choose_from_datasets(datasets, choice_dataset, stop_on_empty_dataset=True)\n",
      " |      Creates a dataset that deterministically chooses elements from `datasets`.\n",
      " |      \n",
      " |      For example, given the following datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      datasets = [tf.data.Dataset.from_tensors(\"foo\").repeat(),\n",
      " |                  tf.data.Dataset.from_tensors(\"bar\").repeat(),\n",
      " |                  tf.data.Dataset.from_tensors(\"baz\").repeat()]\n",
      " |      \n",
      " |      # Define a dataset containing `[0, 1, 2, 0, 1, 2, 0, 1, 2]`.\n",
      " |      choice_dataset = tf.data.Dataset.range(3).repeat(3)\n",
      " |      \n",
      " |      result = tf.data.Dataset.choose_from_datasets(datasets, choice_dataset)\n",
      " |      ```\n",
      " |      \n",
      " |      The elements of `result` will be:\n",
      " |      \n",
      " |      ```\n",
      " |      \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\"\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      " |          structure.\n",
      " |        choice_dataset: A `tf.data.Dataset` of scalar `tf.int64` tensors between\n",
      " |          `0` and `len(datasets) - 1`.\n",
      " |        stop_on_empty_dataset: If `True`, selection stops if it encounters an\n",
      " |          empty dataset. If `False`, it skips empty datasets. It is recommended to\n",
      " |          set it to `True`. Otherwise, the selected elements start off as the user\n",
      " |          intends, but may change as input datasets become empty. This can be\n",
      " |          difficult to detect since the dataset starts off looking correct.\n",
      " |          Defaults to `True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset that interleaves elements from `datasets` according to the\n",
      " |        values of `choice_dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `datasets` or `choice_dataset` has the wrong type.\n",
      " |        ValueError: If `datasets` is empty.\n",
      " |  \n",
      " |  from_generator(generator, output_types=None, output_shapes=None, args=None, output_signature=None, name=None)\n",
      " |      Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      " |      \n",
      " |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(output_shapes, output_types)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Use output_signature instead\n",
      " |      \n",
      " |      Note: The current implementation of `Dataset.from_generator()` uses\n",
      " |      `tf.numpy_function` and inherits the same constraints. In particular, it\n",
      " |      requires the dataset and iterator related operations to be placed\n",
      " |      on a device in the same process as the Python program that called\n",
      " |      `Dataset.from_generator()`. In particular, using `from_generator` will\n",
      " |      preclude the use of tf.data service for scaling out dataset processing.\n",
      " |      The body of `generator` will not be serialized in a `GraphDef`, and you\n",
      " |      should not use this method if you need to serialize your model and restore\n",
      " |      it in a different environment.\n",
      " |      \n",
      " |      The `generator` argument must be a callable object that returns\n",
      " |      an object that supports the `iter()` protocol (e.g. a generator function).\n",
      " |      \n",
      " |      The elements generated by `generator` must be compatible with either the\n",
      " |      given `output_signature` argument or with the given `output_types` and\n",
      " |      (optionally) `output_shapes` arguments, whichever was specified.\n",
      " |      \n",
      " |      The recommended way to call `from_generator` is to use the\n",
      " |      `output_signature` argument. In this case the output will be assumed to\n",
      " |      consist of objects with the classes, shapes and types defined by\n",
      " |      `tf.TypeSpec` objects from `output_signature` argument:\n",
      " |      \n",
      " |      >>> def gen():\n",
      " |      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n",
      " |      ...   yield 42, ragged_tensor\n",
      " |      >>>\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...      gen,\n",
      " |      ...      output_signature=(\n",
      " |      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n",
      " |      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n",
      " |      >>>\n",
      " |      >>> list(dataset.take(1))\n",
      " |      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n",
      " |      <tf.RaggedTensor [[1, 2], [3]]>)]\n",
      " |      \n",
      " |      There is also a deprecated way to call `from_generator` by either with\n",
      " |      `output_types` argument alone or together with `output_shapes` argument.\n",
      " |      In this case the output of the function will be assumed to consist of\n",
      " |      `tf.Tensor` objects with the types defined by `output_types` and with the\n",
      " |      shapes which are either unknown or defined by `output_shapes`.\n",
      " |      \n",
      " |      Note: If `generator` depends on mutable global variables or other external\n",
      " |      state, be aware that the runtime may invoke `generator` multiple times\n",
      " |      (in order to support repeating the `Dataset`) and at any time\n",
      " |      between the call to `Dataset.from_generator()` and the production of the\n",
      " |      first element from the generator. Mutating global variables or external\n",
      " |      state can cause undefined behavior, and we recommend that you explicitly\n",
      " |      cache any external state in `generator` before calling\n",
      " |      `Dataset.from_generator()`.\n",
      " |      \n",
      " |      Note: While the `output_signature` parameter makes it possible to yield\n",
      " |      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n",
      " |      limited to logic that cannot be expressed through tf.data operations. Using\n",
      " |      tf.data operations within the generator function is an anti-pattern and may\n",
      " |      result in incremental memory growth.\n",
      " |      \n",
      " |      Args:\n",
      " |        generator: A callable object that returns an object that supports the\n",
      " |          `iter()` protocol. If `args` is not specified, `generator` must take no\n",
      " |          arguments; otherwise it must take as many arguments as there are values\n",
      " |          in `args`.\n",
      " |        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n",
      " |          corresponding to each component of an element yielded by `generator`.\n",
      " |        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape`\n",
      " |          objects corresponding to each component of an element yielded by\n",
      " |          `generator`.\n",
      " |        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\n",
      " |          and passed to `generator` as NumPy-array arguments.\n",
      " |        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec`\n",
      " |          objects corresponding to each component of an element yielded by\n",
      " |          `generator`.\n",
      " |        name: (Optional.) A name for the tf.data operations used by\n",
      " |          `from_generator`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensor_slices(tensors, name=None)\n",
      " |      Creates a `Dataset` whose elements are slices of the given tensors.\n",
      " |      \n",
      " |      The given tensors are sliced along their first dimension. This operation\n",
      " |      preserves the structure of the input tensors, removing the first dimension\n",
      " |      of each tensor and using it as the dataset dimension. All input tensors\n",
      " |      must have the same size in their first dimensions.\n",
      " |      \n",
      " |      >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      " |      \n",
      " |      >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      " |      >>> # scalar tensors.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(1, 3, 5), (2, 4, 6)]\n",
      " |      \n",
      " |      >>> # Dictionary structure is also preserved.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      " |      ...                                       {'a': 2, 'b': 4}]\n",
      " |      True\n",
      " |      \n",
      " |      >>> # Two tensors can be combined into one Dataset object.\n",
      " |      >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      " |      >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      " |      >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      " |      >>> # Both the features and the labels tensors can be converted\n",
      " |      >>> # to a Dataset object separately and combined after.\n",
      " |      >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      " |      >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      " |      >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      " |      >>> # A batched feature and label set can be converted to a Dataset\n",
      " |      >>> # in similar fashion.\n",
      " |      >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      " |      ...                                 [[2, 1], [1, 2]],\n",
      " |      ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      " |      >>> batched_labels = tf.constant([['A', 'A'],\n",
      " |      ...                               ['B', 'B'],\n",
      " |      ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      " |      >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[1, 3],\n",
      " |             [2, 3]], dtype=int32), array([[b'A'],\n",
      " |             [b'A']], dtype=object))\n",
      " |      (array([[2, 1],\n",
      " |             [1, 2]], dtype=int32), array([[b'B'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      (array([[3, 3],\n",
      " |             [3, 2]], dtype=int32), array([[b'A'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this guide](\n",
      " |      https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset element, whose components have the same first\n",
      " |          dimension. Supported values are documented\n",
      " |          [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensors(tensors, name=None)\n",
      " |      Creates a `Dataset` with a single element, comprising the given tensors.\n",
      " |      \n",
      " |      `from_tensors` produces a dataset containing only a single element. To slice\n",
      " |      the input tensor into multiple elements, use `from_tensor_slices` instead.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32)]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([1, 2, 3], dtype=int32), b'A')]\n",
      " |      \n",
      " |      >>> # You can use `from_tensors` to produce a dataset which repeats\n",
      " |      >>> # the same example many times.\n",
      " |      >>> example = tf.constant([1,2,3])\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this\n",
      " |      guide](https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset \"element\". Supported values are documented\n",
      " |          [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  list_files(file_pattern, shuffle=None, seed=None, name=None)\n",
      " |      A dataset of all files matching one or more glob patterns.\n",
      " |      \n",
      " |      The `file_pattern` argument should be a small number of glob patterns.\n",
      " |      If your filenames have already been globbed, use\n",
      " |      `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\n",
      " |      filename with `list_files` may result in poor performance with remote\n",
      " |      storage systems.\n",
      " |      \n",
      " |      Note: The default behavior of this method is to return filenames in\n",
      " |      a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\n",
      " |      to get results in a deterministic order.\n",
      " |      \n",
      " |      Example:\n",
      " |        If we had the following files on our filesystem:\n",
      " |      \n",
      " |          - /path/to/dir/a.txt\n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |        If we pass \"/path/to/dir/*.py\" as the directory, the dataset\n",
      " |        would produce:\n",
      " |      \n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |      Args:\n",
      " |        file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\n",
      " |          (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
      " |          pattern(s) that will be matched.\n",
      " |        shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\n",
      " |          Defaults to `True`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        name: Optional. A name for the tf.data operations used by `list_files`.\n",
      " |      \n",
      " |      Returns:\n",
      " |       Dataset: A `Dataset` of strings corresponding to file names.\n",
      " |  \n",
      " |  random(seed=None, name=None)\n",
      " |      Creates a `Dataset` of pseudorandom values.\n",
      " |      \n",
      " |      The dataset generates a sequence of uniformly distributed integer values.\n",
      " |      \n",
      " |      >>> ds1 = tf.data.Dataset.random(seed=4).take(10)\n",
      " |      >>> ds2 = tf.data.Dataset.random(seed=4).take(10)\n",
      " |      >>> print(list(ds2.as_numpy_iterator())==list(ds2.as_numpy_iterator()))\n",
      " |      True\n",
      " |      \n",
      " |      Args:\n",
      " |        seed: (Optional) If specified, the dataset produces a deterministic\n",
      " |          sequence of values.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  range(*args, **kwargs)\n",
      " |      Creates a `Dataset` of a step-separated range of values.\n",
      " |      \n",
      " |      >>> list(Dataset.range(5).as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      >>> list(Dataset.range(2, 5).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2).as_numpy_iterator())\n",
      " |      [1, 3]\n",
      " |      >>> list(Dataset.range(1, 5, -2).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1, -2).as_numpy_iterator())\n",
      " |      [5, 3]\n",
      " |      >>> list(Dataset.range(2, 5, output_type=tf.int32).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2, output_type=tf.float32).as_numpy_iterator())\n",
      " |      [1.0, 3.0]\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: follows the same semantics as python's range.\n",
      " |          len(args) == 1 -> start = 0, stop = args[0], step = 1.\n",
      " |          len(args) == 2 -> start = args[0], stop = args[1], step = 1.\n",
      " |          len(args) == 3 -> start = args[0], stop = args[1], step = args[2].\n",
      " |        **kwargs:\n",
      " |          - output_type: Its expected dtype. (Optional, default: `tf.int64`).\n",
      " |          - name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `RangeDataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if len(args) == 0.\n",
      " |  \n",
      " |  sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False)\n",
      " |      Samples elements at random from the datasets in `datasets`.\n",
      " |      \n",
      " |      Creates a dataset by interleaving elements of `datasets` with `weight[i]`\n",
      " |      probability of picking an element from dataset `i`. Sampling is done without\n",
      " |      replacement. For example, suppose we have 2 datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset1 = tf.data.Dataset.range(0, 3)\n",
      " |      dataset2 = tf.data.Dataset.range(100, 103)\n",
      " |      ```\n",
      " |      \n",
      " |      Suppose that we sample from these 2 datasets with the following weights:\n",
      " |      \n",
      " |      ```python\n",
      " |      sample_dataset = tf.data.Dataset.sample_from_datasets(\n",
      " |          [dataset1, dataset2], weights=[0.5, 0.5])\n",
      " |      ```\n",
      " |      \n",
      " |      One possible outcome of elements in sample_dataset is:\n",
      " |      \n",
      " |      ```\n",
      " |      print(list(sample_dataset.as_numpy_iterator()))\n",
      " |      # [100, 0, 1, 101, 2, 102]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      " |          structure.\n",
      " |        weights: (Optional.) A list or Tensor of `len(datasets)` floating-point\n",
      " |          values where `weights[i]` represents the probability to sample from\n",
      " |          `datasets[i]`, or a `tf.data.Dataset` object where each element is such\n",
      " |          a list. Defaults to a uniform distribution across `datasets`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        stop_on_empty_dataset: If `True`, sampling stops if it encounters an empty\n",
      " |          dataset. If `False`, it skips empty datasets. It is recommended to set\n",
      " |          it to `True`. Otherwise, the distribution of samples starts off as the\n",
      " |          user intends, but may change as input datasets become empty. This can be\n",
      " |          difficult to detect since the dataset starts off looking correct.\n",
      " |          Default to `False` for backward compatibility.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset that interleaves elements from `datasets` at random, according\n",
      " |        to `weights` if provided, otherwise with uniform probability.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If the `datasets` or `weights` arguments have the wrong type.\n",
      " |        ValueError:\n",
      " |          - If `datasets` is empty, or\n",
      " |          - If `weights` is specified and does not match the length of `datasets`.\n",
      " |  \n",
      " |  zip(datasets, name=None)\n",
      " |      Creates a `Dataset` by zipping together the given datasets.\n",
      " |      \n",
      " |      This method has similar semantics to the built-in `zip()` function\n",
      " |      in Python, with the main difference being that the `datasets`\n",
      " |      argument can be a (nested) structure of `Dataset` objects. The supported\n",
      " |      nesting mechanisms are documented\n",
      " |      [here] (https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      >>> # The nested structure of the `datasets` argument determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 4), (2, 5), (3, 6)]\n",
      " |      >>> ds = tf.data.Dataset.zip((b, a))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(4, 1), (5, 2), (6, 3)]\n",
      " |      >>>\n",
      " |      >>> # The `datasets` argument may contain an arbitrary number of datasets.\n",
      " |      >>> c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
      " |      ...                                            #       [9, 10],\n",
      " |      ...                                            #       [11, 12] ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b, c))\n",
      " |      >>> for element in ds.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (1, 4, array([7, 8]))\n",
      " |      (2, 5, array([ 9, 10]))\n",
      " |      (3, 6, array([11, 12]))\n",
      " |      >>>\n",
      " |      >>> # The number of elements in the resulting dataset is the same as\n",
      " |      >>> # the size of the smallest dataset in `datasets`.\n",
      " |      >>> d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, d))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 13), (2, 14)]\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A (nested) structure of datasets.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from DatasetV2:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Iterable:\n",
      " |  \n",
      " |  __class_getitem__ = GenericAlias(...) from abc.ABCMeta\n",
      " |      Represent a PEP 585 generic type\n",
      " |      \n",
      " |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      " |  \n",
      " |  __tf_tracing_type__(self, context)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "take1 = trial_ds.take(1)\n",
    "help(take1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert train, valid, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(df):\n",
    "  '''Convert DataFrame to PrefetchDataset\n",
    "  Args:\n",
    "    df (dataframe): with two columns ('txt', and 'label') and indices\n",
    "  Return:\n",
    "    dataset (PrefetchDataset): with:\n",
    "      <PrefetchDataset element_spec={'idx': TensorSpec(shape=(None,), \n",
    "                                            dtype=tf.int32, name=None), \n",
    "                                     'label': TensorSpec(shape=(None,), \n",
    "                                            dtype=tf.int32, name=None), \n",
    "                                     'txt': TensorSpec(shape=(None,), \n",
    "                                            dtype=tf.string, name=None)}>\n",
    "\n",
    "  '''\n",
    "  idx = df.index   # aded this, as the tutorial has an index input\n",
    "  X   = df['txt']\n",
    "  y   = df['label']\n",
    "\n",
    "  df_dict = {\"idx\":idx, \"label\":y.values, \"txt\":X.values}\n",
    "\n",
    "  raw_ds       = tf.data.Dataset.from_tensor_slices(df_dict)  \n",
    "  raw_ds_batch = raw_ds.batch(batch_size)\n",
    "  dataset      = raw_ds_batch.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'idx': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'label': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'txt': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert train data\n",
    "train_ds = dataframe_to_dataset(train)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation dataset\n",
    "valid_ds = dataframe_to_dataset(valid)\n",
    "\n",
    "# Get testing dataset\n",
    "test_ds = dataframe_to_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Testing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec={'idx': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'label': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'txt': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "5\n",
      "txt\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:57:53.668179: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  print(text_batch[0])\n",
    "  print(len(text_batch))\n",
    "  print(label_batch)\n",
    "  print(len(label_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:30:15.751221Z",
     "iopub.status.busy": "2022-03-29T12:30:15.750998Z",
     "iopub.status.idle": "2022-03-29T12:30:15.778963Z",
     "shell.execute_reply": "2022-03-29T12:30:15.778411Z"
    },
    "id": "JuxDkcvVIoev"
   },
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(1):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classify_text_with_bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('bert_finetune': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a62edfbcf39af3bfe98b03791e65c4337047c7eef8bfa85d65d3997033bead22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
