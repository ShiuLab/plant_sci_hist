{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 2a: Bag of words and TF-idf models__\n",
    "\n",
    "Contruct bag of word and Tf-idf models. Hyperparameters include:\n",
    "- Feature extraction\n",
    "  - Cleaned or not in step 1\n",
    "  - `CountVectorizer`\n",
    "    - `max_features`: try 1e4, 2e4, 5e4, 1e5\n",
    "    - `ngram_range`: default [1,1], try also [1,2], [1,3]\n",
    "    - `max_df`: default 1.0, try also 0.9, 0.7, 0.5\n",
    "    - `min_df`: default 1, try also 2, 4, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b4016c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For reproducibility\n",
    "rand_state = 20220609\n",
    "\n",
    "## for data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from os import chdir\n",
    "from pathlib import Path\n",
    "\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, feature_selection, metrics\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## for deep learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, preprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "## for bert language model\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up working directory and corpus file location\n",
    "proj_dir          = Path('/home/shius/projects/plant_sci_hist')\n",
    "work_dir          = proj_dir / \"2_text_classify\"\n",
    "corpus_combo_file = work_dir / \"corpus_combo\"\n",
    "\n",
    "chdir(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Train/test split___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "\n",
    "The data are serialized as a json file from the last step in `script_text_preprocess.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>QualifiedName</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "      <th>txt_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1418117</th>\n",
       "      <td>32535930</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>The New phytologist</td>\n",
       "      <td>Allelic differences of clustered terpene synth...</td>\n",
       "      <td>Plant volatile emissions can recruit predators...</td>\n",
       "      <td>plant</td>\n",
       "      <td>Allelic differences of clustered terpene synth...</td>\n",
       "      <td>1</td>\n",
       "      <td>allelic difference clustered terpene synthases...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294489</th>\n",
       "      <td>10575286</td>\n",
       "      <td>1999-11-27</td>\n",
       "      <td>Forschende Komplementarmedizin</td>\n",
       "      <td>[Results of a standardized survey on the medic...</td>\n",
       "      <td>The plant Cannabis sativa has a long history o...</td>\n",
       "      <td>plant</td>\n",
       "      <td>[Results of a standardized survey on the medic...</td>\n",
       "      <td>0</td>\n",
       "      <td>result standardized survey medical use cannabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79180</th>\n",
       "      <td>2575122</td>\n",
       "      <td>1989-01-01</td>\n",
       "      <td>The Journal of experimental zoology. Supplemen...</td>\n",
       "      <td>Interspecific variation in sugar and amino aci...</td>\n",
       "      <td>Previous studies of cecal sugar and amino acid...</td>\n",
       "      <td>sage</td>\n",
       "      <td>Interspecific variation in sugar and amino aci...</td>\n",
       "      <td>0</td>\n",
       "      <td>interspecific variation sugar amino acid trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219916</th>\n",
       "      <td>29643861</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Frontiers in plant science</td>\n",
       "      <td>Targeted Sequencing by Gene Synteny, a New Str...</td>\n",
       "      <td>Sugarcane exhibits a complex genome mainly due...</td>\n",
       "      <td>sugarcane</td>\n",
       "      <td>Targeted Sequencing by Gene Synteny, a New Str...</td>\n",
       "      <td>1</td>\n",
       "      <td>targeted sequencing gene synteny new strategy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504520</th>\n",
       "      <td>16631830</td>\n",
       "      <td>2006-04-25</td>\n",
       "      <td>Phytochemistry</td>\n",
       "      <td>Immunosuppressive diacetylenes, ceramides and ...</td>\n",
       "      <td>Three C-17 diacetylenic compounds (1-3), one m...</td>\n",
       "      <td>hydrocotyle</td>\n",
       "      <td>Immunosuppressive diacetylenes, ceramides and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>immunosuppressive diacetylenes ceramides cereb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PMID        Date  \\\n",
       "1418117  32535930  2020-06-15   \n",
       "294489   10575286  1999-11-27   \n",
       "79180     2575122  1989-01-01   \n",
       "1219916  29643861  2018-04-13   \n",
       "504520   16631830  2006-04-25   \n",
       "\n",
       "                                                   Journal  \\\n",
       "1418117                                The New phytologist   \n",
       "294489                      Forschende Komplementarmedizin   \n",
       "79180    The Journal of experimental zoology. Supplemen...   \n",
       "1219916                         Frontiers in plant science   \n",
       "504520                                      Phytochemistry   \n",
       "\n",
       "                                                     Title  \\\n",
       "1418117  Allelic differences of clustered terpene synth...   \n",
       "294489   [Results of a standardized survey on the medic...   \n",
       "79180    Interspecific variation in sugar and amino aci...   \n",
       "1219916  Targeted Sequencing by Gene Synteny, a New Str...   \n",
       "504520   Immunosuppressive diacetylenes, ceramides and ...   \n",
       "\n",
       "                                                  Abstract QualifiedName  \\\n",
       "1418117  Plant volatile emissions can recruit predators...         plant   \n",
       "294489   The plant Cannabis sativa has a long history o...         plant   \n",
       "79180    Previous studies of cecal sugar and amino acid...          sage   \n",
       "1219916  Sugarcane exhibits a complex genome mainly due...     sugarcane   \n",
       "504520   Three C-17 diacetylenic compounds (1-3), one m...   hydrocotyle   \n",
       "\n",
       "                                                       txt  label  \\\n",
       "1418117  Allelic differences of clustered terpene synth...      1   \n",
       "294489   [Results of a standardized survey on the medic...      0   \n",
       "79180    Interspecific variation in sugar and amino aci...      0   \n",
       "1219916  Targeted Sequencing by Gene Synteny, a New Str...      1   \n",
       "504520   Immunosuppressive diacetylenes, ceramides and ...      1   \n",
       "\n",
       "                                                 txt_clean  \n",
       "1418117  allelic difference clustered terpene synthases...  \n",
       "294489   result standardized survey medical use cannabi...  \n",
       "79180    interspecific variation sugar amino acid trans...  \n",
       "1219916  targeted sequencing gene synteny new strategy ...  \n",
       "504520   immunosuppressive diacetylenes ceramides cereb...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load json file\n",
    "with corpus_combo_file.open(\"r+\") as f:\n",
    "    corpus_combo_json = json.load(f)\n",
    "\n",
    "# Convert json back to dataframe\n",
    "corpus_combo = pd.read_json(corpus_combo_json)\n",
    "corpus_combo.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "\n",
    "- Stratify based on labels\n",
    "- Set random state: The setting will ensure two splits have the same instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original corpus\n",
    "corpus_ori = corpus_combo[['label','txt']]\n",
    "train_ori, test_ori = model_selection.train_test_split(corpus_ori, \n",
    "    test_size=0.2, stratify=corpus_ori['label'], random_state=rand_state)\n",
    "\n",
    "# Cleaned corpus\n",
    "corpus_cln = corpus_combo[['label','txt_clean']]\n",
    "corpus_cln.rename(columns={'txt_clean': 'txt'}) # make column names consistent\n",
    "train_cln, test_cln = model_selection.train_test_split(corpus_cln, \n",
    "    test_size=0.2, stratify=corpus_cln['label'], random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853778</th>\n",
       "      <td>0</td>\n",
       "      <td>Update: Exertional hyponatremia, active compon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165206</th>\n",
       "      <td>1</td>\n",
       "      <td>Stable megadalton TOC-TIC supercomplexes as ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107511</th>\n",
       "      <td>0</td>\n",
       "      <td>Effects of population-related variation in pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513902</th>\n",
       "      <td>1</td>\n",
       "      <td>Water Relations in Pulvini from Samanea saman:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177616</th>\n",
       "      <td>0</td>\n",
       "      <td>Inhibitory activities of substances present in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                                txt\n",
       "853778       0  Update: Exertional hyponatremia, active compon...\n",
       "1165206      1  Stable megadalton TOC-TIC supercomplexes as ma...\n",
       "1107511      0  Effects of population-related variation in pla...\n",
       "513902       1  Water Relations in Pulvini from Samanea saman:...\n",
       "177616       0  Inhibitory activities of substances present in..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ori.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>txt_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853778</th>\n",
       "      <td>0</td>\n",
       "      <td>update exertional hyponatremia active componen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165206</th>\n",
       "      <td>1</td>\n",
       "      <td>stable megadalton toctic supercomplexes major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107511</th>\n",
       "      <td>0</td>\n",
       "      <td>effect populationrelated variation plant prima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513902</th>\n",
       "      <td>1</td>\n",
       "      <td>water relation pulvini samanea saman ii effect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177616</th>\n",
       "      <td>0</td>\n",
       "      <td>inhibitory activity substance present plant se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                          txt_clean\n",
       "853778       0  update exertional hyponatremia active componen...\n",
       "1165206      1  stable megadalton toctic supercomplexes major ...\n",
       "1107511      0  effect populationrelated variation plant prima...\n",
       "513902       1  water relation pulvini samanea saman ii effect...\n",
       "177616       0  inhibitory activity substance present plant se..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cln.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    34658\n",
       " 1    34658\n",
       " Name: label, dtype: int64,\n",
       " 0    8665\n",
       " 1    8665\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ori['label'].value_counts(), test_ori['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    34658\n",
       " 1    34658\n",
       " Name: label, dtype: int64,\n",
       " 0    8665\n",
       " 1    8665\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cln['label'].value_counts(), test_cln['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Bag of words model___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Hyperparameters_\n",
    "\n",
    "Run a testing XgBoost model in the section `Models for original text` and found that the test F1 is already 0.94. Not sure how much tuning on this is needed. So reduce the scope to focus on: \n",
    "- `ngram_range`, `stop_words` (want to see how stop word impact classification), and feature selection.\n",
    "\n",
    "Thoughts:\n",
    "- Cleaned or not in step 1.\n",
    "- `CountVectorizer`\n",
    "  - `max_features`: 1e4, 5e4, 1e5\n",
    "    - Originally thought that it did not make sense to do this because at p<1e-2, there are only 8k features. But here the features are selected based on freuqencies. Some less frequency terms can still be only present in one class.\n",
    "  - `ngram_range`: [1,1], [1,2], [1,3]\n",
    "  - NOT TESTED: `max_df`: default 1.0, try also 0.9, 0.7, 0.5\n",
    "  - NOT TESTED: `min_df`: default 1, try also 2, 4, 8\n",
    "  - For original text\n",
    "    - `stop_words`: None, try also `english`\n",
    "- Feature selection\n",
    "  - `p_threshold`: 1e-2, 1e-3, 1e-4, 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameters(stopw=0):\n",
    "    ''' Return a dictionary with hyperparameters\n",
    "    Args\n",
    "      stopw (int): whether to rid of english stopwords (1) or not (0)\n",
    "    Return:\n",
    "      hyperp (dict): a dictionary with hyperparameters\n",
    "    '''\n",
    "   \n",
    "    param_grid = {\"max_features\": [1e4, 5e4, 1e5],\n",
    "                  \"ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "                  \"stop_words:\": [None],\n",
    "                  \"p_threshold\": [1e-2, 1e-3, 1e-4, 1e-5]}\n",
    "    if stopw:\n",
    "        param_grid[\"Stop_words\"].append(\"english\")\n",
    "    \n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### _Feature extraction_\n",
    "\n",
    "- Build a vocab with the number of words = `max_features`. \n",
    "- Consider: unigrams, bigrams, and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat(X_train, param=[], vocab=\"\"):\n",
    "    '''Extracting features as term frequencies\n",
    "    Args:\n",
    "      param (list): contains max_features, ngram_range, max_df, min_df,\n",
    "        and stop_words\n",
    "      X_train (pandas series): the txt column in the training data frame\n",
    "    Returns:\n",
    "      vectorizer (sklearn.feature_extraction.text.CountVectorizer) \n",
    "      X_train (pandas series): the transformed X_train\n",
    "    '''\n",
    "    # vectorizerd term frequencies\n",
    "    if vocab == \"\":\n",
    "      [max_features, ngram_range, max_df, min_df, stop_words] = param\n",
    "      vectorizer = feature_extraction.text.CountVectorizer(\n",
    "                              max_features = max_features, \n",
    "                              ngram_range  = ngram_range,\n",
    "                              max_df       = max_df,\n",
    "                              min_df       = min_df,\n",
    "                              stop_words   = stop_words)\n",
    "    else:\n",
    "      vectorizer = feature_extraction.text.CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "    # fit the vectorizer with training corpus\n",
    "    vectorizer.fit(X_train)\n",
    "\n",
    "    # transform the training corpus\n",
    "    X_train = vectorizer.transform(X_train)\n",
    "\n",
    "    return vectorizer, X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### _Feature selection_\n",
    "\n",
    "With chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feat(X_train, y_train, vectorizer, p_threshold):\n",
    "    '''Select features based on chi-square test results\n",
    "    Args:\n",
    "      X_train (pandas series): the txt column in the training data frame\n",
    "      y_train (pandas series): the label column in the training data frame\n",
    "      vecorizer: fitted with original X_train and returned from get_vectorizer()\n",
    "      p_threshold (float): p is derived from chi-square test. Features with p <= \n",
    "        p_threshold_s are selected.\n",
    "    Return:\n",
    "      X_names (list): names of selected features\n",
    "    '''\n",
    "    y            = y_train\n",
    "    X_names      = vectorizer.get_feature_names_out()\n",
    "    dtf_features = pd.DataFrame()\n",
    "    for cat in np.unique(y):\n",
    "        _, p = feature_selection.chi2(X_train, y==cat)\n",
    "        dtf_features = pd.concat([dtf_features, \n",
    "                    pd.DataFrame({\"feature\":X_names, \"p\":p, \"y\":cat})])\n",
    "        dtf_features = dtf_features.sort_values(\n",
    "                    [\"y\",\"p\"], ascending=[True,False])\n",
    "        dtf_features = dtf_features[dtf_features[\"p\"] <= p_threshold]\n",
    "    \n",
    "    X_names = dtf_features[\"feature\"].unique().tolist()\n",
    "\n",
    "    for cat in np.unique(y):\n",
    "        print(\"{}:\".format(cat), \" selected features:\",\n",
    "                len(dtf_features[dtf_features[\"y\"]==cat]))\n",
    "        print(\" top features:\", \",\".join(\n",
    "                dtf_features[dtf_features[\"y\"]==cat][\"feature\"].values[:10]))\n",
    "\n",
    "    print('Total selected:', len(X_names))\n",
    "\n",
    "    return X_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Model training, hyperparameter tuning, and cross-validation_\n",
    "\n",
    "Do [hyperparameter grid search with XGBoost](https://www.kaggle.com/code/tilii7/hyperparameter-grid-search-with-xgboost/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgboost(X_train, y_train, rand_state):\n",
    "    '''Do hyperparameter tuning and cross-validation of XgBoost models\n",
    "    Args:\n",
    "      X_train (pandas dataframe): features\n",
    "      y_train (pandas series): labels\n",
    "      rand_state (int): rand\n",
    "    Return:\n",
    "      rand_search (RandomizedSearchCV): fitted obj\n",
    "    '''\n",
    "\n",
    "    params = {'min_child_weight': [1, 5, 10],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'max_depth': [3, 4, 5]}\n",
    "    folds       = 5\n",
    "    param_comb  = 5\n",
    "    n_jobs      = 14\n",
    "\n",
    "    # Initialize classifier\n",
    "    # 06/11/2022: the silent parameter is deprecated, use verbosity=0\n",
    "    xgb = XGBClassifier(learning_rate=0.02, \n",
    "                        n_estimators=600, \n",
    "                        objective='binary:logistic',\n",
    "                        verbosity=1, \n",
    "                        nthread=1)\n",
    "\n",
    "    # Initilize stratified k fold obj\n",
    "    skf = model_selection.StratifiedKFold(\n",
    "                        n_splits=folds, shuffle = True, random_state = rand_state)\n",
    "    \n",
    "    # initiate randomized search CV obj\n",
    "    rand_search = model_selection.RandomizedSearchCV(\n",
    "                        xgb                , param_distributions = params, \n",
    "                        n_iter = param_comb, scoring      = 'roc_auc', \n",
    "                        n_jobs = n_jobs    , cv = skf.split(X_train,y_train), \n",
    "                        verbose = 3        , random_state =rand_state)\n",
    "\n",
    "    # Train\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    return rand_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for original text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Testing run_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training/testing corpus and labels\n",
    "X_train_ori = train_ori['txt']\n",
    "y_train_ori = train_ori['label']\n",
    "X_test_ori  = test_ori['txt']\n",
    "y_test_ori  = test_ori['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dim: (69316, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "param       = [10000, [1,1], 1.0, 1, None]\n",
    "\n",
    "# Get vectorizer and fitted X_train\n",
    "vectorizer, X_train_ori_vec = extract_feat(X_train_ori, param=param)\n",
    "print(\"Train dim:\", X_train_ori_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  selected features: 8130\n",
      " top features: 210,appearing,exotic,application,su,stratification,antifungal,projected,depending,holds\n",
      "1:  selected features: 8130\n",
      " top features: 210,appearing,exotic,application,su,stratification,antifungal,projected,depending,holds\n",
      "Total selected: 8130\n"
     ]
    }
   ],
   "source": [
    "# Get selected feature names\n",
    "p_threshold = 1e-4\n",
    "X_names_ori = select_feat(X_train_ori_vec, y_train_ori, vectorizer, p_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dim: (69316, 8130)\n"
     ]
    }
   ],
   "source": [
    "# Refit vectorizer with selected features and re-transform X_train_ori\n",
    "vectorizer_sel, X_train_ori_vec_sel = extract_feat(X_train_ori, vocab=X_names_ori)\n",
    "print(\"Train dim:\", X_train_ori_vec_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dim: (17330, 8130)\n"
     ]
    }
   ],
   "source": [
    "# Also apply the refitted vecorizer to testing data\n",
    "X_test_ori_vec_sel = vectorizer_sel.transform(X_test_ori)\n",
    "print(\"Test dim:\", X_test_ori_vec_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.979 total time= 2.6min\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.977 total time= 2.6min\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.980 total time= 2.6min\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.978 total time= 2.7min\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, max_depth=4, min_child_weight=5, subsample=1.0;, score=0.983 total time= 4.0min\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, max_depth=4, min_child_weight=5, subsample=1.0;, score=0.982 total time= 4.1min\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, max_depth=4, min_child_weight=5, subsample=1.0;, score=0.982 total time= 4.1min\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, max_depth=4, min_child_weight=5, subsample=1.0;, score=0.981 total time= 4.1min\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, max_depth=4, min_child_weight=5, subsample=1.0;, score=0.983 total time= 4.1min\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=10, subsample=1.0;, score=0.985 total time= 5.0min\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=10, subsample=1.0;, score=0.984 total time= 5.0min\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=10, subsample=1.0;, score=0.984 total time= 5.0min\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.980 total time= 2.5min\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=10, subsample=1.0;, score=0.985 total time= 5.1min\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=10, subsample=1.0;, score=0.985 total time= 5.1min\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.980 total time= 2.9min\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.978 total time= 2.9min\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.979 total time= 2.9min\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8;, score=0.980 total time= 1.8min\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8;, score=0.978 total time= 1.8min\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8;, score=0.979 total time= 1.8min\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8;, score=0.978 total time= 1.5min\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8;, score=0.980 total time= 1.5min\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.980 total time= 2.5min\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0;, score=0.977 total time= 2.5min\n"
     ]
    }
   ],
   "source": [
    "# Get xgboost model and cv results\n",
    "rand_search = run_xgboost(X_train_ori_vec_sel, y_train_ori, rand_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best auROC: 0.9844870097228213\n",
      "best parameters: {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 5, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "corpus_ori_best_est   = rand_search.best_estimator_\n",
    "corpus_ori_best_param = rand_search.best_params_\n",
    "corpus_ori_best_score = rand_search.best_score_\n",
    "print(\"best auROC:\", corpus_ori_best_score)\n",
    "print(\"best parameters:\", corpus_ori_best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/shius/projects/plant_sci_hist/2_text_classify/model_txt_original_randomizedseachcv_.sav']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "model_ori_name = work_dir / f'model_txt_original_randomizedseachcv_.sav'\n",
    "joblib.dump(corpus_ori_best_est, model_ori_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "corpus_ori_best_est_loaded = joblib.load(model_ori_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(corpus_ori_best_est_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ori = corpus_ori_best_est_loaded.predict(X_test_ori_vec_sel)\n",
    "report = metrics.classification_report(y_test_ori, y_pred_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413039758142718"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test_ori, y_pred_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10000-1|1-None-0.01'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = [10000.0, (1, 1), None, 0.01]\n",
    "param_str  = \\\n",
    "    f\"{int(param[0])}-{'|'.join(map(str,param[1]))}-{param[2]}-{param[3]}\"\n",
    "param_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For term freuqency models, move to `script_text_classify_tf.py`.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dd3af54f5fe992bccbd23931b262c263c643af7052ca64c3b616d552ec510a8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
