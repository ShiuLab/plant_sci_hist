{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 4: Topic model__\n",
    "\n",
    "The kmean cluserting results are not particularly clear what's going on. So go stiraght to topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Set up___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting working directory\n",
    "proj_dir   = Path.home() / \"projects/plant_sci_hist\"\n",
    "work_dir   = proj_dir / \"4_topic_model/4_1_get_topics\"\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# plant science corpus\n",
    "dir25       = proj_dir / \"2_text_classify/2_5_predict_pubmed\"\n",
    "corpus_file = dir25 / \"corpus_plant_421658.tsv.gz\"\n",
    "\n",
    "# qualified feature names\n",
    "dir31          = proj_dir / \"3_key_term_temporal/3_1_pubmed_vocab\"\n",
    "X_vec_file     = dir31 / \"tfidf_sparse_matrix_4542\"\n",
    "feat_name_file = dir31 / \"tfidf_feat_name_and_sum_4542\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proprecess corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>QualifiedName</th>\n",
       "      <th>txt</th>\n",
       "      <th>reg_article</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>1975-12-11</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>Identification of the 120 mus phase in the dec...</td>\n",
       "      <td>After a 500 mus laser flash a 120 mus phase in...</td>\n",
       "      <td>spinach</td>\n",
       "      <td>Identification of the 120 mus phase in the dec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1975-11-20</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>Cholinesterases from plant tissues. VI. Prelim...</td>\n",
       "      <td>Enzymes capable of hydrolyzing esters of thioc...</td>\n",
       "      <td>plant</td>\n",
       "      <td>Cholinesterases from plant tissues. VI. Prelim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PMID        Date                        Journal  \\\n",
       "0           3    61  1975-12-11  Biochimica et biophysica acta   \n",
       "1           4    67  1975-11-20  Biochimica et biophysica acta   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Identification of the 120 mus phase in the dec...   \n",
       "1  Cholinesterases from plant tissues. VI. Prelim...   \n",
       "\n",
       "                                            Abstract QualifiedName  \\\n",
       "0  After a 500 mus laser flash a 120 mus phase in...       spinach   \n",
       "1  Enzymes capable of hydrolyzing esters of thioc...         plant   \n",
       "\n",
       "                                                 txt  reg_article    y_prob  \\\n",
       "0  Identification of the 120 mus phase in the dec...            1  0.716394   \n",
       "1  Cholinesterases from plant tissues. VI. Prelim...            1  0.894874   \n",
       "\n",
       "   y_pred  \n",
       "0       1  \n",
       "1       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.read_csv(corpus_file, sep='\\t', compression='gzip')\n",
    "corpus_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x, stop_words_dict):\n",
    "    x = str(x)\n",
    "    x = x.lower()\n",
    "    # Replace any non-alphanumric characters of any length\n",
    "    # Q: Not sure what the # character do.\n",
    "    x = re.sub(r'#[A-Za-z0-9]*', ' ', x)\n",
    "    # tokenize and rid of any token matching stop words\n",
    "    tokens = word_tokenize(x)\n",
    "    x = ' '.join([w for w in tokens if not w in stop_words_dict])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs       = corpus_df['txt']\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words_dict = {}\n",
    "for i in stop_words:\n",
    "  stop_words_dict[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 421658/421658 [07:50<00:00, 895.85it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "421658"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean = []\n",
    "for doc_idx in tqdm(range(len(docs))):\n",
    "  doc = docs[doc_idx]\n",
    "  docs_clean.append(clean_text(doc, stop_words_dict))\n",
    "len(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = corpus_df.Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Run BERTopic___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c03c3-1b09-4a28-9131-e4f5f6cb8ad9",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "\n",
    "- language: str = 'english'\n",
    "- top_n_words: int = 10\n",
    "  - The number of words per topic to extract. __Setting this too high can negatively impact topic embeddings__ as topics are typically best represented by at most __10 words__.\n",
    "- n_gram_range: Tuple[int, int] = (1, 1)\n",
    "  - The n-gram range for the CountVectorizer, between 1 and 3, otherwise memory issue.\n",
    "- min_topic_size: int = 10\n",
    "  - The minimum size of the topic.\n",
    "- nr_topics: Union[int, str] = None\n",
    "  - Specifying the number of topics will reduce the initial number of topics to the value specified.\n",
    "  - Use __\"auto\"__ to automatically reduce topics using HDBSCAN\n",
    "- calculate_probabilities: bool = False\n",
    "  - Whether to calculate the probabilities of all topics per document instead of the probability of the assigned topic per document.\n",
    "  - Will significantly increase computing time if True.\n",
    "- diversity: float = None\n",
    "  - Whether to use MMR to diversify the resulting topic representations.\n",
    "  - Value between 0 (no divresity) and 1 (very diverse).\n",
    "    - __Q: What does diversity mean here?__\n",
    "- seed_topic_list: List[List[str]] = None\n",
    "  - A list of seed words per topic to converge around.\n",
    "- embedding_model=None\n",
    "  - SentenceTransformers, Flair, Spacy, Gensim, USE (TF-Hub), or [these](https://www.sbert.net/docs/pretrained_models.html).\n",
    "  - Try to use `allenai-specter`.\n",
    "- umap_model: umap.umap_.UMAP = None\n",
    "- hdbscan_model: hdbscan.hdbscan_.HDBSCAN = None\n",
    "- vectorizer_model: sklearn.feature_extraction.text.CountVectorizer = None\n",
    "- verbose: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c193f3-a948-460c-924d-7c1198643908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(calculate_probabilities=False,\n",
    "                       n_gram_range=(1,2),\n",
    "                       min_topic_size=1000, \n",
    "                       nr_topics='auto',\n",
    "                       embedding_model='allenai-specter',\n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c193f3-a948-460c-924d-7c1198643908",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topic_model.fit_transform(docs_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bertopic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c20b0cb396bbd9019bf822cb52809ec816dc3543a10977636a6749a66e5f9aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
