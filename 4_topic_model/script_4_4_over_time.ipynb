{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 4.4: Topic over time__\n",
    "\n",
    "Goals here:\n",
    "- Analyze topics over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Set up___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from bertopic import BERTopic\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from xlsxwriter.workbook import Workbook\n",
    "from plotly.io import write_image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting working directory\n",
    "proj_dir   = Path.home() / \"projects/plant_sci_hist\"\n",
    "work_dir   = proj_dir / \"4_topic_model/4_4_over_time\"\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# plant science corpus\n",
    "dir25       = proj_dir / \"2_text_classify/2_5_predict_pubmed\"\n",
    "corpus_file = dir25 / \"corpus_plant_421658.tsv.gz\"\n",
    "\n",
    "# saved model and probability file\n",
    "dir42            = proj_dir / \"4_topic_model/4_2_outlier_assign\"\n",
    "topic_model_file = dir42 / \"topic_model_updated\"\n",
    "prob_file        = dir42 / \"probs.pickle\"\n",
    "embedding_file   = dir42 / \"embeddings_scibert.pickle\"\n",
    "\n",
    "# So PDF is saved in a format properly\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Load data___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_csv(corpus_file, sep='\\t')\n",
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(docs_clean_file, \"rb\") as f:\n",
    "  docs_clean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load topic model and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load topic model\n",
    "topic_model = BERTopic.load(topic_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prob\n",
    "with open(prob_file, \"rb\") as f:\n",
    "  probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(topic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Basic summary___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic size distribution\n",
    "\n",
    "See Revisit topic size plot for an updated version used for graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(topic_info[\"Count\"]), bins=200)\n",
    "plt.xlabel(\"log10(Count)\")\n",
    "plt.ylabel(\"Frquency\")\n",
    "plt.xlim(2.5,5)\n",
    "plt.savefig(work_dir / \"fig4_3_topic_count_dist.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representative docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_docs = topic_model.get_representative_docs()\n",
    "\n",
    "# So outlier topic is not included\n",
    "type(rep_docs), len(rep_docs.keys()), len(rep_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a tsv\n",
    "rep_docs_file = work_dir / \"topic_rep_docs.tsv\"\n",
    "rep_docs_df   = pd.DataFrame.from_dict(rep_docs, orient='index',\n",
    "                                  columns=['doc1', 'doc2', 'doc3'])\n",
    "rep_docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_docs_df.to_csv(rep_docs_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Get top words for different topics___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_topic_labels\n",
    "\n",
    "Get labels for each topic in a user-defined format\n",
    "- Try nr_words=10\n",
    "- E.g., cluster 5 does not make sense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = topic_model.generate_topic_labels(nr_words=10,\n",
    "                                                 topic_prefix=True,\n",
    "                                                 separator='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(topic_labels), topic_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_topic\n",
    "\n",
    "Return top 10 words for a specific topic and their c-TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "topic0 = topic_model.get_topic(0)\n",
    "type(topic0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all topic top 10 words, exclude the outlier cluster\n",
    "# Ok, this can be done with top_model.get_topics()\n",
    "\n",
    "#topic_top10 = {} # {cluster_id: top_10_list}\n",
    "#for cluster_id in range(topic_info.shape[0]-1):\n",
    "#  topic_top10[cluster_id] = topic_model.get_topic(cluster_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = topic_model.get_topics()\n",
    "type(all_topics), all_topics[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic-term matrix\n",
    "\n",
    "Follow [this](https://maartengr.github.io/BERTopic/getting_started/tips_and_tricks/tips_and_tricks.html#topic-term-matrix)\n",
    "- The approaches before only give the top 10 terms. Want to get more from each topic.\n",
    "- So process the matrix instead.\n",
    "- To get the top n entries per row, follow [this post](https://stackoverflow.com/questions/31790819/scipy-sparse-csr-matrix-how-to-get-top-ten-values-and-indices).\n",
    "- Also, see [this post](https://stackoverflow.com/questions/3179106/python-select-subset-from-list-based-on-index-set) for selecting a subset from a list based on indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse matrix with topics as rows and features (i.e. terms) as columns, \n",
    "# values are c-Tf-idf\n",
    "topic_term_matrix = topic_model.c_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(topic_term_matrix), topic_term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of features (terms)\n",
    "terms = topic_model.vectorizer_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(terms), len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 50 terms\n",
    "top_50 = {} # {topic:[top50_idx_list, top50_c-tf-idf_list, to50_feat_list]}\n",
    "\n",
    "# Skip the outlier topic, named the variable topic_plus1 because the topic\n",
    "# index is -1 from the index in the topic_term_marix.\n",
    "for topic_plus1 in tqdm(range(1, topic_term_matrix.shape[0])):\n",
    "  row     = topic_term_matrix.getrow(topic_plus1).toarray()[0].ravel()\n",
    "\n",
    "  # The following two lines sorted from low to high\n",
    "  t50_idx = list(row.argsort()[-50:])\n",
    "  t50_val = list(row[row.argsort()[-50:]])\n",
    "\n",
    "  t50_fea = [terms[i] for i in t50_idx]\n",
    "  top_50[topic_plus1-1] = [t50_idx, t50_val, t50_fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the top 50 terms\n",
    "with open(work_dir / 'top_50_terms_per_topic.pickle', 'wb') as f:\n",
    "  pickle.dump(top_50, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save top terms for different topics into an xlsx file\n",
    "\n",
    "See [this post](https://www.geeksforgeeks.org/convert-a-tsv-file-to-excel-using-python/) for saving TSVs into spreadsheet\n",
    "- Also include a topic label sheet where label is the top 10 words\n",
    "- Also include a representative doc sheet where the topic 3 docs of each topic is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_file = work_dir / \"table_top_50.xlsx\"\n",
    "xlsx      = Workbook(xlsx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incude the top 10 words in a worksheet\n",
    "topic_label_file = work_dir / \"topic_labels.txt\"\n",
    "\n",
    "# Do not output outlier\n",
    "topic_label_df = pd.DataFrame(topic_labels[1:])\n",
    "topic_label_df.columns = [\"label\"]\n",
    "topic_label_df.to_csv(topic_label_file, sep='\\t')\n",
    "\n",
    "worksheet = xlsx.add_worksheet(\"topic_label\")\n",
    "read_tsv = csv.reader(open(topic_label_file,'r',encoding='utf-8'),delimiter='\\t')\n",
    "for row, data in enumerate(read_tsv):\n",
    "  worksheet.write_row(row, 0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incude the representative doc in a worksheet\n",
    "worksheet = xlsx.add_worksheet(\"representative docs\")\n",
    "read_tsv = csv.reader(open(rep_docs_file,'r',encoding='utf-8'),delimiter='\\t')\n",
    "for row, data in enumerate(read_tsv):\n",
    "  worksheet.write_row(row, 0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the top 50 term info into different tsv files in the top_50 folder\n",
    "top_50_dir = work_dir / \"top_50\"\n",
    "top_50_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Output individual tsv files and put tsv into xlsx\n",
    "for topic in top_50:\n",
    "  topic_file = top_50_dir / f\"topic_{topic}.tsv\"\n",
    "  # The nested list has index, c-tf-idf, and feature as rows. So it is transposed\n",
    "  # to have the rows as columns. The iloc bit is to reverse the order so higher\n",
    "  # c-tf-idf entries are on top.\n",
    "  topic_df = pd.DataFrame(top_50[topic]).transpose().iloc[::-1]\n",
    "  topic_df.columns = [\"index\", \"c-tf-idf\", \"feature\"]\n",
    "  topic_df.to_csv(topic_file, sep='\\t')\n",
    "\n",
    "  # Save to xlsx\n",
    "  worksheet = xlsx.add_worksheet(f\"{topic}\")\n",
    "  read_tsv  = csv.reader(open(topic_file, 'r',encoding='utf-8'),delimiter='\\t')\n",
    "  for row, data in enumerate(read_tsv):\n",
    "    worksheet.write_row(row, 0, data)\n",
    "\n",
    "xlsx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792a910-dc6d-4a5e-9c5a-d5938e9af5a7",
   "metadata": {},
   "source": [
    "## ___Visualize topic___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic relations in 2D\n",
    "\n",
    "- visualize_topics:\n",
    "  - This is useful to see how topics are related to each other in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209ae79-ea13-4db3-a51e-87f218862b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis1 = topic_model.visualize_topics()\n",
    "type(vis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaac44b-e225-4385-b623-ce230dc02cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis1.write_html(work_dir / \"fig4_3_topic_relation_2d.html\")\n",
    "write_image(vis1, work_dir / \"fig4_3_topic_relation_2d.pdf\", \n",
    "            format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataframe for plotting the 2D graph\n",
    "\n",
    "Get the dataframe used to plot this thing out, based on the codes in [here](https://github.com/MaartenGr/BERTopic/blob/master/bertopic/plotting/_topics.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list   = sorted(topics)\n",
    "all_topics   = sorted(list(topic_model.get_topics().keys()))\n",
    "indices      = np.array([all_topics.index(topic) for topic in topics])\n",
    "frequencies  = [topic_model.topic_sizes[topic] for topic in topic_list]\n",
    "\n",
    "words = [\" | \".join([word[0] for word in topic_model.get_topic(topic)[:5]]) \n",
    "                                                      for topic in topic_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ctfidf = topic_model.c_tf_idf.toarray()[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_scaled = MinMaxScaler().fit_transform(embed_ctfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes ~3 min.\n",
    "embed_umap   = UMAP(\n",
    "  n_neighbors=2, n_components=2, metric='hellinger').fit_transform(embed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = pd.DataFrame({\"x\": embed_umap[:, 0], \"y\": embed_umap[:, 1],\n",
    "                       \"Topic\": topic_list, \"Words\": words, \"Size\": frequencies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df.to_csv(work_dir / \"table4_3_topic_relation_embedding_scaled_umap.tsv\",\n",
    "                sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Topic hierachical relations___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_threshold = np.percentile(probs, 95)\n",
    "\n",
    "# For hierachical_topics, a list of topics is required. This is returned by\n",
    "# fit or fit_transform, but it does not make sense to run it again. So I get the\n",
    "# topic cluster assignment based on probabilities.\n",
    "topics = [np.argmax(prob) if max(prob) >= probability_threshold else -1 \n",
    "                                                            for prob in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs_clean, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hierarchical_topics), hierarchical_topics.shape, hierarchical_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hier_bot = topic_model.visualize_hierarchy(orientation=\"bottom\")\n",
    "fig_hier_bot.write_html(work_dir / \"fig4_3_topic_hierarchy_bottom.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hier_lef = topic_model.visualize_hierarchy(orientation=\"left\")\n",
    "fig_hier_lef.write_html(work_dir / \"fig4_3_topic_hierarchy_left.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_image(fig_hier_bot, work_dir / \"fig4_3_topic_hierarchy_bottom.pdf\", \n",
    "            format='pdf')\n",
    "write_image(fig_hier_lef, work_dir / \"fig4_3_topic_hierarchy_left.pdf\", \n",
    "            format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic relations heatmap\n",
    "\n",
    "This is not particularly helpful out of the box as the axes are not clustered.\n",
    "- Look into [source code](https://github.com/MaartenGr/BERTopic/blob/master/bertopic/plotting/_heatmap.py) to see if I can get the distance matrix out and do my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_heatmap = topic_model.visualize_heatmap()\n",
    "fig_heatmap.write_html(work_dir / \"fig4_3_topic_heatmap.html\")\n",
    "write_image(fig_heatmap, work_dir / \"fig4_3_topic_heatmap.pdf\", \n",
    "            format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic relations heatmap - manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "\n",
    "# The following won't work because when I save the model, I did not save the\n",
    "# embeddings. I did not save it because it is precomputed in 4.2.\n",
    "#embeddings = np.array(topic_model.topic_embeddings)\n",
    "\n",
    "# Load the saved embedding file\n",
    "# The following won't work because it ask for >600Gb of memory when the distance\n",
    "# matrix is being created.\n",
    "#with open(embedding_file, \"rb\") as f:\n",
    "#  embeddings = pickle.load(f)\n",
    "\n",
    "# Realize that the embedding here is the topic embedding, not doc embedding.\n",
    "# So the above is not useful. \n",
    "embeddings = topic_model.c_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embeddings), embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = topic_model.get_topic_freq()\n",
    "topics  = sorted(freq_df.Topic.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_df = pd.DataFrame(distance_matrix,\n",
    "                              index=topics,\n",
    "                              columns=topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_clustergrid = sns.clustermap(dist_matrix_df, cmap=\"coolwarm\", \n",
    "                                  xticklabels=False, yticklabels=True)\n",
    "topic_clustergrid.savefig(work_dir / 'fig4_3_topic_heatmap_seaborn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = [[[f\"{topic}\\t\", None]] + topic_model.get_topic(topic) \n",
    "                                                    for topic in topics]\n",
    "new_labels = [\"|\".join([label[0] for label in labels[:10]]) \n",
    "                                                    for labels in new_labels]\n",
    "#new_labels = [label if len(label) < 30 else label[:27] + \"...\" \n",
    "#                                                    for label in new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned order is in row index, not label or column names\n",
    "order_idx   = topic_clustergrid.dendrogram_row.reordered_ind\n",
    "\n",
    "# Create a list with each element containing topic labels\n",
    "topic_order = [f\"{new_labels[i]}\" for i in order_idx]\n",
    "\n",
    "# Write the topic order into a file\n",
    "with open(work_dir / \"fig4_3_topic_heatmap_seaborn_order.txt\", \"w\") as f:\n",
    "  f.write(\"\\n\".join(topic_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic relations heatmap - lower half\n",
    "\n",
    "Generate another version with only the lower half, see [this post](https://stackoverflow.com/questions/67879908/lower-triangle-mask-with-seaborn-clustermap) but did not lead to a figure. Try [this](https://medium.com/@fleetw00d/plotting-a-triangluar-portion-of-a-seaborn-clustermap-92f3405c2f4d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask   = np.tril(np.ones_like(dist_matrix_df))\n",
    "values = topic_clustergrid.ax_heatmap.collections[0].get_array().reshape(\n",
    "                                                          dist_matrix_df.shape)\n",
    "new_values = np.ma.array(values, mask=mask)\n",
    "topic_clustergrid.ax_heatmap.collections[0].set_array(new_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(dist_matrix_df)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "g = sns.clustermap(dist_matrix_df, mask=mask, vmax=.3, figsize=(0.1,0.1))\n",
    "mask = mask[np.argsort(g.dendrogram_row.reordered_ind),:]\n",
    "mask = mask[:,np.argsort(g.dendrogram_col.reordered_ind)]\n",
    "topic_clustergrid_lower = sns.clustermap(dist_matrix_df, \n",
    "                                         figsize=(40,40), mask=mask, \n",
    "                                         cmap='coolwarm', \n",
    "                                         xticklabels=False, \n",
    "                                         yticklabels=dist_matrix_df.columns)\n",
    "topic_clustergrid_lower.ax_col_dendrogram.set_visible(False)\n",
    "topic_clustergrid_lower.savefig(work_dir/'fig4_3_topic_heatmap_seaborn_lower.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified top terms\n",
    "\n",
    "Take `fig4_3_topic_heatmap_seaborn_order.txt`:\n",
    "- Manually go through the terms to reduce redundancy and select 4-6 representative terms for each topic. The rules are:\n",
    "  - Combine singular and plural forms (e.g., gene and genes)\n",
    "  - Combine terms that are describing similar entities (e.g., strain and isolate)\n",
    "  - Rid of overly common words (e.g., plant, gene in some cases)\n",
    "- The result is in `fig4_3_topic_heatmap_seaborn_order_modified.txt`. Parse this so the info can be used as the topic names in the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(work_dir / 'fig4_3_topic_heatmap_seaborn_order_modified.txt', 'r') as f:\n",
    "  topic_modified = []\n",
    "  lines = f.readlines()\n",
    "  for line in lines:\n",
    "    elements = line.strip().split(\"\\t\")\n",
    "    ele_str  = f\"{elements[0]}\\t\" # write the topic index\n",
    "    for element in elements[1:]:\n",
    "      if element != \"\":\n",
    "        ele_str += f\"{element} | \"\n",
    "    ele_str = ele_str[:-3]\n",
    "    ele_str += \"\\n\"\n",
    "    topic_modified.append(ele_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(work_dir / 'fig4_3_topic_heatmap_seaborn_order_condensed.txt', 'w') as f:\n",
    "  for topic in topic_modified:\n",
    "    f.write(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisit topic size plot using the modified topic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered based on the index\n",
    "topic_modified_ordered = [\"\"]*len(topic_modified)\n",
    "for topic_name in topic_modified:\n",
    "  [topic, name] = topic_name.strip().split('\\t')\n",
    "  topic_modified_ordered[int(topic)+1] = f\"{topic}: {name}\"\n",
    "topic_modified_ordered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modified_ordered[0] = \"OUTLIER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info['Modified'] = topic_modified_ordered\n",
    "topic_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info.sort_values('Count', inplace=True)\n",
    "topic_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/barh.html\n",
    "\n",
    "# Do not plot outliers\n",
    "fig, ax = plt.subplots(figsize=(6,16))\n",
    "y_pos = np.arange(topic_info.shape[0]-1)\n",
    "ax.barh(y_pos, topic_info['Count'][:-1], align='center')\n",
    "ax.set_yticks(y_pos, labels=topic_info['Modified'][:-1])\n",
    "ax.set_xlabel(\"Number of documents\")\n",
    "plt.savefig(work_dir / \"fig4_3_number_docs_per_topic.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 30\n",
    "top_n   = 30\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "y_pos = np.arange(top_n)\n",
    "ax.barh(y_pos, topic_info['Count'][-top_n-1:-1], align='center')\n",
    "ax.set_yticks(y_pos, labels=topic_info['Modified'][-top_n-1:-1])\n",
    "ax.set_xlabel(\"Number of documents\")\n",
    "plt.savefig(work_dir / f\"fig4_3_number_docs_per_topic_top{top_n}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info['Count'][-top_n-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info[topic_info[\"Topic\"] == 72]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Compare topics___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic correlation scatter plot\n",
    "\n",
    "The c-Tf-Idf values are multiplied by 1,000 so it is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_pair_scatter(topic_term_matrix, topic_pair, top_50, out_file,\n",
    "                       t_annotate=6):\n",
    "  '''Generate and save a scatter plot of the top50 c-Tf-Idfs of a topic pair\n",
    "  Args:\n",
    "   topic_term_matrix (csr): A sparse matrix returned from topic_model.c_tf_idf\n",
    "   top_50 (dict): {topic:[t50_idx, t50_val, t50_fea]}\n",
    "   topic_pair (list): a pair of topic indices (-1, ..., 90) in a list\n",
    "   out_file (str): output pdf name\n",
    "   t_annotate (float): threshold c-Tf-Idfx1000 values to show feature annotation\n",
    "  Returns:\n",
    "  Output:\n",
    "    out_file (pdf): the scatter plot. \n",
    "  '''\n",
    "  [topic1, topic2] = topic_pair\n",
    "\n",
    "  # combined top 50 indices\n",
    "  idx1 = top_50[topic1][0]\n",
    "  idx2 = top_50[topic2][0]\n",
    "  top_50_both = list(set(idx1 + idx2))\n",
    "  #print(len(top_50_both))\n",
    "\n",
    "  # Get the feature names of indices in the combined list\n",
    "  top_50_both_feats = []\n",
    "  feat1 = top_50[topic1][2]\n",
    "  feat2 = top_50[topic2][2]\n",
    "  for idx in top_50_both:\n",
    "    if idx in idx1:\n",
    "      idx_idx1 = idx1.index(idx)\n",
    "      top_50_both_feats.append(feat1[idx_idx1])\n",
    "    elif idx in idx2:\n",
    "      idx_idx2 = idx2.index(idx)\n",
    "      top_50_both_feats.append(feat2[idx_idx2])\n",
    "    else:\n",
    "      print(\"ERR: idx {idx} not found\")      \n",
    "\n",
    "  # Get all feature ctfidf values. Note that topic_term_matrix include the -1 \n",
    "  # topic, so the index of topic 0 should have a row index of 1 in the matrix, \n",
    "  # so +1 in the getrow bit below.\n",
    "  row1 = topic_term_matrix.getrow(topic1+1).toarray()[0].ravel()\n",
    "  row2 = topic_term_matrix.getrow(topic2+1).toarray()[0].ravel()\n",
    "\n",
    "  ctfidf1 = row1[top_50_both]*1e3\n",
    "  ctfidf2 = row2[top_50_both]*1e3\n",
    "  #print(ctfidf1, ctfidf2)\n",
    "\n",
    "  # For setting the x, y limits\n",
    "  #ctfidf_max = math.ceil(max([max(ctfidf1), max(ctfidf2)]))\n",
    "  #print(ctfidf_max)\n",
    "  ctfidf_max=12\n",
    "\n",
    "  plt.figure(figsize=(5,5))\n",
    "  plt.scatter(ctfidf1, ctfidf2)\n",
    "  plt.xlabel(f\"topic {topic1} c-Tf-Idf (x1,000)\")\n",
    "  plt.ylabel(f\"topic {topic2} c-Tf-Idf (x1,000)\")\n",
    "  plt.plot([0, ctfidf_max], [0, ctfidf_max], 'ro--')\n",
    "  plt.xlim(0, ctfidf_max)\n",
    "  plt.ylim(0, ctfidf_max)\n",
    "\n",
    "  for idx, label in enumerate(top_50_both_feats):\n",
    "    x = ctfidf1[idx]\n",
    "    y = ctfidf2[idx]\n",
    "    # Only annotate if the values are larger\n",
    "    if  x >= t_annotate or y >= t_annotate:\n",
    "      # annotate labels out of boundary\n",
    "      if x > ctfidf_max or y > ctfidf_max:\n",
    "        if x > ctfidf_max and y > ctfidf_max:\n",
    "            new_x = new_y = ctfidf_max\n",
    "        elif x > ctfidf_max:\n",
    "          new_x = ctfidf_max\n",
    "          new_y = y\n",
    "        else:\n",
    "          new_x = x\n",
    "          new_y = ctfidf_max\n",
    "        plt.arrow(new_x-0.6, new_y-0.6, 0.5, 0.5, \n",
    "                  width=0.05, head_width=0.2, ec=\"purple\")\n",
    "        plt.annotate(f\"{label}({x},{y})\", (new_x, new_y), fontsize=6)\n",
    "      # for points within boundary\n",
    "      else:\n",
    "        plt.annotate(label, (x, y), fontsize=6)\n",
    "  out_file = work_dir / f\"fig4_3_topic_pair_scatter_{topic1}_{topic2}.pdf\"\n",
    "  plt.savefig(out_file)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate similarities between topics in a \"super-cluster\"\n",
    "\n",
    "- Topic 74, 75: host, larve, herbivore, pest, host\n",
    "- Topic 4, 44: uvb, stress, light, leave, co\n",
    "- Topic 25, 26, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1 = [74, 75]\n",
    "pair2 = [4, 44]\n",
    "pair3 = [25, 26]\n",
    "pair4 = [25, 27]\n",
    "pair5 = [26, 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pair_scatter(topic_term_matrix, pair1, top_50, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pair_scatter(topic_term_matrix, pair2, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair3, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair4, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair5, top_50, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair11 = [86, 88]\n",
    "topic_pair_scatter(topic_term_matrix, pair11, top_50, 5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate similarities between topics not in a \"super-cluster\"\n",
    "\n",
    "- Topic 25, 6: auxin signaling, microscopy\n",
    "- Topic 22, 15, lipid, oil\n",
    "- Topic 4, 24: uvb stress, ros, metabolism\n",
    "- Topic 44, 52: light, leaves, co, electron, light\n",
    "- Topic 44, 51: 51 and 52 are highly similar, but not between 44 and 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair6 = [25, 6]\n",
    "pair7 = [22, 15]\n",
    "pair8 = [4, 24]\n",
    "pair9 = [44, 52]\n",
    "pair10 = [44, 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pair_scatter(topic_term_matrix, pair6, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair7, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair8, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair9, top_50, 5.5)\n",
    "topic_pair_scatter(topic_term_matrix, pair10, top_50, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch_default': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4255f477c905e3cafd6d08b9a6d118445dbfbaff982fd1d9831280a79a13df35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
