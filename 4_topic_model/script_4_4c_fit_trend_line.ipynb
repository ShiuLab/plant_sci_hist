{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 4.4c: Fit trend line__\n",
    "\n",
    "Goals here:\n",
    "- Better detect the trends for topics\n",
    "\n",
    "10/11/22:\n",
    "- Think of this as a [forcasting problem](https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python-scikitlearn.html).\n",
    "- Update `sklearn` environment but run into problem:\n",
    " - `libstdc++.so.6: version 'GLIBCXX_3.4.29' not found`\n",
    " - [Fix](https://github.com/BVLC/caffe/issues/4953): `conda install libgcc`\n",
    "\n",
    "10/10/22: \n",
    "- The topic over time heatmap is ordered in a unstatisfactory way. While I can tell if a topic is declining or rising, it is rather subjective. Looking into [non-linear regression models for time-series](https://otexts.com/fpp2/nonlinear-regression.html), I can get a better picture by fitting trend lines.\n",
    "- From [this post](https://stackoverflow.com/questions/51321100/python-natural-smoothing-splines) found the following packages:\n",
    "  - https://github.com/espdev/csaps\n",
    "  - https://github.com/madrury/basis-expansions\n",
    "- Here is another way using [pycaret](https://towardsdatascience.com/time-series-forecasting-with-pycaret-regression-module-237b703a0c63)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Set up___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing environment\n",
    "\n",
    "```\n",
    "conda activate sklearn\n",
    "conda update --all\n",
    "pip install skforecast\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This following is done because:\n",
    "# ImportError: cannot import name '_centered' from 'scipy.signal.signaltools\n",
    "#https://stackoverflow.com/questions/71106940/cannot-import-name-centered-from-scipy-signal-signaltools \n",
    "\n",
    "import  scipy.signal.signaltools\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shius/miniconda3/envs/timeseries/lib/python3.10/site-packages/statsmodels/compat/pandas.py:61: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "/home/shius/miniconda3/envs/timeseries/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "from math import isnan\n",
    "from scipy.interpolate import UnivariateSpline, CubicSpline\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for recursive autoregressive forcasting\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.interpolate import interp1d\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.utils import save_forecaster\n",
    "from skforecast.utils import load_forecaster\n",
    "\n",
    "# For ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from itertools import product\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting working directory\n",
    "proj_dir   = Path.home() / \"projects/plant_sci_hist\"\n",
    "work_dir   = proj_dir / \"4_topic_model/4_4_over_time\"\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# modified topic names\n",
    "dir43            = proj_dir / \"4_topic_model/4_3_model_analysis\"\n",
    "toc_mod_name_file= dir43 / 'fig4_3_topic_heatmap_seaborn_order_condensed.txt'\n",
    "\n",
    "# Topic freuqency for each timestamp\n",
    "toc_freq_file    = work_dir / 'table4_4_topics_over_time_df_no_global_tune.tsv'\n",
    "\n",
    "# So PDF is saved in a format properly\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Load data___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load toc_mod_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>cell | expression | gene | protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>mirna | rnas | micrornas | target | lncrnas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>circadian clock | rhythms | flowering | arabid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>allergen | pollen | ige | allergenic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>medium | callus | regeneration | culture | som...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                                               Name\n",
       "0     -1                 cell | expression | gene | protein\n",
       "1     13        mirna | rnas | micrornas | target | lncrnas\n",
       "2     21  circadian clock | rhythms | flowering | arabid...\n",
       "3      0               allergen | pollen | ige | allergenic\n",
       "4      1  medium | callus | regeneration | culture | som..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.adamsmith.haus/python/answers/how-to-set-column-names-when-importing-a-csv-into-a-pandas-dataframe-in-python\n",
    "header_list   = [\"Topic\", \"Name\"]\n",
    "toc_mod_names = pd.read_csv(toc_mod_name_file, sep='\\t', names=header_list)\n",
    "toc_mod_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process top_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Words</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>cells, growth, acid, activity, tissue</td>\n",
       "      <td>981</td>\n",
       "      <td>250750799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>timothy, timothy pollen, antigen, ragweed, all...</td>\n",
       "      <td>8</td>\n",
       "      <td>250750799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>callus, medium, kinetin, culture, protoplasts</td>\n",
       "      <td>85</td>\n",
       "      <td>250750799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>berberinium, viscometric titrations, flow pola...</td>\n",
       "      <td>2</td>\n",
       "      <td>250750799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>amiben, atrazine, gsatrazine, atrazine metabol...</td>\n",
       "      <td>4</td>\n",
       "      <td>250750799.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                                              Words  Frequency  \\\n",
       "0     -1              cells, growth, acid, activity, tissue        981   \n",
       "1      0  timothy, timothy pollen, antigen, ragweed, all...          8   \n",
       "2      1      callus, medium, kinetin, culture, protoplasts         85   \n",
       "3      2  berberinium, viscometric titrations, flow pola...          2   \n",
       "4      3  amiben, atrazine, gsatrazine, atrazine metabol...          4   \n",
       "\n",
       "     Timestamp  \n",
       "0  250750799.0  \n",
       "1  250750799.0  \n",
       "2  250750799.0  \n",
       "3  250750799.0  \n",
       "4  250750799.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/28200404/pandas-read-table-use-first-column-as-index\n",
    "top_freq      = pd.read_csv(toc_freq_file, index_col=0, sep='\\t')\n",
    "top_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the dataframe into a matrix with rows as timestamps, column as topics,\n",
    "# and values as frequency\n",
    "top_freq_dict = {} # {timestamp:{topic:freq}}\n",
    "for idx in top_freq.index:\n",
    "  row  = top_freq.loc[idx]\n",
    "  ts   = row[\"Timestamp\"]\n",
    "  toc  = row[\"Topic\"]\n",
    "  freq = row[\"Frequency\"]\n",
    "  if ts not in top_freq_dict:\n",
    "    top_freq_dict[ts] = {toc:freq}\n",
    "  elif toc not in top_freq_dict[ts]:\n",
    "    top_freq_dict[ts][toc] = freq\n",
    "  else:\n",
    "    print(\"ERR: redundant\", topic,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.507508e+08</th>\n",
       "      <th>4.258800e+08</th>\n",
       "      <th>5.468400e+08</th>\n",
       "      <th>6.389460e+08</th>\n",
       "      <th>7.126416e+08</th>\n",
       "      <th>7.783920e+08</th>\n",
       "      <th>8.361936e+08</th>\n",
       "      <th>8.975376e+08</th>\n",
       "      <th>9.497268e+08</th>\n",
       "      <th>9.869616e+08</th>\n",
       "      <th>...</th>\n",
       "      <th>1.521864e+09</th>\n",
       "      <th>1.532750e+09</th>\n",
       "      <th>1.543986e+09</th>\n",
       "      <th>1.554178e+09</th>\n",
       "      <th>1.564027e+09</th>\n",
       "      <th>1.574053e+09</th>\n",
       "      <th>1.583557e+09</th>\n",
       "      <th>1.592712e+09</th>\n",
       "      <th>1.601438e+09</th>\n",
       "      <th>1.609477e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>981.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1074</td>\n",
       "      <td>...</td>\n",
       "      <td>1050</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>927</td>\n",
       "      <td>934.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>957</td>\n",
       "      <td>980.0</td>\n",
       "      <td>896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>53</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2.507508e+08  4.258800e+08  5.468400e+08  6.389460e+08  7.126416e+08  \\\n",
       "Topic                                                                         \n",
       "-1            981.0         899.0         949.0         971.0         997.0   \n",
       " 0              8.0          31.0          31.0          35.0          28.0   \n",
       " 1             85.0          87.0         211.0         222.0         212.0   \n",
       " 2              2.0           1.0           2.0           4.0           0.0   \n",
       " 3              4.0           2.0           2.0           8.0          26.0   \n",
       "\n",
       "       7.783920e+08  8.361936e+08  8.975376e+08  9.497268e+08  9.869616e+08  \\\n",
       "Topic                                                                         \n",
       "-1            910.0        1013.0        1032.0        1139.0          1074   \n",
       " 0             47.0          44.0          67.0          58.0            30   \n",
       " 1            159.0         144.0         153.0          58.0            94   \n",
       " 2              2.0           6.0           3.0           2.0             6   \n",
       " 3             11.0           5.0           6.0           6.0             6   \n",
       "\n",
       "       ...  1.521864e+09  1.532750e+09  1.543986e+09  1.554178e+09  \\\n",
       "Topic  ...                                                           \n",
       "-1     ...          1050         960.0        1013.0           927   \n",
       " 0     ...             4           7.0           6.0             5   \n",
       " 1     ...            30          22.0          19.0            21   \n",
       " 2     ...            37          32.0          45.0            53   \n",
       " 3     ...            26          17.0          11.0            24   \n",
       "\n",
       "       1.564027e+09  1.574053e+09  1.583557e+09  1.592712e+09  1.601438e+09  \\\n",
       "Topic                                                                         \n",
       "-1            934.0         977.0         996.0           957         980.0   \n",
       " 0              6.0           3.0           4.0             7           4.0   \n",
       " 1             22.0          18.0          27.0            26          29.0   \n",
       " 2             31.0          40.0          50.0            48          36.0   \n",
       " 3             21.0          22.0          23.0            22          17.0   \n",
       "\n",
       "       1.609477e+09  \n",
       "Topic                \n",
       "-1            896.0  \n",
       " 0              6.0  \n",
       " 1             24.0  \n",
       " 2             33.0  \n",
       " 3             18.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in 0s\n",
    "#ts_unique = top_freq.Timestamp.unique()\n",
    "#topics    = top_freq.Topic.unique()\n",
    "\n",
    "# Go through each ts_unique and topics\n",
    "#for ts in ts_unique:\n",
    "#  if ts not in top_freq_dict:\n",
    "#    top_freq_dict[ts] = {}\n",
    "#  for toc in topics:\n",
    "#    if toc not in top_freq_dict[ts]:\n",
    "#      top_freq_dict[ts][toc] = 0\n",
    "\n",
    "# Realize that I can use DataFrame.fillna after dataframe is created\n",
    "top_freq_df = pd.DataFrame.from_dict(top_freq_dict)\n",
    "top_freq_df.fillna(0, inplace=True)\n",
    "top_freq_df.sort_index(axis=0, inplace=True)  # sort rows\n",
    "top_freq_df.sort_index(axis=1, inplace=True)  # sort columns\n",
    "top_freq_df.index.name = \"Topic\"\n",
    "top_freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_freq_df.to_csv(work_dir / 'table4_4c_topic_frequency_per_timestamp.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Forcasting___ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folder\n",
    "dir_forcast = work_dir / \"_forcast\"\n",
    "dir_forcast.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_unique    = top_freq_df.columns.to_list()\n",
    "topics       = top_freq_df.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asfreq_series(row_series):\n",
    "  '''This is to get a pandas series that with day info set to 1, and fill in\n",
    "     missing months with NaN.\n",
    "    Args:\n",
    "      row_series (Series): timestamps as indices and doc frequency as values\n",
    "    Return\n",
    "      y_df (DataFrame): with dates as indicies and a column of y values\n",
    "  '''\n",
    "  x  = row_series.index.to_list()\n",
    "  y  = row_series.values.tolist()\n",
    "\n",
    "  # Turn timestamps to dates\n",
    "  x_dates = [datetime.fromtimestamp(ts+1) for ts in x]\n",
    "  # Change all dates to 1st day of the month. This is done otherwise anything\n",
    "  # not on the 1st day of the month will be removed when df.asfreq is applied.\n",
    "  x_dates = [datetime.strptime(d.strftime(\"%Y:%m\"), \"%Y:%m\") for d in x_dates]\n",
    "\n",
    "  # Create a pandas series with y using dates as indices\n",
    "  y_df = pd.DataFrame({\"date\":x_dates, \"y\":y})\n",
    "  y_df = y_df.set_index('date')\n",
    "\n",
    "  # Set frequency to monthly and fill in missing data as NaN\n",
    "  y_df = y_df.asfreq('MS') \n",
    "  y_df = y_df.sort_index() # make sure the date is sorted\n",
    "\n",
    "  return y_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ForecasterAutoreg\n",
    "\n",
    "The results are linear, does not look right. This approach also requires missing data to be imputed. There are simply too many missing values at the month level.\n",
    "\n",
    "After working on ARIMA, the results pretty much the same, both crappy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ForecasterAutoreg(toc, row_series, steps_test, steps_future, dir_forcast):\n",
    "  '''Fit recursive autoregressors with data for a topic\n",
    "  Args:\n",
    "    toc (int): topic\n",
    "    row_series (Series): a pandas series with dates as indices and frequency as \n",
    "      values for a topic that derives from a row in the topic-timestamp \n",
    "      dataframe\n",
    "    steps_test (int): number of data witheld for testing\n",
    "    steps_future (int): number of months to predict into the future\n",
    "    dir_forcast (Path): directory for forcast results\n",
    "  Returns:\n",
    "    predictions_future (Series): the future prediction values\n",
    "  Output:\n",
    "    plots (pdf): original data + predictions\n",
    "    values (txt): original data + predictions\n",
    "  '''\n",
    "  y_df = get_asfreq_series(row_series)\n",
    "\n",
    "  # impute missing data\n",
    "  y_df['y_spline'] = y_df['y'].interpolate(option='spline')\n",
    "\n",
    "  # Set last few months as test set\n",
    "  data_train = y_df[:-steps_test]\n",
    "  data_test  = y_df[-steps_test:]\n",
    "\n",
    "  # train ForcasterAutoreg\n",
    "  forecaster_ar = ForecasterAutoreg(\n",
    "                  regressor = RandomForestRegressor(random_state=seed),\n",
    "                  lags      = 6)\n",
    "\n",
    "  # Lags used as predictors\n",
    "  lags_grid = [10, 20]\n",
    "\n",
    "  # Regressor's hyperparameters\n",
    "  param_grid = {'n_estimators': [50, 100, 200], \n",
    "                'max_depth': [3, 5, 10]}\n",
    "\n",
    "  results_grid = grid_search_forecaster(\n",
    "                          forecaster         = forecaster_ar,\n",
    "                          y                  = data_train['y_spline'],\n",
    "                          param_grid         = param_grid,\n",
    "                          lags_grid          = lags_grid,\n",
    "                          steps              = steps_test,\n",
    "                          refit              = True,\n",
    "                          metric             = 'mean_squared_error',\n",
    "                          initial_train_size = int(len(data_train)*0.5),\n",
    "                          fixed_train_size   = False,\n",
    "                          return_best        = True,\n",
    "                          verbose            = False)\n",
    "\n",
    "  # get best parameters\n",
    "  num_lags     = len(results_grid.iloc[0]['lags'])\n",
    "  max_depth    = results_grid.iloc[0]['max_depth']\n",
    "  n_estimators = results_grid.iloc[0]['n_estimators'] \n",
    "  \n",
    "  # generate final model\n",
    "  regressor_rf = RandomForestRegressor(max_depth=5, n_estimators=100, \n",
    "                                     random_state=seed)\n",
    "  forecaster_final = ForecasterAutoreg(regressor = regressor_rf,\n",
    "                                      lags      = 20)\n",
    "  forecaster_final.fit(y=data_train['y_spline'])\n",
    "\n",
    "  # generate predictions\n",
    "  predictions_test            = forecaster_final.predict(steps=steps_test)\n",
    "  predictions_test_and_future = forecaster_final.predict(steps=steps_test + \\\n",
    "                                                               steps_future)\n",
    "  predictions_future = predictions_test_and_future[steps_test:]\n",
    "\n",
    "  # plot orignal, imputed, and prediction values\n",
    "  fig, ax=plt.subplots(figsize=(9, 4))\n",
    "  data_train['y_spline'].plot(ax=ax, label='train')\n",
    "  data_test['y_spline'].plot(ax=ax, label='test')\n",
    "  y_df['y'].plot(ax=ax, style='o', ms=5, label='original data')\n",
    "  predictions_future.plot(ax=ax, label='predictions:test + future')\n",
    "  fig.savefig(dir_forcast / f'figure4_4c_forcast_topic_{toc}_autoreg.pdf')\n",
    "\n",
    "  return predictions_future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not let it finish\n",
    "'''\n",
    "steps_test   = 24\n",
    "steps_future = 120\n",
    "c = 0\n",
    "for toc in tqdm(topics):\n",
    "  row_series = top_freq_df.loc[toc]\n",
    "  predictions_future = fit_ForecasterAutoreg(toc, row_series, steps_test, \n",
    "                                             steps_future, dir_forcast)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA\n",
    "\n",
    "- Functions from [ML Mastery](https://machinelearningmastery.com/grid-search-arima-hyperparameters-with-python/)\n",
    "- Discussion on [ARIMA with missing values](https://github.com/statsmodels/statsmodels/issues/6596)\n",
    "- There is also pmdarima that does auto ARIMA in [this post section 12](https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/). But this does not deal with missing values. So still need to impute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_auto_arima(series):\n",
    "  model = pm.auto_arima(series, \n",
    "                        start_p=0, start_q=0,\n",
    "                        test='adf',       # use adftest to find optimal 'd'\n",
    "                        max_p=3, max_q=3, # maximum p and q\n",
    "                        m=1,              # frequency of series\n",
    "                        d=None,           # let model determine 'd'\n",
    "                        seasonal=False,   # No Seasonality\n",
    "                        start_P=0, \n",
    "                        D=0, \n",
    "                        error_action='ignore',  \n",
    "                        suppress_warnings=True, \n",
    "                        stepwise=True,\n",
    "                        trace=False)\n",
    "\n",
    "  best_param = model.arima_res_.specification['order']\n",
    "  \n",
    "  return model, best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED: slow\n",
    "# Another implementation doing grid search\n",
    "# change function name\n",
    "def grid_search_arima(dataset, p_values, d_values, q_values):\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tbest_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "\t# 10/12/22: Modify the original function to get a list of combinations so\n",
    "\t#   tqdm can be used.\n",
    "\tcombo = list(product(p_values, d_values, q_values))\n",
    "\n",
    "\tfor order in tqdm(combo):\n",
    "\t\ttry:\n",
    "\t\t\tmse = evaluate_arima_model(dataset, order)\n",
    "\t\t\tif mse < best_score:\n",
    "\t\t\t\tbest_score, best_cfg = mse, order\n",
    "\t\t\t#print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\tprint('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n",
    "\t\n",
    "\t# added\n",
    "\treturn best_score, best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED: part of the function above\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.66)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\t# make predictions\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\tmodel = ARIMA(history, order=arima_order)\n",
    "\t\tmodel_fit = model.fit()\n",
    "\t\tyhat = model_fit.forecast()[0]\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\t# calculate out of sample error\n",
    "\trmse = sqrt(mean_squared_error(test, predictions))\n",
    "\treturn rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit ARIMA for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "#p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "#d_values = range(0, 3)\n",
    "#q_values = range(0, 3)\n",
    "\n",
    "for toc in tqdm(topics):\n",
    "  # Get the timestamp-freq series for a topic\n",
    "  toc_series   = top_freq_df.loc[toc]\n",
    "  # Get a dataframe where the rows are in months, months without values have NaN\n",
    "  toc_y_df     = get_asfreq_series(toc_series)\n",
    "  # Impute NaN with spline\n",
    "  toc_y_df_imp = toc_y_df['y'].interpolate(option='spline')\n",
    "\n",
    "  # Run auto ARIMA and get best param\n",
    "  model_aa, best_param = run_auto_arima(toc_y_df_imp)\n",
    "  #_, best_param = grid_search_arima(toc_y_df_imp, p_values, d_values, q_values)\n",
    "  \n",
    "  # Run ARIMA again with best param\n",
    "  model_arima = ARIMA(toc_y_df_imp, order=best_param)\n",
    "  model_fit   = model_arima.fit()\n",
    "\n",
    "  # Plottting\n",
    "  fig, ax = plt.subplots()\n",
    "  ax = toc_y_df_imp.iloc[0:].plot(ax=ax)\n",
    "  plot_predict(model_fit, '2020-01-01', '2024-12-01', ax=ax)\n",
    "  toc_y_df['y'].plot(ax=ax, style='o', ms=5, label='original data')\n",
    "  file_name = dir_forcast / f'figure4_4c_forcast_topic_{toc}_arima.pdf'\n",
    "  fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Curve fitting: LOWESS___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folder\n",
    "dir_lowess = work_dir / \"_lowess\"\n",
    "dir_lowess.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowess(toc, x, y, frac, it=3, plot=0):\n",
    "\n",
    "  lowess = sm.nonparametric.lowess\n",
    "  lowess_fit = lowess(y, x, frac=frac, it=it) \n",
    "  lowess_x   = list(zip(*lowess_fit))[0]\n",
    "  lowess_y   = list(zip(*lowess_fit))[1]\n",
    "\n",
    "  # create a function using the interp1d method\n",
    "  f     = interp1d(lowess_x, lowess_y, bounds_error=False)\n",
    "\n",
    "  #x_line = [i/10. for i in range(400)]\n",
    "  # define a sequence of inputs between the smallest and largest known inputs\n",
    "  x_line = np.arange(min(x), max(x), (max(x)-min(x))/100)\n",
    "  #x_date = [datetime.fromtimestamp(ts) for ts in lowess_x]\n",
    "  y_line = f(x_line)\n",
    "\n",
    "  # Create series\n",
    "  lowess_ser = pd.Series(lowess_y, index=lowess_x, name=toc)\n",
    "\n",
    "  if plot:\n",
    "    # get 2 decimal points for mse\n",
    "    mse = \"{:.2f}\".format(mean_squared_error(y, lowess_y))\n",
    "    plt.title(f\"topic {toc}, MSE={mse}\")\n",
    "    plt.plot(x, y, 'o')\n",
    "    #plt.plot(lowess_x, lowess_y, '*')\n",
    "    plt.plot(lowess_x, lowess_y, '*')\n",
    "    #plt.plot(x_new, y_new, '-')\n",
    "    plt.plot(x_line, y_line, '-')\n",
    "    plt.ylim([0, max([max(y), max(lowess_y)])])\n",
    "    plt.savefig(dir_lowess / f'figure4_4c_topic_{toc}_lowess.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "  return lowess_ser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y_idxs      = [] # indices (x, timestamps) with max y\n",
    "lowess_ser_list = [] # list of lowess-fitted series for different topics\n",
    "for toc in topics:\n",
    "  # series for the topic, timestamps as indices, frequencies as row\n",
    "  toc_series = top_freq_df.loc[toc]\n",
    "  x          = toc_series.index  # timestamps\n",
    "  y          = toc_series.values # frequencies\n",
    "\n",
    "  # series after lowess smoothing\n",
    "  lowess_ser = get_lowess(toc, x, y, 1/10, 3, plot=1)\n",
    "\n",
    "  max_y_idx  = lowess_ser.idxmax()\n",
    "  max_y_idxs.append(max_y_idx)\n",
    "  lowess_ser_list.append(lowess_ser)\n",
    "  print(toc, max_y_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output fitted values and topic order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for topic order\n",
    "max_y_idxs_ser = pd.Series(max_y_idxs, index=topics, name='max_y_timestamp')\n",
    "max_y_idxs_ser.to_csv(dir_lowess / \"table4_4c_timestamps_with_max_y.txt\")\n",
    "max_y_idxs_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://sparkbyexamples.com/pandas/pandas-create-dataframe-from-multiple-series/\n",
    "lowess_df = pd.concat(lowess_ser_list, axis=1).transpose()\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-sort-a-pandas-dataframe-based-on-column-names-or-row-index/\n",
    "lowess_df.sort_index(inplace=True, axis=1)\n",
    "\n",
    "lowess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess_df.to_csv(dir_lowess / \"table4_4c_toc_timestamps_lowess_vals.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Code testing___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_unique = top_freq_df.columns.to_list()\n",
    "\n",
    "data = top_freq_df.iloc[1]\n",
    "x  = data.index.to_list()\n",
    "y  = data.values.tolist()\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy natural cubic smoothing spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same cubic spline (k=3) as before\n",
    "np.random.seed(seed)\n",
    "spl    = UnivariateSpline(x, y, k=3, ext=0)\n",
    "xs     = np.linspace(x[0], x[-1], 150) \n",
    "ys_spl = spl(xs)\n",
    "plt.plot(x, y, 'o', xs, ys_spl, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy cubic spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs    = CubicSpline(x, y, bc_type='natural')\n",
    "ys_cs = cs(xs)\n",
    "plt.plot(x, y, 'o', xs, ys_cs, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive autoregressive forecasting\n",
    "\n",
    "https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python-scikitlearn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn timestamps to dates\n",
    "x_dates = [datetime.fromtimestamp(ts+1) for ts in x]\n",
    "\n",
    "# Change all dates to 1st day of the month. This is done otherwise anything\n",
    "# not on the 1st day of the month will be removed when df.asfreq is applied.\n",
    "x_dates = [datetime.strptime(d.strftime(\"%Y:%m\"), \"%Y:%m\") for d in x_dates]\n",
    "x_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas series with y using dates as indices\n",
    "y_df = pd.DataFrame({\"date\":x_dates, \"y\":y})\n",
    "y_df = y_df.set_index('date')\n",
    "\n",
    "# Set frequency to monthly and fill in missing data as NaN\n",
    "y_df = y_df.asfreq('MS') \n",
    "y_df = y_df.sort_index() # make sure the date is sorted\n",
    "print(f'#rows: {y_df.shape[0]}, #missing_val:{y_df.isnull().any(axis=1).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data\n",
    "y_df['y_spline'] = y_df['y'].interpolate(option='spline')\n",
    "print('#rows:', y_df.shape[0], \n",
    "      '#missing_val:',y_df['y_spline'].isnull().any().sum())\n",
    "plt.plot(y_df['y_spline'], 'yo')\n",
    "plt.plot(y_df['y'], 'r+')\n",
    "plt.legend([\"y_spline\", \"y\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that a temporary index is complete\n",
    "(y_df.index == pd.date_range(start=y_df.index.min(),\n",
    "                             end=y_df.index.max(),\n",
    "                             freq=y_df.index.freq)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set last few months as test set\n",
    "steps = 36\n",
    "data_train = y_df[:-steps]\n",
    "data_test  = y_df[-steps:]\n",
    "\n",
    "print(f\"Train dates:{data_train.index.min()}-{data_train.index.max()} (n={len(data_train)})\")\n",
    "print(f\"Test dates :{data_test.index.min()}-{data_test.index.max()} (n={len(data_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ForcasterAutoReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_ar = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=seed),\n",
    "                lags      = 6)\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [5, 10, 20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = {'n_estimators': [100, 500], 'max_depth': [3, 5, 10]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster_ar,\n",
    "                        y                  = data_train['y_spline'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best result with smallest mse\n",
    "results_grid.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num_lags=\",len(results_grid.iloc[0]['lags']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_rf = RandomForestRegressor(max_depth=5, n_estimators=100, \n",
    "                                     random_state=seed)\n",
    "forecaster_final = ForecasterAutoreg(regressor = regressor_rf,\n",
    "                                     lags      = 20)\n",
    "forecaster_final.fit(y=data_train['y_spline'])\n",
    "predictions_test = forecaster_final.predict(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next 10 years\n",
    "steps_future = 120\n",
    "predictions_future = forecaster_final.predict(steps=steps+steps_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data_train['y_spline'].plot(ax=ax, label='train')\n",
    "data_test['y_spline'].plot(ax=ax, label='test')\n",
    "y_df['y'].plot(ax=ax, style='o', ms=5, label='original data')\n",
    "predictions_future.plot(ax=ax, label='predictions:test + future')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error\n",
    "error_mse = mean_squared_error(y_true = data_test['y_spline'],\n",
    "                               y_pred = predictions_test)\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_future[steps:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA plot\n",
    "\n",
    "https://stackoverflow.com/questions/73112516/arimaresults-object-has-no-attribute-plot-predict-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "dta = sm.datasets.sunspots.load_pandas().data[['SUNACTIVITY']]\n",
    "\n",
    "# freq alias: 'A': year end frequency\n",
    "#https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\n",
    "dta.index = pd.date_range(start='1700', end='2009', freq='A')\n",
    "dta.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = ARIMA(dta, order=(0,2,0)).fit()\n",
    "fig, ax = plt.subplots()\n",
    "ax = dta.loc['1950':].plot(ax=ax)\n",
    "plot_predict(res, '1990', '2012', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series = top_freq_df.loc[1]\n",
    "test_y_df   = get_asfreq_series(test_series)\n",
    "test_y_df['y_spline'] = test_y_df['y'].interpolate(option='spline')\n",
    "test_y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_y_df.y_spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aa = run_auto_arima(test_y_df.y_spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model_aa.arima_res_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = model_aa.arima_res_.specification['order']\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arima = ARIMA(test_y_df['y_spline'], order=best_param)\n",
    "model_fit   = model_arima.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/73112516/arimaresults-object-has-no-attribute-plot-predict-error\n",
    "fig, ax = plt.subplots()\n",
    "ax = test_y_df['y_spline'].iloc[0:].plot(ax=ax)\n",
    "plot_predict(model_fit, '2018-01-01', '2024-12-01', ax=ax)\n",
    "test_y_df['y'].plot(ax=ax, style='o', ms=5, label='original data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting directly with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  x  = test_series.index.to_list()\n",
    "  y  = test_series.values.tolist()\n",
    "\n",
    "  # Turn timestamps to dates\n",
    "  x_dates  = [datetime.fromtimestamp(ts+1) for ts in x]\n",
    "  # Change all dates to 1st day of the month. This is done otherwise anything\n",
    "  # not on the 1st day of the month will be removed when df.asfreq is applied.\n",
    "  x_dates2 = [datetime.strptime(d.strftime(\"%Y:%m\"), \"%Y:%m\") for d in x_dates]\n",
    "\n",
    "  # Create a pandas series with y using dates as indices\n",
    "  y_df_ori = pd.DataFrame({\"date\":x_dates, \"y\":y})\n",
    "  y_df_mod = pd.DataFrame({\"date\":x_dates2, \"y\":y})\n",
    "  y_df_ori = y_df_ori.set_index('date')\n",
    "  y_df_mod = y_df_mod.set_index('date')\n",
    "  y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_ori.index = pd.DatetimeIndex(y_df_ori.index).to_period('M')\n",
    "y_df_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ARIMA with original series with timestamps\n",
    "model_arima = ARIMA(y_df_ori['y'], order=(1,1,0))\n",
    "model_fit   = model_arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = y_df_ori['y'].iloc[0:].plot(ax=ax)\n",
    "plot_predict(model_fit, '2018-01', '2024-12', ax=ax)\n",
    "y_df_ori['y'].plot(ax=ax, style='o', ms=5, label='original data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LOWESS curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_series = top_freq_df.loc[topics[0]]\n",
    "x = toc_series.index\n",
    "y = toc_series.values\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowess(x, y, frac, it=3, plot=0):\n",
    "\n",
    "  lowess = sm.nonparametric.lowess\n",
    "  lowess_fit = lowess(y, x, frac=frac, it=it) \n",
    "  lowess_x   = list(zip(*lowess_fit))[0]\n",
    "  lowess_y   = list(zip(*lowess_fit))[1]\n",
    "\n",
    "  print(\"MSE=\", mean_squared_error(y, lowess_y))\n",
    "\n",
    "  # create a function using the interp1d method\n",
    "  f     = interp1d(lowess_x, lowess_y, bounds_error=False)\n",
    "\n",
    "  #x_line = [i/10. for i in range(400)]\n",
    "  # define a sequence of inputs between the smallest and largest known inputs\n",
    "  x_line = np.arange(min(x), max(x), (max(x)-min(x))/100)\n",
    "  #x_date = [datetime.fromtimestamp(ts) for ts in lowess_x]\n",
    "  y_line = f(x_line)\n",
    "  if plot:\n",
    "    plt.plot(x, y, 'o')\n",
    "    #plt.plot(lowess_x, lowess_y, '*')\n",
    "    plt.plot(lowess_x, lowess_y, '*')\n",
    "    #plt.plot(x_new, y_new, '-')\n",
    "    plt.plot(x_line, y_line, '-')\n",
    "    plt.ylim([0, max([max(y), max(lowess_y)])])\n",
    "    plt.show()\n",
    "\n",
    "  lowess_ser = pd.Series(lowess_y, index=lowess_x)\n",
    "  max_x = lowess_ser.max()\n",
    "  return lowess_ser, max_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess_ser, max_x = get_lowess(x, y, 1/10, 3, plot=1)\n",
    "lowess_ser, datetime.fromtimestamp(max_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('timeseries': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f8cb91f47827f211941a065b76f743227477234c3424914d54c3d52b7cecf3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
