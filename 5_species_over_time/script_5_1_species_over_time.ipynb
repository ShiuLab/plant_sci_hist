{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Step 5.1: Species over time__\n",
    "\n",
    "Goals here:\n",
    "- Determine overall genus mention\n",
    "- Determine genus mention over time\n",
    "- Same analysis at other taxonmic levels\n",
    "\n",
    "Considerations:\n",
    "- Deal with common names\n",
    "  - Common names must be those in the USDA common name database.\n",
    "  - If some non-specific names are mentioned, even though they most likely refer to a particular species frequently, they will not be counted.\n",
    "- Deal with synonyms\n",
    "  - Both NCBI and USDA data have synonym info. They will be pointed to a specific level.\n",
    "- Deal with redundancy\n",
    "  - It is possible that multiple taxa levels are mentioned in a single title/abstract: e.g., Solanceae, Solanum, tomato. At the genus level, it will be counted just one time at both the family and the genus levels for this record.\n",
    "- Missing info\n",
    "  - Some species info may be mentioned only in the full text.\n",
    "- NCBI compressed taxa dump was downloaded in 11/11/2021. Notice that some taxa names are found in USDA common names and in NCBI taxonomy website, but not in the names.dmp.\n",
    "  - Example: Achnatherum  \n",
    "  - One level up, tribe Stipeae, only have 25 children when there should be 34. Missing: Barkworthia, Eriocoma, Neotrinia, Oryzopsis (ricegrass), Pseudoeriocoma, Ptilagrostiella, Stipellula, Thorneochloa, x Eriosella.\n",
    "  - Download the taxnomy dump again from [here](https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.tar.gz) on 9/20/22. \n",
    "- Also realized that I need to include `no_rank` taxa when parse parent-child relations, otherwise, the lineage will be broken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Set up___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, nltk, re, multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix, dok_matrix\n",
    "from time import time\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting working directory\n",
    "proj_dir   = Path.home() / \"projects/plant_sci_hist\"\n",
    "work_dir   = proj_dir / \"5_species_over_time/\"\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# species information\n",
    "# NEED TO SPECIFY\n",
    "# NEED TO SPECIFY\n",
    "dir1           = proj_dir / \"1_obtaining_corpus\"\n",
    "#names_dmp_path = dir1 / \"taxonomy/names.dmp\"\n",
    "#nodes_dmp_path = dir1 / \"taxonomy/nodes.dmp\"\n",
    "usda_plant_db  = dir1 / \"usda/USDA_Plants_Database.txt\"\n",
    "\n",
    "names_dmp_path = work_dir / \"taxonomy/names.dmp\"\n",
    "nodes_dmp_path = work_dir / \"taxonomy/nodes.dmp\"\n",
    "\n",
    "# plant science corpus with date and other info\n",
    "dir2        = proj_dir / \"2_text_classify//2_5_predict_pubmed\"\n",
    "corpus_file = dir2 / \"corpus_plant_421658.tsv.gz\"\n",
    "\n",
    "# So PDF is saved in a format properly\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Get plant names___\n",
    "\n",
    "In `1_obtaining_corpus`, plant names are from two sources:\n",
    "- NCBI: the taxonomy database with mention of all taxa levels\n",
    "  - This will also contain synonyms for different levels.\n",
    "- USDA: plant common names with species information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI taxonomy\n",
    "\n",
    "Functions modified from:\n",
    "- `1_obtaining_corpus\\script_get_plant_taxa.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse name_dmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# For: Getting the tax_id of Viridiplantae and generate a dictionary.\n",
    "# Parameters\n",
    "#   names_dmp_file - The Path object to the names.dmp file from NCBI taxonomy.\n",
    "#   target - Target taxon name.\n",
    "# Return:\n",
    "#   target_id - The NCBI taxon ID for the taxon.\n",
    "#   names_dic - A dictionary with: {tax_id:{name_class:[names]}\n",
    "#\n",
    "def get_name_dict(names_dmp_path, target):\n",
    "  target_id = \"\"\n",
    "  names_dmp = open(names_dmp_path)\n",
    "  L         = names_dmp.readline()\n",
    "  names_dic = {}\n",
    "  while L != \"\":\n",
    "    L = L.strip().split(\"\\t\")\n",
    "    tax_id = L[0]\n",
    "    name   = L[2]\n",
    "    name_c = L[6]\n",
    "    if L[2] == target:\n",
    "      print(f\"{target} tax_id:\",tax_id)\n",
    "      target_id = tax_id\n",
    "\n",
    "    if tax_id not in names_dic:\n",
    "      names_dic[tax_id] = {name_c:[name]}\n",
    "    elif name_c not in names_dic[tax_id]:\n",
    "      names_dic[tax_id][name_c] = [name]\n",
    "    else:\n",
    "      names_dic[tax_id][name_c].append(name)\n",
    "    L = names_dmp.readline()\n",
    "  return target_id, names_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viridiplantae tax_id: 33090\n"
     ]
    }
   ],
   "source": [
    "target_id, names_dic = get_name_dict(names_dmp_path, 'Viridiplantae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'authority': ['Chlorobionta Jeffrey, 1982',\n",
       "   'Chloroplastida Adl et al. 2005',\n",
       "   'Viridiplantae Cavalier-Smith, 1981'],\n",
       "  'synonym': ['Chlorobionta', 'Chloroplastida'],\n",
       "  'equivalent name': ['Chlorophyta/Embryophyta group',\n",
       "   'chlorophyte/embryophyte group'],\n",
       "  'blast name': ['green plants'],\n",
       "  'common name': ['green plants'],\n",
       "  'scientific name': ['Viridiplantae']},\n",
       " {'authority': ['Stipeae Dumort., 1824'], 'scientific name': ['Stipeae']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dic['33090'], names_dic['147383']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse node_dmp\n",
    "\n",
    "This is to get:\n",
    "- Parent-child relation\n",
    "- Child-parent relation\n",
    "- Rank count:\n",
    "- Taxa_id-rank relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# For: Get the parent-child relationships from nodes.dmp file.\n",
    "# Parameters: \n",
    "#   nodes_dmp_path - The Path object to the nodes.dmp file from NCBI taxonomy.\n",
    "# Return: \n",
    "#   parent_child - A dictionary with {parent:[children]}\n",
    "#\n",
    "def get_parent_child(nodes_dmp_path):\n",
    "    nodes_dmp    = open(nodes_dmp_path)\n",
    "    L            = nodes_dmp.readline()\n",
    "    rank_d       = {} # {rank: count}\n",
    "    taxa_rank    = {} # {taxa_id: rank}\n",
    "    rank_taxa    = {} # {rank: taxa_id}\n",
    "    parent_child = {}\n",
    "    child_parent = {}\n",
    "    target_ranks = ['genus', 'family', 'order']\n",
    "\n",
    "    debug_count  = 0\n",
    "    debug_list   = []\n",
    "    while L != \"\":\n",
    "        L = L.strip().split(\"\\t\")\n",
    "        tax_id = L[0]\n",
    "        par_id = L[2]\n",
    "        rank   = L[4]\n",
    "        if rank not in rank_d:\n",
    "            rank_d[rank] = 1\n",
    "        else:\n",
    "            rank_d[rank]+= 1\n",
    "        \n",
    "        # Don't want any species or taxon with no rank\n",
    "        # 9/20/22: actually, do not want no rank result in problem. Am example\n",
    "        #   is taxid=2822797, child of 147368, this lead to some taxa missing.\n",
    "        #   so removed.\n",
    "        #if rank not in [\"no rank\", \"species\"]:\n",
    "        if rank != \"species\":\n",
    "            # debug\n",
    "            if par_id == '147383':\n",
    "                debug_count += 1\n",
    "                debug_list.append(names_dic[tax_id]['scientific name'][0])\n",
    "                #print(debug_count, tax_id, names_dic[tax_id]['scientific name'])\n",
    "\n",
    "            # populate parent_child dict\n",
    "            if par_id not in parent_child:\n",
    "                parent_child[par_id] = [tax_id]\n",
    "            else:\n",
    "                parent_child[par_id].append(tax_id)\n",
    "            \n",
    "             # populate child_parent dict\n",
    "            if tax_id not in child_parent:\n",
    "                child_parent[tax_id] = par_id\n",
    "            else:\n",
    "                print(f\"ERR: {tax_id} with >1 parents\",\n",
    "                        child_parent[tax_id], par_id)\n",
    "            \n",
    "            # populate taxa_rank and rank_taxa dicts\n",
    "            taxa_rank[tax_id] = rank\n",
    "            \n",
    "            if rank not in rank_taxa:\n",
    "                rank_taxa[rank] = [tax_id]\n",
    "            else:\n",
    "                rank_taxa[rank].append(tax_id)\n",
    "            \n",
    "        L = nodes_dmp.readline()\n",
    "        \n",
    "    return parent_child, child_parent, rank_d, taxa_rank, rank_taxa, debug_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_child, child_parent, rank_d, taxa_rank, rank_taxa, debug_list = \\\n",
    "                                              get_parent_child(nodes_dmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get offsprings of Viridiplantae\n",
    "\n",
    "These are the names to search for, after adding the USDA names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# For: Get the offsprings of a parent.\n",
    "# Parameters: \n",
    "#   p - The parent taxa ID to get children for.\n",
    "#   paren_child - The dictionary returned from get_parent_child().\n",
    "#   offspring - An initially empty list to append offspring IDs.\n",
    "# Return: \n",
    "#   offspring - The populated offspring list.\n",
    "#\n",
    "def get_offsprings(p, parent_child, offsprings, debug=0):\n",
    "    if debug:\n",
    "        print(p)\n",
    "    if p in parent_child:\n",
    "        # Initialize c with an empty element for debugging purpose\n",
    "        #c = [\"\"]\n",
    "        c = parent_child[p]\n",
    "        if debug:\n",
    "            print(\"\",p, c)\n",
    "            if p == \"147383\":\n",
    "                print(\"debug parent found\")\n",
    "\n",
    "        offsprings.extend(c)\n",
    "        for a_c in c:\n",
    "            get_offsprings(a_c, parent_child, offsprings)\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\" NO CHILD\")\n",
    "    return offsprings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsprings_33090 = get_offsprings(target_id, parent_child, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25232"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(offsprings_33090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26782"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert taxa id into scientific names\n",
    "offspring_names = []\n",
    "redun = {}\n",
    "for o in offsprings_33090:\n",
    "    if o in names_dic:\n",
    "        for nc in names_dic[o]: # for each name_class\n",
    "            if nc != 'authority': \n",
    "                for name in names_dic[o][nc]:\n",
    "                    if name not in redun:\n",
    "                        offspring_names.append(name)\n",
    "                        redun[name] = 0\n",
    "                    #else:\n",
    "                    #    print(\"Redun:\", name)\n",
    "\n",
    "# Note that this number is larger than offspring_33090 which contain indicies\n",
    "# This is because there are other names, like synonyms for each index.\n",
    "len(offspring_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle\n",
    "with open(work_dir / \"viridiplantae_offspring_names.pickle\", \"wb\") as f:\n",
    "  pickle.dump(offspring_names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USDA names\n",
    "\n",
    "Functions modified from:\n",
    "- `1_obtaining_corpus\\script_get_plant_common_names.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = {} # {common_name:[scientific name, family]}\n",
    "\n",
    "with open(usda_plant_db) as f:\n",
    "    f.readline() # header, don't need it\n",
    "    L = f.readline()\n",
    "    while L != \"\":\n",
    "        L = L.strip()\n",
    "        # There is empty line in the file.\n",
    "        if L == \"\":\n",
    "            break\n",
    "        #print(L.split(\",\"))\n",
    "        try:\n",
    "            # some names have \",\" in there. So need to split with \"\"\\,\"\n",
    "            [symbol, synonym, sname, cname, fam] = L.split(\"\\\",\")\n",
    "        except ValueError:\n",
    "            print(\"ValueError:\",[L])\n",
    "            break\n",
    "        # rid of quotes\n",
    "        \n",
    "        [symbol, synonym, sname, cname, fam] = [symbol.split(\"\\\"\")[1], \n",
    "                                                synonym.split(\"\\\"\")[1], \n",
    "                                                sname.split(\"\\\"\")[1], \n",
    "                                                cname.split(\"\\\"\")[1], \n",
    "                                                fam.split(\"\\\"\")[1]]\n",
    "        #print([symbol, synonym, sname, cname, fam])\n",
    "        # Get genus name out\n",
    "        genus = sname.split(\" \")[0]\n",
    "\n",
    "        if cname != \"\":\n",
    "            if cname not in cnames:\n",
    "                cnames[cname] = [genus, fam]\n",
    "            #else:\n",
    "            #    print(\"Redun cname:\", [cname], cnames[cname], [sname,fam])        \n",
    "        L = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle\n",
    "with open(work_dir / \"usda_common_names_dict.pickle\", \"wb\") as f:\n",
    "  pickle.dump(cnames, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rid of USDA names not found in the NCBI list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authority': ['Achnatherum P.Beauv., 1812'],\n",
       " 'scientific name': ['Achnatherum']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dic['37868']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all USDA genus names are found in NCBI\n",
    "# This helped identified issues with the parent_child script and missing data\n",
    "# due to the use of older NCBI taxa dump file. Currently, missings ones are \n",
    "# fungal and are excluded.\n",
    "cnames_overlap = {}\n",
    "for cname in cnames:\n",
    "  genus = cnames[cname][0]\n",
    "  if genus in offspring_names:\n",
    "    cnames_overlap[cname] = genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_names = list(cnames_overlap.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle\n",
    "with open(work_dir / \"usda_common_names.pickle\", \"wb\") as f:\n",
    "  pickle.dump(common_names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Find names in corpus___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(corpus_file, compression='gzip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421658, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function based on Mauro Di Pietro (2020):\n",
    "#  https://towardsdatascience.com/text-classification-with-no-model-training-935fe0e42180\n",
    "# For the purpose here, did not do lower-casing\n",
    "def utils_preprocess_text(text, lst_stopwords, flg_stemm=False, flg_lemm=True):\n",
    "    '''\n",
    "    Preprocess a string.\n",
    "    :parameter\n",
    "        :param text: string - name of column containing text\n",
    "        :param lst_stopwords: list - list of stopwords to remove\n",
    "        :param flg_stemm: bool - whether stemming is to be applied\n",
    "        :param flg_lemm: bool - whether lemmitisation is to be applied\n",
    "    :return\n",
    "        cleaned text\n",
    "    '''\n",
    "    ## clean: stripping, then removing punctuations.\n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # RE: replace any character that is not alphanumeric, underscore, whitespace\n",
    "    #  with ''. Originally this is it, but realized that biological terms have\n",
    "    #  special characters including roman numerals, dash, and \",\". So they are\n",
    "    #  not removed.\n",
    "    #text = re.sub(r'[^\\w\\s(α-ωΑ-Ω)-,]', '', text)\n",
    "    # Use the original method\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()    \n",
    "    \n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean text: 100%|██████████| 421658/421658 [05:04<00:00, 1385.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>QualifiedName</th>\n",
       "      <th>txt</th>\n",
       "      <th>reg_article</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>txt_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125390</th>\n",
       "      <td>557681</td>\n",
       "      <td>17504472</td>\n",
       "      <td>2007-05-17</td>\n",
       "      <td>The New phytologist</td>\n",
       "      <td>Small populations are mate-poor but pollinator...</td>\n",
       "      <td>If pollinators or compatible mates are scarce,...</td>\n",
       "      <td>plants</td>\n",
       "      <td>Small populations are mate-poor but pollinator...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825434</td>\n",
       "      <td>1</td>\n",
       "      <td>Small population matepoor pollinatorrich rare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321669</th>\n",
       "      <td>1165942</td>\n",
       "      <td>28756542</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>Applied biochemistry and biotechnology</td>\n",
       "      <td>Bioethanol Production from Soybean Residue via...</td>\n",
       "      <td>Bioethanol was produced using polysaccharide f...</td>\n",
       "      <td>soybean</td>\n",
       "      <td>Bioethanol Production from Soybean Residue via...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823566</td>\n",
       "      <td>1</td>\n",
       "      <td>Bioethanol Production Soybean Residue via Sepa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      PMID        Date  \\\n",
       "125390      557681  17504472  2007-05-17   \n",
       "321669     1165942  28756542  2017-08-02   \n",
       "\n",
       "                                       Journal  \\\n",
       "125390                     The New phytologist   \n",
       "321669  Applied biochemistry and biotechnology   \n",
       "\n",
       "                                                    Title  \\\n",
       "125390  Small populations are mate-poor but pollinator...   \n",
       "321669  Bioethanol Production from Soybean Residue via...   \n",
       "\n",
       "                                                 Abstract QualifiedName  \\\n",
       "125390  If pollinators or compatible mates are scarce,...        plants   \n",
       "321669  Bioethanol was produced using polysaccharide f...       soybean   \n",
       "\n",
       "                                                      txt  reg_article  \\\n",
       "125390  Small populations are mate-poor but pollinator...            1   \n",
       "321669  Bioethanol Production from Soybean Residue via...            1   \n",
       "\n",
       "          y_prob  y_pred                                          txt_clean  \n",
       "125390  0.825434       1  Small population matepoor pollinatorrich rare ...  \n",
       "321669  0.823566       1  Bioethanol Production Soybean Residue via Sepa...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Clean text\")\n",
    "lst_stopwords       = nltk.corpus.stopwords.words(\"english\")\n",
    "corpus[\"txt_clean\"] = corpus[\"txt\"].progress_apply(lambda x: \n",
    "                                        utils_preprocess_text(x, lst_stopwords))\n",
    "corpus.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"txt_clean\"].to_csv(work_dir / \"txt_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find names\n",
    "\n",
    "- Update csr values\n",
    "  - https://stackoverflow.com/questions/56981077/how-to-update-value-in-csr-matrix\n",
    "- See code testing section on the different functions tried\n",
    "- Got kernel error\n",
    "- Set aside the following as `script_5_1a_find_names.py` and run,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_csr(txt):\n",
    "\n",
    "  with multiprocessing.Pool(processes=14) as pool:\n",
    "    results_ncbi_list = list(tqdm(pool.imap(task, enumerate(txt)), \n",
    "                                  total=len(txt)))\n",
    "\n",
    "  row_idx   = []\n",
    "  col_idx   = []\n",
    "  csr_val   = []\n",
    "  for row, results_ncbi in enumerate(results_ncbi_list):\n",
    "    non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    row_idx.extend([row]*len(non0_idx))\n",
    "    col_idx.extend(non0_idx)\n",
    "    csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "  # create a sparse matrix with shape=(num_docs, num_names)\n",
    "  match_csr = csr_matrix((csr_val, (row_idx, col_idx)),\n",
    "                         shape=(txt.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  return match_csr\n",
    "\n",
    "def task(item):\n",
    "  '''Task to parallelize\n",
    "  Args:\n",
    "    item (tuple): (row_number, doc)\n",
    "  Return:\n",
    "    results_ncbi (list): an offspring_name is present in the doc (1) or not(1)\n",
    "  '''\n",
    "  (row, doc) = item\n",
    "  # Get the matching common names as a list\n",
    "  results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "  # Add the results to doc\n",
    "  for cname in results_usda:  # for each common name\n",
    "    genus = cnames[cname][0]  # get the genus name\n",
    "    doc += f\" {genus}\"        # add the genus name to doc\n",
    "  \n",
    "  # Match to NCBI names\n",
    "  results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "  return results_ncbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9301/421658 [00:38<28:43, 239.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    854\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb Cell 38\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m match_csr \u001b[39m=\u001b[39m get_match_csr(corpus[\u001b[39m'\u001b[39;49m\u001b[39mtxt_clean\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Save as a pickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(work_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmatch_csr.pickle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;32m/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb Cell 38\u001b[0m in \u001b[0;36mget_match_csr\u001b[0;34m(txt)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_match_csr\u001b[39m(txt):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39mwith\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mPool(processes\u001b[39m=\u001b[39m\u001b[39m14\u001b[39m) \u001b[39mas\u001b[39;00m pool:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     results_ncbi_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(tqdm(pool\u001b[39m.\u001b[39;49mimap(task, \u001b[39menumerate\u001b[39;49m(txt)), \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                   total\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(txt)))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m   row_idx   \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y255sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m   col_idx   \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 858\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    859\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "match_csr = get_match_csr(corpus['txt_clean'])\n",
    "\n",
    "# Save as a pickle\n",
    "with open(work_dir / \"match_csr.pickle\", \"wb\") as f:\n",
    "  pickle.dump(match_csr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the above code in script_5_1a_find_names.py and load the saved obj\n",
    "with open(work_dir / \"match_csr.pickle\", \"rb\") as f:\n",
    "  match_csr = pickle.load(, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Genus level counts___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get genus level tax_id and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of genus tax_ids\n",
    "genus_taxids = rank_taxa[\"genus\"]\n",
    "len(genus_taxids), genus_taxids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tax_ids to scientific names\n",
    "genus_names = [names_dic[tax_id]['scientific name'][0] \n",
    "               for tax_id in genus_taxids]\n",
    "len(genus_names), genus_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get match_csr column index for genus names\n",
    "genus_csr_idx   = [offspring_names.index(name) for name in genus_names]\n",
    "len(genus_csr_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the genus sub-csr\n",
    "genus_csr = match_csr[:, genus_csr_idx]\n",
    "genus_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Code testing___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing parent-child parsing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'37868' in offsprings_33090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Achnatherum' in offspring_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no rank': 233626,\n",
       " 'superkingdom': 4,\n",
       " 'genus': 104243,\n",
       " 'species': 1996830,\n",
       " 'order': 1761,\n",
       " 'family': 9909,\n",
       " 'subspecies': 27153,\n",
       " 'subfamily': 3203,\n",
       " 'strain': 45246,\n",
       " 'serogroup': 140,\n",
       " 'biotype': 17,\n",
       " 'tribe': 2304,\n",
       " 'phylum': 292,\n",
       " 'class': 462,\n",
       " 'species group': 347,\n",
       " 'forma': 633,\n",
       " 'clade': 917,\n",
       " 'suborder': 373,\n",
       " 'subclass': 166,\n",
       " 'varietas': 9244,\n",
       " 'kingdom': 13,\n",
       " 'subphylum': 32,\n",
       " 'forma specialis': 746,\n",
       " 'isolate': 1322,\n",
       " 'infraorder': 130,\n",
       " 'superfamily': 891,\n",
       " 'infraclass': 19,\n",
       " 'superorder': 57,\n",
       " 'subgenus': 1741,\n",
       " 'superclass': 6,\n",
       " 'parvorder': 26,\n",
       " 'serotype': 1235,\n",
       " 'species subgroup': 129,\n",
       " 'subcohort': 3,\n",
       " 'cohort': 5,\n",
       " 'genotype': 21,\n",
       " 'subtribe': 582,\n",
       " 'section': 479,\n",
       " 'series': 9,\n",
       " 'morph': 12,\n",
       " 'subkingdom': 1,\n",
       " 'superphylum': 1,\n",
       " 'subsection': 21,\n",
       " 'pathogroup': 5}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spot check parent-child\n",
    "len(parent_child['147383']), '37868' in parent_child['147383']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_147383 = '''\n",
    "    Achnatherum   \n",
    "    Aciachne   \n",
    "    Amelichloa   \n",
    "    Anatherostipa   \n",
    "    Anemanthele   \n",
    "    Austrostipa   \n",
    "    Barkworthia   \n",
    "    Celtica   \n",
    "    Eriocoma   \n",
    "    Hesperostipa   \n",
    "    Jarava   \n",
    "    Lorenzochloa   \n",
    "    Macrochloa   \n",
    "    Nassella   \n",
    "    Neotrinia   \n",
    "    Oloptum   \n",
    "    Ortachne   \n",
    "    Oryzopsis (ricegrass)   \n",
    "    Pappostipa   \n",
    "    Patis   \n",
    "    Piptatheropsis   \n",
    "    Piptatherum   \n",
    "    Piptochaetium   \n",
    "    Psammochloa   \n",
    "    Pseudoeriocoma   \n",
    "    Ptilagrostiella   \n",
    "    Ptilagrostis   \n",
    "    Stipa   \n",
    "    Stipellula   \n",
    "    Thorneochloa   \n",
    "    Timouria   \n",
    "    Trikeraia   \n",
    "    x Eriosella'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test string preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cholinesterases from plant tissues VI Preliminary characterization of enzymes from Solanum melongena L and Zea mays L Enzymes capable of hydrolyzing esters of thiocholine have been assayed in extracts of Solanum melongena L eggplant and Zea Mays L corn The enzymes from both species are inhibited by the anticholinesterases neostigmine physostigmine and 284c51 and by AMO1618 a plant growth retardant and they both have pH optima near pH 80 The enzyme from eggplant is maximally active at a substrate concentration of 015 mM acetylthiocholine and is inhibited at higher substrate concentrations On the basis of this last property the magnitude of inhibition by the various inhibitors and the substrate specificity we conclude that the enzyme from eggplant but not that from corn is a cholinesterase'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = corpus['txt'][1]\n",
    "doc = str(doc).strip()\n",
    "doc = re.sub(r'[^\\w\\s]', '', doc)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_147383_parsed = []\n",
    "for child in children_147383.split(\"\\n\"):\n",
    "  children_147383_parsed.append(child.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 33)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(children_147383_parsed), len(parent_child['147383'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['147381',\n",
       " '191503',\n",
       " '888031',\n",
       " '1648037',\n",
       " '1648038',\n",
       " '2822795',\n",
       " '2822796',\n",
       " '2822797']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_child['147368']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Oryzopsis (ricegrass)\n"
     ]
    }
   ],
   "source": [
    "# Still missing 1, this is a synonym\n",
    "for child in children_147383_parsed:\n",
    "  if child not in debug_list:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3041 phylum 33090\n",
      "35493 phylum 33090\n",
      "144313 no rank 33090\n",
      "144314 no rank 33090\n",
      "2806169 phylum 33090\n"
     ]
    }
   ],
   "source": [
    "# Spot check child_parent\n",
    "for child in parent_child[target_id]:\n",
    "  print(child, taxa_rank[child], child_parent[child])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'147383'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this was missing in the 2021 taxa dump file, now it is there\n",
    "child_parent['2950019']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing find names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zea', 'Solanum']\n"
     ]
    }
   ],
   "source": [
    "doc = corpus['txt_clean'][1]\n",
    "results_ncbi = [name for name in offspring_names if(name in doc)]\n",
    "print(results_ncbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "print(sum(results_ncbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eggplant', 'corn']\n"
     ]
    }
   ],
   "source": [
    "# Note that here I add two spaces to pad the names, to prevent matching to\n",
    "# substring.\n",
    "results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "print(results_usda)\n",
    "\n",
    "#results_usda = [1 if(f\" {name} \" in doc) else 0 for name in common_names ]\n",
    "#print(sum(results_usda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholinesterases plant tissue VI Preliminary characterization enzyme Solanum melongena L Zea may L Enzymes capable hydrolyzing ester thiocholine assayed extract Solanum melongena L eggplant Zea Mays L corn The enzyme specie inhibited anticholinesterase neostigmine physostigmine 284c51 AMO1618 plant growth retardant pH optimum near pH 80 The enzyme eggplant maximally active substrate concentration 015 mM acetylthiocholine inhibited higher substrate concentration On basis last property magnitude inhibition various inhibitor substrate specificity conclude enzyme eggplant corn cholinesterase Solanum Zea\n"
     ]
    }
   ],
   "source": [
    "## Get genus names for common matches and add the doc \n",
    "for cname in results_usda:\n",
    "  genus = cnames[cname][0]\n",
    "  doc += f\" {genus}\"\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Do the count again\n",
    "results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "print(sum(results_ncbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, [4360, 16432])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the non-zero indices\n",
    "non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "type(non0_idx), non0_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4360, 16432]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col_idx = [1,2]\n",
    "test_col_idx.extend(non0_idx)\n",
    "test_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ordered dict comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eggplant', 'corn', 0]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test_names = [\"eggplant\", \"corn\", \"spinach\"]\n",
    "[name if(f\" {name} \" in doc) else 0 for name in test_names ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eggplant', 1), ('corn', 1), ('spinach', 0)])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrderedDict((name, 1) if(f\" {name} \" in doc) else (name, 0) \n",
    "                                              for name in test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, True)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(common_names), \"eggplant\" in common_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_usda = OrderedDict(\n",
    "  (name, 1) if(f\" {name} \" in doc) else (name, 0) for name in common_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 0)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_usda['eggplant'], results_usda['corn'], results_usda['spinach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `get_match_csr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 24.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "test_txt_clean = corpus['txt_clean'][:5]\n",
    "test_match_csr = get_match_csr(test_txt_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421658, 26782)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected 421628 x 26782\n",
    "test_match_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26782)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_sum = test_match_csr.sum(axis=0)\n",
    "col_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4360,  5401, 10061, 16432, 21477, 21986])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non0_idx = col_sum.nonzero()[1]\n",
    "non0_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zea\n",
      "Hordeum\n",
      "Spinacia\n",
      "Solanum\n",
      "Sesbania\n",
      "Arachis\n"
     ]
    }
   ],
   "source": [
    "for idx in non0_idx:\n",
    "  print(offspring_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identification 120 mu phase decay delayed fluorescence spinach chloroplast subchloroplast particle intrinsic back reaction The dependence level phase thylakoids internal pH After 500 mu laser flash 120 mu phase decay delayed fluorescence visible variety circumstance spinach chloroplast subchloroplast particle enriched Photosystem II prepared mean digitonin The level phase high case inhibition oxygen evolution donor side Photosystem II Comparison result Babcock Sauer 1975 Biochim Biophys Acta 376 329344 indicates EPR signal IIf suppose due Z oxidized first secondary donor Photosystem II well correlated large amplitude 120 mu phase We explain 120 mu phase intrinsic back reaction excited reaction center presence Z predicted Van Gorkom Donze 1973 Photochem Photobiol 17 333342 The redox state Z dependent internal pH thylakoids The result effect pH mu region compared obtained m region'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spinach\n",
    "test_txt_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cholinesterases plant tissue VI Preliminary characterization enzyme Solanum melongena L Zea may L Enzymes capable hydrolyzing ester thiocholine assayed extract Solanum melongena L eggplant Zea Mays L corn The enzyme specie inhibited anticholinesterase neostigmine physostigmine 284c51 AMO1618 plant growth retardant pH optimum near pH 80 The enzyme eggplant maximally active substrate concentration 015 mM acetylthiocholine inhibited higher substrate concentration On basis last property magnitude inhibition various inhibitor substrate specificity conclude enzyme eggplant corn cholinesterase'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solanum, Zea\n",
    "test_txt_clean[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fructose 16bisphosphate aldolase activity Rhizobium specie FDP aldolase found present cellfree extract Rhizobium leguminosarum Rhizobium phaseoli Rhizobium trifolii Rhizobium meliloti Rhizobium lupini Rhizobium japonicum Rhizobium specie Arachis hypogaea Sesbania cannabina The enzyme 3 representative specie optimal activity pH 84 02M veronal buffer The enzyme activity completely lost treatment 60 degree C 15 min The Km value range 238 455 X 106M FDP Metal chelating agent inhibited enzyme activity monovalent bivalent metal ion failed stimulate activity Bivalent metal ion general rather inhibitory'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arachis, Sesbania  \n",
    "test_txt_clean[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Studies trypsin inhibitor barley I Purification property To clarify property function trypsin inhibitor Japanese barley comparison inhibitor Pirkka barley inhibitor isolated barley Hordeum distichum L var emend Lamark extraction 1 NaCl ammonium sulfate fractionation repeated chromatography DEAEcellulose CMcellulose The final purified preparation inhibitor found homogeneous chromatographic electrophoretic analysis The inhibitor thermostable stable broad pH range 2 11 No inhibition observed heavy metal ion many reagent 102 M except pchloromercuribenzoate caused 69 loss activity The inhibitor subjected isoelectric focusing pH 751 molecular weight calculated 14200900 polyacrylamide gel electrophoresis presence sodium dodecyl sulfate The apparent dissociation constant complex inhibitor trypsinEC 34214 164 X 107M casein substrate One microgram purified inhibitor inhibited 15 mug pure trypsin hydrolysis alphaNbenzoylDLargininepnitroanilide By chemical modification arginyl residue inhibitor 12cyclohexanedione inhibitor shown arginine inhibitor The inhibitor contained relatively many basic amino acid half cystine compared Pirkka barley trypsin inhibitor'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# barley  \n",
    "test_txt_clean[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reconstitution ion transport respiratory control vesicle formed reduced coenzyme Qcytochrome c reductase phospholipid Reduced coenzyme Qcytochrome c reductase bovine heart mitochondrion complex III incorporated phospholipid vesicle cholate dialysis procedure Soybean phospholipid mixture purified phosphatidylcholine phosphatidylethanolamine cardiolipin could used Oxidation reduced coenzyme Q2 reconstituted vesicle cytochrome c oxidant showed following energycoupling phenomenon 1 Protons translocated outward coupling ratio H2e 19 02 Measurements mitochondrion similar condition showed H2e ratio 18 Proton translocation seen presence uncoupling agent addition net acidification medium overall oxidation reaction 2 Potassium ion taken reconstituted vesicle presence valinomycin reaction coupled electron transfer The coupling ratio K uptake K2e 20 vesicle approximately 15 mitochondrion 3 The rate oxidation reduced coenzyme Q2 reconstituted vesicle stimulated 10fold uncouplers valinomycin plus nigericin K ion Addition valinomycin alone K medium caused transient stimulation electron transfer The result indicate energy coupling observed isolated reduced coenzyme Qcytochrome c reductase enzyme complex properly incorporated phospholipid vesicle'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soybean , Sesbania  \n",
    "test_txt_clean[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `get_match_csr` to get run time estimate\n",
    "\n",
    "https://stackoverflow.com/questions/28427236/set-row-of-csr-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lists of values, row_idx, and col idx, then create csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_csr_v1(txt):\n",
    "  row_idx   = []\n",
    "  col_idx   = []\n",
    "  csr_val   = []\n",
    "  for row, doc in enumerate(tqdm(txt)):\n",
    "    # Get the matching common names as a list\n",
    "    results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "    # Add the results to doc\n",
    "    for cname in results_usda:  # for each common name\n",
    "      genus = cnames[cname][0]  # get the genus name\n",
    "      doc += f\" {genus}\"        # add the genus name to doc\n",
    "    \n",
    "    # Match to NCBI names\n",
    "    results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "    # Assign row_idx, col_idx, and values for non-zero results_ncbi\n",
    "    non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    row_idx.extend([row]*len(non0_idx))\n",
    "    col_idx.extend(non0_idx)\n",
    "    csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "  # create a sparse matrix with shape=(num_docs, num_names)\n",
    "  match_csr = csr_matrix((csr_val, (row_idx, col_idx)),\n",
    "                         shape=(corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  return match_csr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.452066421508789\n"
     ]
    }
   ],
   "source": [
    "test100 = corpus['txt_clean'][:100]\n",
    "t = time()\n",
    "test100_csr1 = get_match_csr_v1(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create empty match_csr first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty match_csr, then create a tmp_csr with row_idx, col_idx, values,\n",
    "# then add match_csr with the tmp_csr\n",
    "def get_match_csr_v2(txt):\n",
    "\n",
    "  # create an empty sparse matrix with shape=(num_docs, num_names)\n",
    "  match_csr = csr_matrix((corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  for row, doc in enumerate(tqdm(txt)):\n",
    "    # Get the matching common names as a list\n",
    "    results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "    # Add the results to doc\n",
    "    for cname in results_usda:  # for each common name\n",
    "      genus = cnames[cname][0]  # get the genus name\n",
    "      doc += f\" {genus}\"        # add the genus name to doc\n",
    "    \n",
    "    # Match to NCBI names\n",
    "    results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "    # Assign row_idx, col_idx, and values for non-zero results_ncbi\n",
    "    non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    row_idx  = [row]*len(non0_idx)\n",
    "    col_idx  = non0_idx\n",
    "    csr_val  = [1]*len(non0_idx)\n",
    "\n",
    "    # Create a tmp csr to hold this row\n",
    "    tmp_csr = csr_matrix((csr_val, (row_idx, col_idx)),\n",
    "                         shape=(corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "    # Update match_csr by adding tmp_csr to it\n",
    "    match_csr = match_csr + tmp_csr\n",
    "\n",
    "  return match_csr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.682857036590576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test100_csr_v2 = get_match_csr_v2(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign a list to a row in match_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_csr_v3(txt):\n",
    "\n",
    "  # create an empty sparse matrix with shape=(num_docs, num_names)\n",
    "  match_csr = csr_matrix((corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  row_idx   = []\n",
    "  col_idx   = []\n",
    "  csr_val   = []\n",
    "  for row, doc in enumerate(tqdm(txt)):\n",
    "    # Get the matching common names as a list\n",
    "    results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "    # Add the results to doc\n",
    "    for cname in results_usda:  # for each common name\n",
    "      genus = cnames[cname][0]  # get the genus name\n",
    "      doc += f\" {genus}\"        # add the genus name to doc\n",
    "    \n",
    "    # Match to NCBI names\n",
    "    results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "    # Assign row_idx, col_idx, and values for non-zero results_ncbi\n",
    "    #non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    #row_idx.extend([row]*len(non0_idx))\n",
    "    #col_idx.extend(non0_idx)\n",
    "    #csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "    # Assign new row values to match_csr\n",
    "    match_csr[row, :] = results_ncbi\n",
    "\n",
    "  return match_csr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/shius/miniconda3/envs/nlp/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.317140579223633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test100_csr_v3 = get_match_csr_v3(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate lil matrix instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to v3, but use lil matrix instead, tried coo also, but does not work\n",
    "def get_match_lil_v4(txt):\n",
    "\n",
    "  # create an empty sparse matrix with shape=(num_docs, num_names)\n",
    "  # instead of csr, use lil\n",
    "  match_lil = lil_matrix((corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  #row_idx   = []\n",
    "  #col_idx   = []\n",
    "  #csr_val   = []\n",
    "  for row, doc in enumerate(tqdm(txt)):\n",
    "    # Get the matching common names as a list\n",
    "    results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "    # Add the results to doc\n",
    "    for cname in results_usda:  # for each common name\n",
    "      genus = cnames[cname][0]  # get the genus name\n",
    "      doc += f\" {genus}\"        # add the genus name to doc\n",
    "    \n",
    "    # Match to NCBI names\n",
    "    results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "    # Assign row_idx, col_idx, and values for non-zero results_ncbi\n",
    "    #non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    #row_idx.extend([row]*len(non0_idx))\n",
    "    #col_idx.extend(non0_idx)\n",
    "    #csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "    # Assign new row values to match_csr\n",
    "    match_lil[row, :] = np.asarray(results_ncbi)\n",
    "\n",
    "  return match_lil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.567139387130737\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test100_lil_v4 = get_match_lil_v4(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_dok_v5(txt):\n",
    "\n",
    "  # create an empty sparse matrix with shape=(num_docs, num_names)\n",
    "  # instead of csr, use lil\n",
    "  match_dok = dok_matrix((corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  row_idx   = []\n",
    "  col_idx   = []\n",
    "  csr_val   = []\n",
    "  for row, doc in enumerate(tqdm(txt)):\n",
    "    # Get the matching common names as a list\n",
    "    results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "    # Add the results to doc\n",
    "    for cname in results_usda:  # for each common name\n",
    "      genus = cnames[cname][0]  # get the genus name\n",
    "      doc += f\" {genus}\"        # add the genus name to doc\n",
    "    \n",
    "    # Match to NCBI names\n",
    "    results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "    # Assign row_idx, col_idx, and values for non-zero results_ncbi\n",
    "    #non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    #row_idx.extend([row]*len(non0_idx))\n",
    "    #col_idx.extend(non0_idx)\n",
    "    #csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "    # Assign new row values to match_csr\n",
    "    match_dok[row, :] = results_ncbi\n",
    "\n",
    "  return match_dok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7292234897613525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test100_dok_v5 = get_match_dok_v5(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ordered dictionary comprehension\n",
    "\n",
    "This is extremely slow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pythonpool.com/python-ordereddict/\n",
    "def get_match_csr_v6(txt):\n",
    "  row_idx   = []\n",
    "  col_idx   = []\n",
    "  csr_val   = []\n",
    "  for row, doc in enumerate(tqdm(txt)):\n",
    "    # Get the matching common names as an ordered dict\n",
    "    results_usda = OrderedDict((name, 1) if(f\" {name} \" in doc) else (name, 0) \n",
    "                               for name in common_names)\n",
    "\n",
    "    # Add the results to doc\n",
    "    for cname in results_usda:  # for each common name\n",
    "      genus = cnames[cname][0]  # get the genus name\n",
    "      doc += f\" {genus}\"        # add the genus name to doc\n",
    "    \n",
    "    # Match to NCBI names as an ordered dict\n",
    "    results_ncbi = OrderedDict((name, 1) if(name in doc) else (name, 0) \n",
    "                               for name in offspring_names)\n",
    "\n",
    "    # Assign row_idx, col_idx, and values for non-zero results_ncbi\n",
    "    non0_idx = np.nonzero(results_ncbi.values())[0].tolist()\n",
    "    row_idx.extend([row]*len(non0_idx))\n",
    "    col_idx.extend(non0_idx)\n",
    "    csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "  # create a sparse matrix with shape=(num_docs, num_names)\n",
    "  match_csr = csr_matrix((csr_val, (row_idx, col_idx)),\n",
    "                         shape=(corpus.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  return match_csr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:15<08:31,  5.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb Cell 96\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m t \u001b[39m=\u001b[39m time()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test100_csr6 \u001b[39m=\u001b[39m get_match_csr_v6(test100)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(time()\u001b[39m-\u001b[39mt)\n",
      "\u001b[1;32m/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb Cell 96\u001b[0m in \u001b[0;36mget_match_csr_v6\u001b[0;34m(txt)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m   doc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mgenus\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m        \u001b[39m# add the genus name to doc\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Match to NCBI names as an ordered dict\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m results_ncbi \u001b[39m=\u001b[39m OrderedDict((name, \u001b[39m1\u001b[39;49m) \u001b[39mif\u001b[39;49;00m(name \u001b[39min\u001b[39;49;00m doc) \u001b[39melse\u001b[39;49;00m (name, \u001b[39m0\u001b[39;49m) \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                            \u001b[39mfor\u001b[39;49;00m name \u001b[39min\u001b[39;49;00m offspring_names)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Assign row_idx, col_idx, and values for non-zero results_ncbi\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m non0_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(results_ncbi\u001b[39m.\u001b[39mvalues())[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[1;32m/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb Cell 96\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m   doc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mgenus\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m        \u001b[39m# add the genus name to doc\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Match to NCBI names as an ordered dict\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m results_ncbi \u001b[39m=\u001b[39m OrderedDict((name, \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m(name \u001b[39min\u001b[39;00m doc) \u001b[39melse\u001b[39;00m (name, \u001b[39m0\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                            \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m offspring_names)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Assign row_idx, col_idx, and values for non-zero results_ncbi\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shius/github/plant_sci_hist/5_species_over_time/script_5_1_species_over_time.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m non0_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(results_ncbi\u001b[39m.\u001b[39mvalues())[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test100_csr6 = get_match_csr_v6(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try multiprocessing\n",
    "\n",
    "- https://superfastpython.com/multiprocessing-pool-for-loop/\n",
    "- https://stackoverflow.com/questions/42749772/multiprocessing-how-to-use-pool-map-on-a-list-and-function-with-arguments\n",
    "- https://python.omics.wiki/multiprocessing_map/multiprocessing_partial_function_multiple_arguments\n",
    "- https://stackoverflow.com/questions/41920124/multiprocessing-use-tqdm-to-display-a-progress-bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 12, 21, 6]\n"
     ]
    }
   ],
   "source": [
    "data_pairs = [ [3,5], [4,3], [7,3], [1,6] ]\n",
    "\n",
    "def myfunc(p):\n",
    "  product_of_list = np.prod(p)\n",
    "  return product_of_list\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "result_list = pool.map(myfunc, data_pairs)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(test100):\n",
    "  print(type(i))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_csr_v7(txt):\n",
    "\n",
    "  with multiprocessing.Pool(processes=15) as pool:\n",
    "    results_ncbi_list = list(tqdm(pool.imap(task, enumerate(txt)), \n",
    "                                  total=len(txt)))\n",
    "\n",
    "  row_idx   = []\n",
    "  col_idx   = []\n",
    "  csr_val   = []\n",
    "  for row, results_ncbi in enumerate(results_ncbi_list):\n",
    "    non0_idx = np.nonzero(results_ncbi)[0].tolist()\n",
    "    row_idx.extend([row]*len(non0_idx))\n",
    "    col_idx.extend(non0_idx)\n",
    "    csr_val.extend([1]*len(non0_idx))\n",
    "\n",
    "  # create a sparse matrix with shape=(num_docs, num_names)\n",
    "  match_csr = csr_matrix((csr_val, (row_idx, col_idx)),\n",
    "                         shape=(txt.shape[0], len(offspring_names)), \n",
    "                         dtype=np.int0)\n",
    "\n",
    "  return match_csr\n",
    "\n",
    "def task(item):\n",
    "  '''Task to parallelize\n",
    "  Args:\n",
    "    item (tuple): (row_number, doc)\n",
    "  Return:\n",
    "    results_ncbi (list): an offspring_name is present in the doc (1) or not(1)\n",
    "  '''\n",
    "  (row, doc) = item\n",
    "  # Get the matching common names as a list\n",
    "  results_usda = [name for name in common_names if(f\" {name} \" in doc)]\n",
    "\n",
    "  # Add the results to doc\n",
    "  for cname in results_usda:  # for each common name\n",
    "    genus = cnames[cname][0]  # get the genus name\n",
    "    doc += f\" {genus}\"        # add the genus name to doc\n",
    "  \n",
    "  # Match to NCBI names\n",
    "  results_ncbi = [1 if(name in doc) else 0 for name in offspring_names]\n",
    "\n",
    "  return results_ncbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 107.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6789848804473877\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test100_csr7 = get_match_csr_v7(test100)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 26782)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test100_csr7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cholinesterases plant tissue VI Preliminary characterization enzyme Solanum melongena L Zea may L Enzymes capable hydrolyzing ester thiocholine assayed extract Solanum melongena L eggplant Zea Mays L corn The enzyme specie inhibited anticholinesterase neostigmine physostigmine 284c51 AMO1618 plant growth retardant pH optimum near pH 80 The enzyme eggplant maximally active substrate concentration 015 mM acetylthiocholine inhibited higher substrate concentration On basis last property magnitude inhibition various inhibitor substrate specificity conclude enzyme eggplant corn cholinesterase'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test100[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16432, 4360)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offspring_names.index(\"Solanum\"), offspring_names.index(\"Zea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 0)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect to be 1, 1, 0\n",
    "test100_csr7[1, 16432], test100_csr7[1, 4360], test100_csr7[1, 16431]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fructose 16bisphosphate aldolase activity Rhizobium specie FDP aldolase found present cellfree extract Rhizobium leguminosarum Rhizobium phaseoli Rhizobium trifolii Rhizobium meliloti Rhizobium lupini Rhizobium japonicum Rhizobium specie Arachis hypogaea Sesbania cannabina The enzyme 3 representative specie optimal activity pH 84 02M veronal buffer The enzyme activity completely lost treatment 60 degree C 15 min The Km value range 238 455 X 106M FDP Metal chelating agent inhibited enzyme activity monovalent bivalent metal ion failed stimulate activity Bivalent metal ion general rather inhibitory'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test100[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21986, 21477)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offspring_names.index(\"Arachis\"), offspring_names.index(\"Sesbania\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test100_csr7[2, 21986], test100_csr7[2, 21477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9f976de49e978787b392bf076cac9dcd649ffc2d080fbba5564554c12476cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
