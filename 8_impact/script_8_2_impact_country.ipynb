{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __8.2 Considering country impact__\n",
    "\n",
    "Goal:\n",
    "- Access the impacts of pubs over time (1999-2020) for different:\n",
    "  - Topics in 8.1\n",
    "  - Countries\n",
    "\n",
    "Approach\n",
    "- The averged impact metric is calcualted for:\n",
    "  - Each year, combining all countries\n",
    "    - See `impact_overall.xlsx`\n",
    "  - Each year, each country\n",
    "    - See `impact_country.xlsx` for original values\n",
    "    - See `impact_country_MOD.xlsx` for values normalized in two schemes\n",
    "      - Against all country average each year\n",
    "      - Against top 10 country average each year \n",
    "\n",
    "Thoughts\n",
    "- In all metrics, GBR has consistently high impacts\n",
    "  - While, CHN and IND has lower than average impact throughout the years\n",
    "    - Nonetheless, the impact in all every areas are approching global average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Setup___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import\n",
    "\n",
    "In conda env `base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from urllib import request\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting working directory\n",
    "proj_dir   = Path.home() / \"projects/plant_sci_hist\"\n",
    "parent_dir = proj_dir / \"8_impact\"\n",
    "work_dir   = parent_dir / \"8_2_country\"\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# plant science corpus with topic assignment info\n",
    "dir42      = proj_dir / \"4_topic_model/4_2_outlier_assign\"\n",
    "corpus_file = dir42 / \"table4_2_corpus_with_topic_assignment.tsv.gz\"\n",
    "#corpus_file = dir42 / \"test.tsv\"\n",
    "\n",
    "# country info, pmid, ...\n",
    "dir75            = proj_dir / \"7_countries/7_5_country_over_time\"\n",
    "ci_file          = dir75 / 'ci_pmid_topic.tsv'\n",
    "c_npub_file      = dir75 / 'country_npub_raw.csv'\n",
    "\n",
    "# SJR and pdjity (pmid, date, journal, issn, topic, year)\n",
    "pdjity_file      = parent_dir / \"8_1_topic/table_pdjity.tsv\"\n",
    "file_d_d_metric  = parent_dir / '8_1_topic/sjr_metric_dicts.pkl'\n",
    "\n",
    "# So PDF is saved in a format properly\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Country, ISSN, and SJR metric data___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read country, pmid, topic dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330328, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with A3, confidence, date, topic, year\n",
    "df_acdty = pd.read_csv(ci_file, sep='\\t', index_col=0)\n",
    "df_acdty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400957</th>\n",
       "      <td>CAN</td>\n",
       "      <td>3</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>50</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279107</th>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-11-01</td>\n",
       "      <td>12</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A3  Confidence        Date  Topic  Year\n",
       "PMID                                             \n",
       "400957   CAN           3  1978-01-01     50  1978\n",
       "1279107  FRA           3  1992-11-01     12  1992"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acdty.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read country count to get ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>n_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHN</td>\n",
       "      <td>60298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>59503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  n_pub\n",
       "0     CHN  60298\n",
       "1     USA  59503"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_npub = pd.read_csv(c_npub_file)\n",
    "df_npub.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read pdjity table\n",
    "\n",
    "pmid, date, journal, issn, topic, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421307, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdjity = pd.read_csv(pdjity_file, sep='\\t', index_col=0)\n",
    "df_pdjity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1975-12-11</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>00063002,18782434</td>\n",
       "      <td>52</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1975-11-20</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>00063002,18782434</td>\n",
       "      <td>48</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                        Journal               ISSN  Topic  \\\n",
       "PMID                                                                        \n",
       "61    1975-12-11  Biochimica et biophysica acta  00063002,18782434     52   \n",
       "67    1975-11-20  Biochimica et biophysica acta  00063002,18782434     48   \n",
       "\n",
       "      Year  \n",
       "PMID        \n",
       "61    1975  \n",
       "67    1975  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdjity.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ISSN to df_acdty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330328,\n",
       " [400957, 1279107, 1279650, 1280064, 1280162],\n",
       " [11277426, 28674549, 29736697, 28307190, 17175550])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmid_acdty = list(df_acdty.index)\n",
    "len(pmid_acdty), pmid_acdty[:5], pmid_acdty[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330328,\n",
       " PMID\n",
       " 400957              03050491\n",
       " 1279107    00221317,14652099\n",
       " 1279650    07248741,1573904X\n",
       " 1280064    00039861,10960384\n",
       " 1280162    00063002,18782434\n",
       " Name: ISSN, dtype: object,\n",
       " PMID\n",
       " 11277426             08940282\n",
       " 28674549             1664462X\n",
       " 29736697    13403443,18610293\n",
       " 28307190    00298549,14321939\n",
       " 17175550    00220957,14602431\n",
       " Name: ISSN, dtype: object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issns = df_pdjity.loc[pmid_acdty]['ISSN']\n",
    "\n",
    "# Spot check\n",
    "len(issns.values), issns.iloc[:5], issns.iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "      <th>ISSN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400957</th>\n",
       "      <td>CAN</td>\n",
       "      <td>3</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>50</td>\n",
       "      <td>1978</td>\n",
       "      <td>03050491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279107</th>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-11-01</td>\n",
       "      <td>12</td>\n",
       "      <td>1992</td>\n",
       "      <td>00221317,14652099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A3  Confidence        Date  Topic  Year               ISSN\n",
       "PMID                                                                \n",
       "400957   CAN           3  1978-01-01     50  1978           03050491\n",
       "1279107  FRA           3  1992-11-01     12  1992  00221317,14652099"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add issns to df_acdty\n",
    "df_acdty['ISSN'] = issns\n",
    "df_acdty.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SJR metric dictionary\n",
    "\n",
    "A dictionary with year as key, a dictionary as value\n",
    "- d_d_metric = {year:{ISSN:[4 metrics], ...}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_d_d_metric, 'rb') as f:\n",
    "    d_d_metric = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_d_metric.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Country impact___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting list of impact values\n",
    "\n",
    "Modified from 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In 8.1, originally the whole thing is embeded in get_lst_lst. Separate these \n",
    "# to make it more readable.\n",
    "def get_m_list(pmid, issn, d_metric):\n",
    "  \n",
    "  # first check if issn is np.nan\n",
    "  if type(issn) == float:\n",
    "    if not np.isnan(issn):\n",
    "      print(\"ERR: float but not nan\", issn)\n",
    "    issn = []\n",
    "  else:\n",
    "    issn = issn.split(\",\")\n",
    "\n",
    "  # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "  m_list = []\n",
    "  for issn_token in issn:\n",
    "    if issn_token in d_metric:\n",
    "      metrics = d_metric[issn_token]\n",
    "      m_list.append(metrics)\n",
    "\n",
    "  # check if this journal is found in d_meric\n",
    "  m_list2 = []\n",
    "  if m_list != []:\n",
    "    # get average if multiple issns\n",
    "    for idx in range(0,4):\n",
    "      m_sum = 0\n",
    "      for ms in m_list:\n",
    "        m_sum += ms[idx]\n",
    "      m_avg = m_sum / len(m_list)\n",
    "      m_list2.append(m_avg)\n",
    "\n",
    "  return m_list, m_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m_lst_lst(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code, if \"\", then all countries\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "  '''\n",
    "  \n",
    "  # Get sub-dataframe\n",
    "  if a3 == \"\":\n",
    "    df = df_acdty.loc[df_acdty['Year']==yr]\n",
    "  else:\n",
    "    df = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "\n",
    "  # pmid and issns\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid = pmids[idx]\n",
    "\n",
    "    m_list, m_list2 = get_m_list(pmid, issn, d_metric)\n",
    "\n",
    "    if m_list != []:\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through each country and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>n_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHN</td>\n",
       "      <td>60298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>59503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  n_pub\n",
       "0     CHN  60298\n",
       "1     USA  59503"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_npub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CHN', 'USA', 'JPN', 'DEU', 'FRA'], dtype=object),\n",
       " array(['TZA', 'CAF', 'SLV', 'IRN', 'TCD'], dtype=object))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get country list\n",
    "c_list = df_npub.country.values\n",
    "c_list[:5], c_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/165 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [01:02<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "c_y_avg = {} # {country: {year: [Prank, SJR, Hidx, Cite]}}\n",
    "yr_range = range(1999, 2021)\n",
    "\n",
    "# For each topic\n",
    "for a3 in tqdm(c_list):\n",
    "  c_y_avg[a3] = {}\n",
    "\n",
    "  # For each year\n",
    "  for yr in yr_range:\n",
    "    # [[prank, sjr, hidx, cite]] for all records in a given topic-year\n",
    "    m_lst_lst = get_m_lst_lst(a3, yr) \n",
    "    #print(len(m_lst_lst))\n",
    "    \n",
    "    # compile metrics into a 2d array\n",
    "    m_2d = []\n",
    "    for m_list in m_lst_lst:\n",
    "      m_2d.append(m_list[2])\n",
    "    m_2d  = np.array(m_2d)\n",
    "    # determine n_pub for each metric after removing NA\n",
    "    n_pub = np.subtract([m_2d.shape[0]]*4, sum(np.isnan(m_2d)))\n",
    "    \n",
    "    # For a few cases without publication, set to NaN\n",
    "    if 0 in n_pub:\n",
    "      c_y_avg[a3][yr] = [np.nan]*4\n",
    "    else:\n",
    "      # calculate average and store in dict\n",
    "      # Issue: RuntimeWarning: invalid value encountered in true_divide\n",
    "      # https://www.geeksforgeeks.org/how-to-fix-invalid-value-encountered-in-true_divide/\n",
    "      m_sum = np.nansum(m_2d, axis=0)\n",
    "      m_avg = np.divide(m_sum, n_pub)\n",
    "      c_y_avg[a3][yr] = m_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.79310982,   1.60306774, 177.93186373,   4.74823425]),\n",
       " array([  0.84167973,   2.20986465, 207.40929878,   5.10214558]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_y_avg['CHN'][2020], c_y_avg['USA'][2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate output\n",
    "\n",
    "Sorted according to:\n",
    "- df_npub: country - number of pubs (use c_list, already sorted)\n",
    "- Decide not to do normalization per country. The point is between country comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prank (165, 22)\n",
      "sjr (165, 22)\n",
      "hidx (165, 22)\n",
      "cite (165, 22)\n"
     ]
    }
   ],
   "source": [
    "excel_file    = work_dir / 'impact_country.xlsx'\n",
    "excel_writer  = pd.ExcelWriter(excel_file, engine='xlsxwriter')\n",
    "\n",
    "metric_names = ['prank', 'sjr', 'hidx', 'cite']\n",
    "c_order      = df_npub['country'].values\n",
    "for metric_idx in range(4):\n",
    "  metric_nm      = metric_names[metric_idx]\n",
    "  metric_2d      = [] # a 2D list: a3, then year\n",
    "  metric_2d_norm = [] # a 2D list: a3, then year, normalized for each a3\n",
    "  for a3 in c_list:\n",
    "    metric_a3 = []\n",
    "    for yr in yr_range:\n",
    "      metric_a3.append(c_y_avg[a3][yr][metric_idx])\n",
    "    metric_2d.append(metric_a3)\n",
    "\n",
    "    # do min-max normalization\n",
    "    #m_min = min(metric_a3)\n",
    "    #m_max = max(metric_a3)\n",
    "    #metric_a3_norm = [(m-m_min)/(m_max-m_min) for m in metric_a3]\n",
    "    #metric_2d_norm.append(metric_a3_norm)\n",
    "  \n",
    "  df_metric  = pd.DataFrame(metric_2d, index=c_list, columns=yr_range)\n",
    "  #df_metric2 = pd.DataFrame(metric_2d_norm, index=c_list, columns=yr_range)\n",
    "\n",
    "  # sort by the order of the number of publications\n",
    "  df_metric  = df_metric.reindex(c_order)\n",
    "  #df_metric2 = df_metric2.reindex(c_order)\n",
    "\n",
    "  print(metric_nm, df_metric.shape)\n",
    "  \n",
    "  df_metric.to_excel(excel_writer, sheet_name=metric_nm)\n",
    "  #df_metric2.to_excel(excel_writer, sheet_name=metric_nm+\"_norm\")\n",
    "\n",
    "excel_writer.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Overall impact___\n",
    "\n",
    "Realize that I should also calculate the impact per year over all countries to potentially use them as normalizing factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get yearly average impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:03<00:00,  6.81it/s]\n"
     ]
    }
   ],
   "source": [
    "y_avg = {} # {year: [Prank, SJR, Hidx, Cite]}\n",
    "\n",
    "# For each year\n",
    "for yr in tqdm(yr_range):\n",
    "  # [[prank, sjr, hidx, cite]] for all records in a given topic-year\n",
    "  m_lst_lst = get_m_lst_lst(\"\", yr) \n",
    "  #print(len(m_lst_lst))\n",
    "  \n",
    "  # compile metrics into a 2d array\n",
    "  m_2d = []\n",
    "  for m_list in m_lst_lst:\n",
    "    # m_list2 is in index=2\n",
    "    m_2d.append(m_list[2])\n",
    "\n",
    "  m_2d  = np.array(m_2d)\n",
    "  \n",
    "  # determine n_pub for each metric after removing NA\n",
    "  n_pub = np.subtract([m_2d.shape[0]]*4, sum(np.isnan(m_2d)))\n",
    "  \n",
    "  # For a few cases without publication, set to NaN\n",
    "  if 0 in n_pub:\n",
    "    y_avg[yr] = [np.nan]*4\n",
    "  else:\n",
    "    # calculate average and store in dict\n",
    "    # Issue: RuntimeWarning: invalid value encountered in true_divide\n",
    "    # https://www.geeksforgeeks.org/how-to-fix-invalid-value-encountered-in-true_divide/\n",
    "    m_sum = np.nansum(m_2d, axis=0)\n",
    "    m_avg = np.divide(m_sum, n_pub)\n",
    "    y_avg[yr] = m_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file2    = work_dir / 'impact_all_country_per_year.xlsx'\n",
    "excel_writer2  = pd.ExcelWriter(excel_file2, engine='xlsxwriter')\n",
    "\n",
    "metric_names = ['prank', 'sjr', 'hidx', 'cite']\n",
    "metric_2d    = [] # a 2D list: year, then metrics\n",
    "for yr in yr_range:\n",
    "  metric_2d.append(y_avg[yr])\n",
    "\n",
    "df_metric = pd.DataFrame(metric_2d, index=yr_range, columns=metric_names)\n",
    "df_metric.to_excel(excel_writer2, sheet_name=\"yearly overall\")\n",
    "\n",
    "excel_writer2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Additional analyses___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get average rank\n",
    "\n",
    "From prank, sjr, hindex, and cites/doc normalized values, they are sorted based on % missing values (<10%), num of pubs (>400), then a specific metric. The results are stored in the `summary` sheet in `impact_country_MOD.xlsx`.\n",
    "\n",
    "Get the averge rank for each country in the summary table.\n",
    "- [look up sheet names](https://stackoverflow.com/questions/17977540/pandas-looking-up-the-list-of-sheets-in-an-excel-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top</th>\n",
       "      <th>J-rank</th>\n",
       "      <th>SJR</th>\n",
       "      <th>H-idx</th>\n",
       "      <th>Cites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GBR</td>\n",
       "      <td>GBR</td>\n",
       "      <td>GBR</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Top J-rank  SJR H-idx Cites\n",
       "0    1    CHE  CHE   CHE   CHE\n",
       "1    2    GBR  GBR   GBR   GBR"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_xlsx = work_dir / \"impact_country_MOD.xlsx\"\n",
    "df = pd.read_excel(file_xlsx, sheet_name=\"summary\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/pandas-find-unique-values-from-multiple-columns/\n",
    "\n",
    "# len=47, so this is not needed as all columns have the same countries\n",
    "len(pd.concat([df['J-rank'],df['SJR'],df['H-idx'],df['Cites']]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"J-rank\"] == 'CHE']['Top'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHE': [1, 1, 1, 1],\n",
       " 'GBR': [2, 2, 2, 2],\n",
       " 'NLD': [3, 4, 5, 3],\n",
       " 'USA': [4, 3, 3, 4],\n",
       " 'SWE': [5, 9, 6, 9],\n",
       " 'FRA': [6, 6, 8, 7],\n",
       " 'ISR': [7, 7, 9, 6],\n",
       " 'DEU': [8, 5, 4, 5],\n",
       " 'AUS': [9, 13, 11, 12],\n",
       " 'DNK': [10, 12, 7, 11],\n",
       " 'FIN': [11, 15, 13, 16],\n",
       " 'IRL': [12, 16, 12, 14],\n",
       " 'CAN': [13, 14, 16, 15],\n",
       " 'AUT': [14, 11, 17, 13],\n",
       " 'NOR': [15, 17, 14, 17],\n",
       " 'BEL': [16, 10, 10, 8],\n",
       " 'SGP': [17, 8, 15, 10],\n",
       " 'ESP': [18, 19, 18, 18],\n",
       " 'NZL': [19, 20, 21, 20],\n",
       " 'TWN': [20, 21, 19, 21],\n",
       " 'ITA': [21, 23, 23, 22],\n",
       " 'JPN': [22, 18, 20, 19],\n",
       " 'CZE': [23, 22, 25, 23],\n",
       " 'PRT': [24, 24, 22, 24],\n",
       " 'SVN': [25, 32, 24, 30],\n",
       " 'ZAF': [26, 29, 30, 31],\n",
       " 'PHL': [27, 25, 32, 28],\n",
       " 'GRC': [28, 31, 29, 29],\n",
       " 'MEX': [29, 28, 27, 26],\n",
       " 'ARG': [30, 26, 26, 25],\n",
       " 'CHL': [31, 30, 28, 32],\n",
       " 'COL': [32, 34, 35, 35],\n",
       " 'BRA': [33, 35, 33, 34],\n",
       " 'HUN': [34, 27, 31, 27],\n",
       " 'THA': [35, 38, 38, 39],\n",
       " 'SVK': [36, 39, 41, 38],\n",
       " 'POL': [37, 36, 36, 36],\n",
       " 'TUN': [38, 42, 40, 40],\n",
       " 'IND': [39, 37, 37, 37],\n",
       " 'CHN': [40, 33, 34, 33],\n",
       " 'MYS': [41, 40, 39, 41],\n",
       " 'TUR': [42, 44, 43, 45],\n",
       " 'PAK': [43, 45, 44, 44],\n",
       " 'RUS': [44, 43, 45, 43],\n",
       " 'SAU': [45, 41, 42, 42],\n",
       " 'NGA': [46, 46, 46, 47],\n",
       " 'EGY': [47, 47, 47, 46]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_list = df['J-rank'].unique()\n",
    "c_dict = {} # {country: [rank_metric1, ....]}\n",
    "m_list = df.columns[1:]\n",
    "\n",
    "# for each country\n",
    "for c in c_list:\n",
    "  # for each metric\n",
    "  c_dict[c] = []\n",
    "  for m in m_list:\n",
    "    v = df[df[m] == c]['Top'].values[0]\n",
    "    c_dict[c].append(v)\n",
    "c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output\n",
    "file_c_avg_rank = work_dir / \"country_avg_rank.csv\"\n",
    "\n",
    "with open(file_c_avg_rank, 'w') as f:\n",
    "  f.write('country,J-rank,SJR,H-idx,Cites,Avg_rank\\n')\n",
    "\n",
    "  for c in c_list:\n",
    "    n_pub = df_npub[df_npub['country'] == c]['n_pub'].values[0]\n",
    "    ranks = \",\".join([str(r) for r in c_dict[c]])\n",
    "    f.write(f'{c},{ranks},{np.average(c_dict[c])}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Test___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced\n",
    "def get_m_lst_lst_v1(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "    not_found (dict): {journal: [issn, [pmids]]}\n",
    "  '''\n",
    "  \n",
    "  df        = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  \n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "  #not_found = {}             # {journal: [issn, [pmids]}\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid    = pmids[idx]\n",
    "\n",
    "    # first check if issn is np.nan\n",
    "    if type(issn) == float:\n",
    "      if not np.isnan(issn):\n",
    "        print(\"ERR: float but not nan\", issn)\n",
    "      issn = []\n",
    "    else:\n",
    "      issn = issn.split(\",\")\n",
    "\n",
    "    # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "    m_list = []\n",
    "    for issn_token in issn:\n",
    "      if issn_token in d_metric:\n",
    "        metrics = d_metric[issn_token]\n",
    "        m_list.append(metrics)\n",
    "\n",
    "    # check if this journal is found in d_meric\n",
    "    m_list2 = [] # for getting average if multiple issns\n",
    "    if m_list != []:\n",
    "      for idx in range(0,4):\n",
    "        m_sum = 0\n",
    "        for ms in m_list:\n",
    "          m_sum += ms[idx]\n",
    "        m_avg = m_sum / len(m_list)\n",
    "        m_list2.append(m_avg)\n",
    "\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced\n",
    "def get_m_lst_lst_v1(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "    not_found (dict): {journal: [issn, [pmids]]}\n",
    "  '''\n",
    "  \n",
    "  df        = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  \n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "  #not_found = {}             # {journal: [issn, [pmids]}\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid    = pmids[idx]\n",
    "\n",
    "    # first check if issn is np.nan\n",
    "    if type(issn) == float:\n",
    "      if not np.isnan(issn):\n",
    "        print(\"ERR: float but not nan\", issn)\n",
    "      issn = []\n",
    "    else:\n",
    "      issn = issn.split(\",\")\n",
    "\n",
    "    # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "    m_list = []\n",
    "    for issn_token in issn:\n",
    "      if issn_token in d_metric:\n",
    "        metrics = d_metric[issn_token]\n",
    "        m_list.append(metrics)\n",
    "\n",
    "    # check if this journal is found in d_meric\n",
    "    m_list2 = [] # for getting average if multiple issns\n",
    "    if m_list != []:\n",
    "      for idx in range(0,4):\n",
    "        m_sum = 0\n",
    "        for ms in m_list:\n",
    "          m_sum += ms[idx]\n",
    "        m_avg = m_sum / len(m_list)\n",
    "        m_list2.append(m_avg)\n",
    "\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced\n",
    "def get_m_lst_lst_v1(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "    not_found (dict): {journal: [issn, [pmids]]}\n",
    "  '''\n",
    "  \n",
    "  df        = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  \n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "  #not_found = {}             # {journal: [issn, [pmids]}\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid    = pmids[idx]\n",
    "\n",
    "    # first check if issn is np.nan\n",
    "    if type(issn) == float:\n",
    "      if not np.isnan(issn):\n",
    "        print(\"ERR: float but not nan\", issn)\n",
    "      issn = []\n",
    "    else:\n",
    "      issn = issn.split(\",\")\n",
    "\n",
    "    # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "    m_list = []\n",
    "    for issn_token in issn:\n",
    "      if issn_token in d_metric:\n",
    "        metrics = d_metric[issn_token]\n",
    "        m_list.append(metrics)\n",
    "\n",
    "    # check if this journal is found in d_meric\n",
    "    m_list2 = [] # for getting average if multiple issns\n",
    "    if m_list != []:\n",
    "      for idx in range(0,4):\n",
    "        m_sum = 0\n",
    "        for ms in m_list:\n",
    "          m_sum += ms[idx]\n",
    "        m_avg = m_sum / len(m_list)\n",
    "        m_list2.append(m_avg)\n",
    "\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
