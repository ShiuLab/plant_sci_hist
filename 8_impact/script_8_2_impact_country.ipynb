{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __8.2 Considering country impact__\n",
    "\n",
    "Goal:\n",
    "- Access the impacts of pubs over time (1999-2020) for different:\n",
    "  - Topics in 8.1\n",
    "  - Countries\n",
    "\n",
    "Approach\n",
    "- The averged impact metric is calcualted for:\n",
    "  - Each year, combining all countries\n",
    "    - See `impact_overall.xlsx`\n",
    "  - Each year, each country\n",
    "    - See `impact_country.xlsx` for original values\n",
    "    - See `impact_country_MOD.xlsx` for values normalized in two schemes\n",
    "      - Against all country average each year\n",
    "      - Against top 10 country average each year \n",
    "\n",
    "Thoughts\n",
    "- In all metrics, GBR has consistently high impacts\n",
    "  - While, CHN and IND has lower than average impact throughout the years\n",
    "    - Nonetheless, the impact in all every areas are approching global average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Setup___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import\n",
    "\n",
    "In conda env `base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import kstest, pearsonr, spearmanr\n",
    "from math import log10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 20220609\n",
    "\n",
    "# Setting working directory\n",
    "proj_dir   = Path.home() / \"projects/plant_sci_hist\"\n",
    "parent_dir = proj_dir / \"8_impact\"\n",
    "work_dir   = parent_dir / \"8_2_country\"\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# plant science corpus with topic assignment info\n",
    "dir42      = proj_dir / \"4_topic_model/4_2_outlier_assign\"\n",
    "corpus_file = dir42 / \"table4_2_corpus_with_topic_assignment.tsv.gz\"\n",
    "#corpus_file = dir42 / \"test.tsv\"\n",
    "\n",
    "# country info, pmid, ...\n",
    "dir75             = proj_dir / \"7_countries/7_5_country_over_time\"\n",
    "ci_file           = dir75 / 'ci_pmid_topic.tsv'\n",
    "c_npub_file       = dir75 / 'country_npub_raw.csv'\n",
    "t25_toc_stat_file = dir75 / \"country_top25_toc_stat.csv\"\n",
    "\n",
    "# SJR and pdjity (pmid, date, journal, issn, topic, year)\n",
    "pdjity_file      = parent_dir / \"8_1_topic/table_pdjity.tsv\"\n",
    "file_d_d_metric  = parent_dir / '8_1_topic/sjr_metric_dicts.pkl'\n",
    "\n",
    "# So PDF is saved in a format properly\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Country, ISSN, and SJR metric data___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read country, pmid, topic dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330328, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with A3, confidence, date, topic, year\n",
    "df_acdty = pd.read_csv(ci_file, sep='\\t', index_col=0)\n",
    "df_acdty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400957</th>\n",
       "      <td>CAN</td>\n",
       "      <td>3</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>50</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279107</th>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-11-01</td>\n",
       "      <td>12</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A3  Confidence        Date  Topic  Year\n",
       "PMID                                             \n",
       "400957   CAN           3  1978-01-01     50  1978\n",
       "1279107  FRA           3  1992-11-01     12  1992"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acdty.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read country count to get ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>n_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHN</td>\n",
       "      <td>60298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>59503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  n_pub\n",
       "0     CHN  60298\n",
       "1     USA  59503"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_npub = pd.read_csv(c_npub_file)\n",
    "df_npub.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read pdjity table\n",
    "\n",
    "pmid, date, journal, issn, topic, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421307, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdjity = pd.read_csv(pdjity_file, sep='\\t', index_col=0)\n",
    "df_pdjity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1975-12-11</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>00063002,18782434</td>\n",
       "      <td>52</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1975-11-20</td>\n",
       "      <td>Biochimica et biophysica acta</td>\n",
       "      <td>00063002,18782434</td>\n",
       "      <td>48</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                        Journal               ISSN  Topic  \\\n",
       "PMID                                                                        \n",
       "61    1975-12-11  Biochimica et biophysica acta  00063002,18782434     52   \n",
       "67    1975-11-20  Biochimica et biophysica acta  00063002,18782434     48   \n",
       "\n",
       "      Year  \n",
       "PMID        \n",
       "61    1975  \n",
       "67    1975  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdjity.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ISSN to df_acdty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330328,\n",
       " [400957, 1279107, 1279650, 1280064, 1280162],\n",
       " [11277426, 28674549, 29736697, 28307190, 17175550])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmid_acdty = list(df_acdty.index)\n",
    "len(pmid_acdty), pmid_acdty[:5], pmid_acdty[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330328,\n",
       " PMID\n",
       " 400957              03050491\n",
       " 1279107    00221317,14652099\n",
       " 1279650    07248741,1573904X\n",
       " 1280064    00039861,10960384\n",
       " 1280162    00063002,18782434\n",
       " Name: ISSN, dtype: object,\n",
       " PMID\n",
       " 11277426             08940282\n",
       " 28674549             1664462X\n",
       " 29736697    13403443,18610293\n",
       " 28307190    00298549,14321939\n",
       " 17175550    00220957,14602431\n",
       " Name: ISSN, dtype: object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issns = df_pdjity.loc[pmid_acdty]['ISSN']\n",
    "\n",
    "# Spot check\n",
    "len(issns.values), issns.iloc[:5], issns.iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "      <th>ISSN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400957</th>\n",
       "      <td>CAN</td>\n",
       "      <td>3</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>50</td>\n",
       "      <td>1978</td>\n",
       "      <td>03050491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279107</th>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-11-01</td>\n",
       "      <td>12</td>\n",
       "      <td>1992</td>\n",
       "      <td>00221317,14652099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A3  Confidence        Date  Topic  Year               ISSN\n",
       "PMID                                                                \n",
       "400957   CAN           3  1978-01-01     50  1978           03050491\n",
       "1279107  FRA           3  1992-11-01     12  1992  00221317,14652099"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add issns to df_acdty\n",
    "df_acdty['ISSN'] = issns\n",
    "df_acdty.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SJR metric dictionary\n",
    "\n",
    "A dictionary with year as key, a dictionary as value\n",
    "- d_d_metric = {year:{ISSN:[4 metrics], ...}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_d_d_metric, 'rb') as f:\n",
    "    d_d_metric = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_d_metric.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Country impact___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting list of impact values\n",
    "\n",
    "Modified from 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In 8.1, originally the whole thing is embeded in get_lst_lst. Separate these \n",
    "# to make it more readable.\n",
    "def get_m_list(pmid, issn, d_metric):\n",
    "  \n",
    "  # first check if issn is np.nan\n",
    "  if type(issn) == float:\n",
    "    if not np.isnan(issn):\n",
    "      print(\"ERR: float but not nan\", issn)\n",
    "    issn = []\n",
    "  else:\n",
    "    issn = issn.split(\",\")\n",
    "\n",
    "  # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "  m_list = []\n",
    "  for issn_token in issn:\n",
    "    if issn_token in d_metric:\n",
    "      metrics = d_metric[issn_token]\n",
    "      m_list.append(metrics)\n",
    "\n",
    "  # check if this journal is found in d_meric\n",
    "  m_list2 = []\n",
    "  if m_list != []:\n",
    "    # get average if multiple issns\n",
    "    for idx in range(0,4):\n",
    "      m_sum = 0\n",
    "      for ms in m_list:\n",
    "        m_sum += ms[idx]\n",
    "      m_avg = m_sum / len(m_list)\n",
    "      m_list2.append(m_avg)\n",
    "\n",
    "  return m_list, m_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m_lst_lst(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code, if \"\", then all countries\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "  '''\n",
    "  \n",
    "  # Get sub-dataframe\n",
    "  if a3 == \"\":\n",
    "    df = df_acdty.loc[df_acdty['Year']==yr]\n",
    "  else:\n",
    "    df = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "\n",
    "  # pmid and issns\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid = pmids[idx]\n",
    "\n",
    "    m_list, m_list2 = get_m_list(pmid, issn, d_metric)\n",
    "\n",
    "    if m_list != []:\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through each country and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>n_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHN</td>\n",
       "      <td>60298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>59503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  n_pub\n",
       "0     CHN  60298\n",
       "1     USA  59503"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_npub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CHN', 'USA', 'JPN', 'DEU', 'FRA'], dtype=object),\n",
       " array(['TZA', 'CAF', 'SLV', 'IRN', 'TCD'], dtype=object))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get country list\n",
    "c_list = df_npub.country.values\n",
    "c_list[:5], c_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/165 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [01:02<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "c_y_avg = {} # {country: {year: [Prank, SJR, Hidx, Cite]}}\n",
    "yr_range = range(1999, 2021)\n",
    "\n",
    "# For each topic\n",
    "for a3 in tqdm(c_list):\n",
    "  c_y_avg[a3] = {}\n",
    "\n",
    "  # For each year\n",
    "  for yr in yr_range:\n",
    "    # [[prank, sjr, hidx, cite]] for all records in a given topic-year\n",
    "    m_lst_lst = get_m_lst_lst(a3, yr) \n",
    "    #print(len(m_lst_lst))\n",
    "    \n",
    "    # compile metrics into a 2d array\n",
    "    m_2d = []\n",
    "    for m_list in m_lst_lst:\n",
    "      m_2d.append(m_list[2])\n",
    "    m_2d  = np.array(m_2d)\n",
    "    # determine n_pub for each metric after removing NA\n",
    "    n_pub = np.subtract([m_2d.shape[0]]*4, sum(np.isnan(m_2d)))\n",
    "    \n",
    "    # For a few cases without publication, set to NaN\n",
    "    if 0 in n_pub:\n",
    "      c_y_avg[a3][yr] = [np.nan]*4\n",
    "    else:\n",
    "      # calculate average and store in dict\n",
    "      # Issue: RuntimeWarning: invalid value encountered in true_divide\n",
    "      # https://www.geeksforgeeks.org/how-to-fix-invalid-value-encountered-in-true_divide/\n",
    "      m_sum = np.nansum(m_2d, axis=0)\n",
    "      m_avg = np.divide(m_sum, n_pub)\n",
    "      c_y_avg[a3][yr] = m_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.79310982,   1.60306774, 177.93186373,   4.74823425]),\n",
       " array([  0.84167973,   2.20986465, 207.40929878,   5.10214558]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_y_avg['CHN'][2020], c_y_avg['USA'][2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate output\n",
    "\n",
    "Sorted according to:\n",
    "- df_npub: country - number of pubs (use c_list, already sorted)\n",
    "- Decide not to do normalization per country. The point is between country comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prank (165, 22)\n",
      "sjr (165, 22)\n",
      "hidx (165, 22)\n",
      "cite (165, 22)\n"
     ]
    }
   ],
   "source": [
    "excel_file    = work_dir / 'impact_country.xlsx'\n",
    "excel_writer  = pd.ExcelWriter(excel_file, engine='xlsxwriter')\n",
    "\n",
    "metric_names = ['prank', 'sjr', 'hidx', 'cite']\n",
    "c_order      = df_npub['country'].values\n",
    "for metric_idx in range(4):\n",
    "  metric_nm      = metric_names[metric_idx]\n",
    "  metric_2d      = [] # a 2D list: a3, then year\n",
    "  metric_2d_norm = [] # a 2D list: a3, then year, normalized for each a3\n",
    "  for a3 in c_list:\n",
    "    metric_a3 = []\n",
    "    for yr in yr_range:\n",
    "      metric_a3.append(c_y_avg[a3][yr][metric_idx])\n",
    "    metric_2d.append(metric_a3)\n",
    "\n",
    "    # do min-max normalization\n",
    "    #m_min = min(metric_a3)\n",
    "    #m_max = max(metric_a3)\n",
    "    #metric_a3_norm = [(m-m_min)/(m_max-m_min) for m in metric_a3]\n",
    "    #metric_2d_norm.append(metric_a3_norm)\n",
    "  \n",
    "  df_metric  = pd.DataFrame(metric_2d, index=c_list, columns=yr_range)\n",
    "  #df_metric2 = pd.DataFrame(metric_2d_norm, index=c_list, columns=yr_range)\n",
    "\n",
    "  # sort by the order of the number of publications\n",
    "  df_metric  = df_metric.reindex(c_order)\n",
    "  #df_metric2 = df_metric2.reindex(c_order)\n",
    "\n",
    "  print(metric_nm, df_metric.shape)\n",
    "  \n",
    "  df_metric.to_excel(excel_writer, sheet_name=metric_nm)\n",
    "  #df_metric2.to_excel(excel_writer, sheet_name=metric_nm+\"_norm\")\n",
    "\n",
    "excel_writer.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Overall impact___\n",
    "\n",
    "Realize that I should also calculate the impact per year over all countries to potentially use them as normalizing factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get yearly average impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:03<00:00,  6.81it/s]\n"
     ]
    }
   ],
   "source": [
    "y_avg = {} # {year: [Prank, SJR, Hidx, Cite]}\n",
    "\n",
    "# For each year\n",
    "for yr in tqdm(yr_range):\n",
    "  # [[prank, sjr, hidx, cite]] for all records in a given topic-year\n",
    "  m_lst_lst = get_m_lst_lst(\"\", yr) \n",
    "  #print(len(m_lst_lst))\n",
    "  \n",
    "  # compile metrics into a 2d array\n",
    "  m_2d = []\n",
    "  for m_list in m_lst_lst:\n",
    "    # m_list2 is in index=2\n",
    "    m_2d.append(m_list[2])\n",
    "\n",
    "  m_2d  = np.array(m_2d)\n",
    "  \n",
    "  # determine n_pub for each metric after removing NA\n",
    "  n_pub = np.subtract([m_2d.shape[0]]*4, sum(np.isnan(m_2d)))\n",
    "  \n",
    "  # For a few cases without publication, set to NaN\n",
    "  if 0 in n_pub:\n",
    "    y_avg[yr] = [np.nan]*4\n",
    "  else:\n",
    "    # calculate average and store in dict\n",
    "    # Issue: RuntimeWarning: invalid value encountered in true_divide\n",
    "    # https://www.geeksforgeeks.org/how-to-fix-invalid-value-encountered-in-true_divide/\n",
    "    m_sum = np.nansum(m_2d, axis=0)\n",
    "    m_avg = np.divide(m_sum, n_pub)\n",
    "    y_avg[yr] = m_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file2    = work_dir / 'impact_all_country_per_year.xlsx'\n",
    "excel_writer2  = pd.ExcelWriter(excel_file2, engine='xlsxwriter')\n",
    "\n",
    "metric_names = ['prank', 'sjr', 'hidx', 'cite']\n",
    "metric_2d    = [] # a 2D list: year, then metrics\n",
    "for yr in yr_range:\n",
    "  metric_2d.append(y_avg[yr])\n",
    "\n",
    "df_metric = pd.DataFrame(metric_2d, index=yr_range, columns=metric_names)\n",
    "df_metric.to_excel(excel_writer2, sheet_name=\"yearly overall\")\n",
    "\n",
    "excel_writer2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Additional analyses___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get average rank\n",
    "\n",
    "From prank, sjr, hindex, and cites/doc normalized values, they are sorted based on % missing values (<10%), num of pubs (>400), then a specific metric. The results are stored in the `summary` sheet in `impact_country_MOD.xlsx`.\n",
    "\n",
    "Get the averge rank for each country in the summary table.\n",
    "- [look up sheet names](https://stackoverflow.com/questions/17977540/pandas-looking-up-the-list-of-sheets-in-an-excel-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top</th>\n",
       "      <th>J-rank</th>\n",
       "      <th>SJR</th>\n",
       "      <th>H-idx</th>\n",
       "      <th>Cites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GBR</td>\n",
       "      <td>GBR</td>\n",
       "      <td>GBR</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Top J-rank  SJR H-idx Cites\n",
       "0    1    CHE  CHE   CHE   CHE\n",
       "1    2    GBR  GBR   GBR   GBR"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_xlsx = work_dir / \"impact_country_MOD.xlsx\"\n",
    "df = pd.read_excel(file_xlsx, sheet_name=\"summary\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/pandas-find-unique-values-from-multiple-columns/\n",
    "\n",
    "# len=47, so this is not needed as all columns have the same countries\n",
    "len(pd.concat([df['J-rank'],df['SJR'],df['H-idx'],df['Cites']]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"J-rank\"] == 'CHE']['Top'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHE': [1, 1, 1, 1],\n",
       " 'GBR': [2, 2, 2, 2],\n",
       " 'NLD': [3, 4, 5, 3],\n",
       " 'USA': [4, 3, 3, 4],\n",
       " 'SWE': [5, 9, 6, 9],\n",
       " 'FRA': [6, 6, 8, 7],\n",
       " 'ISR': [7, 7, 9, 6],\n",
       " 'DEU': [8, 5, 4, 5],\n",
       " 'AUS': [9, 13, 11, 12],\n",
       " 'DNK': [10, 12, 7, 11],\n",
       " 'FIN': [11, 15, 13, 16],\n",
       " 'IRL': [12, 16, 12, 14],\n",
       " 'CAN': [13, 14, 16, 15],\n",
       " 'AUT': [14, 11, 17, 13],\n",
       " 'NOR': [15, 17, 14, 17],\n",
       " 'BEL': [16, 10, 10, 8],\n",
       " 'SGP': [17, 8, 15, 10],\n",
       " 'ESP': [18, 19, 18, 18],\n",
       " 'NZL': [19, 20, 21, 20],\n",
       " 'TWN': [20, 21, 19, 21],\n",
       " 'ITA': [21, 23, 23, 22],\n",
       " 'JPN': [22, 18, 20, 19],\n",
       " 'CZE': [23, 22, 25, 23],\n",
       " 'PRT': [24, 24, 22, 24],\n",
       " 'SVN': [25, 32, 24, 30],\n",
       " 'ZAF': [26, 29, 30, 31],\n",
       " 'PHL': [27, 25, 32, 28],\n",
       " 'GRC': [28, 31, 29, 29],\n",
       " 'MEX': [29, 28, 27, 26],\n",
       " 'ARG': [30, 26, 26, 25],\n",
       " 'CHL': [31, 30, 28, 32],\n",
       " 'COL': [32, 34, 35, 35],\n",
       " 'BRA': [33, 35, 33, 34],\n",
       " 'HUN': [34, 27, 31, 27],\n",
       " 'THA': [35, 38, 38, 39],\n",
       " 'SVK': [36, 39, 41, 38],\n",
       " 'POL': [37, 36, 36, 36],\n",
       " 'TUN': [38, 42, 40, 40],\n",
       " 'IND': [39, 37, 37, 37],\n",
       " 'CHN': [40, 33, 34, 33],\n",
       " 'MYS': [41, 40, 39, 41],\n",
       " 'TUR': [42, 44, 43, 45],\n",
       " 'PAK': [43, 45, 44, 44],\n",
       " 'RUS': [44, 43, 45, 43],\n",
       " 'SAU': [45, 41, 42, 42],\n",
       " 'NGA': [46, 46, 46, 47],\n",
       " 'EGY': [47, 47, 47, 46]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_list = df['J-rank'].unique()\n",
    "c_dict = {} # {country: [rank_metric1, ....]}\n",
    "m_list = df.columns[1:]\n",
    "\n",
    "# for each country\n",
    "for c in c_list:\n",
    "  # for each metric\n",
    "  c_dict[c] = []\n",
    "  for m in m_list:\n",
    "    v = df[df[m] == c]['Top'].values[0]\n",
    "    c_dict[c].append(v)\n",
    "c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output\n",
    "file_c_avg_rank = work_dir / \"country_avg_rank.csv\"\n",
    "\n",
    "with open(file_c_avg_rank, 'w') as f:\n",
    "  f.write('country,J-rank,SJR,H-idx,Cites,Avg_rank\\n')\n",
    "\n",
    "  for c in c_list:\n",
    "    n_pub = df_npub[df_npub['country'] == c]['n_pub'].values[0]\n",
    "    ranks = \",\".join([str(r) for r in c_dict[c]])\n",
    "    f.write(f'{c},{ranks},{np.average(c_dict[c])}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topical area similarities between countries\n",
    "\n",
    "Do two things on the log(n_pub_country/n_pub_all) across topics between country pairs\n",
    "- KS test \n",
    "- Pearson's correl\n",
    "- Spearman's rank correl\n",
    "\n",
    "Topic 5 is dropped because >50% country has NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toc_name</th>\n",
       "      <th>CHN</th>\n",
       "      <th>USA</th>\n",
       "      <th>JPN</th>\n",
       "      <th>DEU</th>\n",
       "      <th>FRA</th>\n",
       "      <th>GBR</th>\n",
       "      <th>IND</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ITA</th>\n",
       "      <th>...</th>\n",
       "      <th>SWE</th>\n",
       "      <th>MEX</th>\n",
       "      <th>ISR</th>\n",
       "      <th>ARG</th>\n",
       "      <th>DNK</th>\n",
       "      <th>AUT</th>\n",
       "      <th>TWN</th>\n",
       "      <th>FIN</th>\n",
       "      <th>CZE</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergen | pollen | ige | allergenic</td>\n",
       "      <td>-3.312153</td>\n",
       "      <td>-1.542355</td>\n",
       "      <td>-0.055263</td>\n",
       "      <td>1.198622</td>\n",
       "      <td>-0.706536</td>\n",
       "      <td>-1.728808</td>\n",
       "      <td>-0.129337</td>\n",
       "      <td>2.473362</td>\n",
       "      <td>1.282652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005351</td>\n",
       "      <td>-1.870480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.841007</td>\n",
       "      <td>1.407829</td>\n",
       "      <td>4.874546</td>\n",
       "      <td>-1.354562</td>\n",
       "      <td>0.663111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.424717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium | callus | regeneration | culture | som...</td>\n",
       "      <td>-1.242767</td>\n",
       "      <td>-0.361898</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>-1.373959</td>\n",
       "      <td>-0.198650</td>\n",
       "      <td>-0.394981</td>\n",
       "      <td>2.660110</td>\n",
       "      <td>-0.503193</td>\n",
       "      <td>-0.559371</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.501572</td>\n",
       "      <td>0.147972</td>\n",
       "      <td>-0.680384</td>\n",
       "      <td>0.446187</td>\n",
       "      <td>-1.175619</td>\n",
       "      <td>-1.689199</td>\n",
       "      <td>0.479973</td>\n",
       "      <td>-0.405347</td>\n",
       "      <td>-1.996689</td>\n",
       "      <td>0.977939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fluorescence | detection | carbon dots | quant...</td>\n",
       "      <td>1.527449</td>\n",
       "      <td>-0.670790</td>\n",
       "      <td>-0.151140</td>\n",
       "      <td>-0.898798</td>\n",
       "      <td>-1.463035</td>\n",
       "      <td>-1.492804</td>\n",
       "      <td>1.717483</td>\n",
       "      <td>-0.779417</td>\n",
       "      <td>-0.606446</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.695345</td>\n",
       "      <td>-0.796187</td>\n",
       "      <td>-1.100190</td>\n",
       "      <td>-1.507906</td>\n",
       "      <td>-0.781978</td>\n",
       "      <td>-1.618565</td>\n",
       "      <td>0.731855</td>\n",
       "      <td>-1.019394</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>1.158348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glyphosate | resistance | herbicide | epsps | ...</td>\n",
       "      <td>-0.354139</td>\n",
       "      <td>1.074553</td>\n",
       "      <td>-1.009266</td>\n",
       "      <td>-1.862348</td>\n",
       "      <td>-0.410191</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>-1.767792</td>\n",
       "      <td>0.515976</td>\n",
       "      <td>-0.702754</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.717263</td>\n",
       "      <td>0.648813</td>\n",
       "      <td>1.895315</td>\n",
       "      <td>-0.371019</td>\n",
       "      <td>-2.211547</td>\n",
       "      <td>-2.201532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.193019</td>\n",
       "      <td>2.142193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uvb | stress | radiation | leaves | light</td>\n",
       "      <td>0.023069</td>\n",
       "      <td>-1.260985</td>\n",
       "      <td>-0.544993</td>\n",
       "      <td>-0.276598</td>\n",
       "      <td>-1.110769</td>\n",
       "      <td>-0.745533</td>\n",
       "      <td>0.476713</td>\n",
       "      <td>1.020558</td>\n",
       "      <td>0.769305</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.141131</td>\n",
       "      <td>-0.689553</td>\n",
       "      <td>0.349644</td>\n",
       "      <td>1.214957</td>\n",
       "      <td>-0.284094</td>\n",
       "      <td>-0.114779</td>\n",
       "      <td>-0.729694</td>\n",
       "      <td>0.428557</td>\n",
       "      <td>1.049800</td>\n",
       "      <td>0.750736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cell | imaging | microscopy | proteins | fluor...</td>\n",
       "      <td>-2.343031</td>\n",
       "      <td>0.394551</td>\n",
       "      <td>-0.108810</td>\n",
       "      <td>1.108182</td>\n",
       "      <td>0.878554</td>\n",
       "      <td>1.252378</td>\n",
       "      <td>-1.945473</td>\n",
       "      <td>-0.713480</td>\n",
       "      <td>-0.540380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565086</td>\n",
       "      <td>0.206532</td>\n",
       "      <td>-0.445615</td>\n",
       "      <td>-4.035713</td>\n",
       "      <td>0.199719</td>\n",
       "      <td>1.178670</td>\n",
       "      <td>-0.733056</td>\n",
       "      <td>-0.731165</td>\n",
       "      <td>1.356637</td>\n",
       "      <td>1.716389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              toc_name       CHN       USA  \\\n",
       "toc                                                                          \n",
       "0                 allergen | pollen | ige | allergenic -3.312153 -1.542355   \n",
       "1    medium | callus | regeneration | culture | som... -1.242767 -0.361898   \n",
       "2    fluorescence | detection | carbon dots | quant...  1.527449 -0.670790   \n",
       "3    glyphosate | resistance | herbicide | epsps | ... -0.354139  1.074553   \n",
       "4            uvb | stress | radiation | leaves | light  0.023069 -1.260985   \n",
       "6    cell | imaging | microscopy | proteins | fluor... -2.343031  0.394551   \n",
       "\n",
       "          JPN       DEU       FRA       GBR       IND       ESP       ITA  \\\n",
       "toc                                                                         \n",
       "0   -0.055263  1.198622 -0.706536 -1.728808 -0.129337  2.473362  1.282652   \n",
       "1    0.070518 -1.373959 -0.198650 -0.394981  2.660110 -0.503193 -0.559371   \n",
       "2   -0.151140 -0.898798 -1.463035 -1.492804  1.717483 -0.779417 -0.606446   \n",
       "3   -1.009266 -1.862348 -0.410191  0.576386 -1.767792  0.515976 -0.702754   \n",
       "4   -0.544993 -0.276598 -1.110769 -0.745533  0.476713  1.020558  0.769305   \n",
       "6   -0.108810  1.108182  0.878554  1.252378 -1.945473 -0.713480 -0.540380   \n",
       "\n",
       "     ...       SWE       MEX       ISR       ARG       DNK       AUT  \\\n",
       "toc  ...                                                               \n",
       "0    ...  1.005351 -1.870480       NaN -1.841007  1.407829  4.874546   \n",
       "1    ... -1.501572  0.147972 -0.680384  0.446187 -1.175619 -1.689199   \n",
       "2    ... -1.695345 -0.796187 -1.100190 -1.507906 -0.781978 -1.618565   \n",
       "3    ...       NaN -2.717263  0.648813  1.895315 -0.371019 -2.211547   \n",
       "4    ... -1.141131 -0.689553  0.349644  1.214957 -0.284094 -0.114779   \n",
       "6    ...  0.565086  0.206532 -0.445615 -4.035713  0.199719  1.178670   \n",
       "\n",
       "          TWN       FIN       CZE  Variance  \n",
       "toc                                          \n",
       "0   -1.354562  0.663111       NaN  3.424717  \n",
       "1    0.479973 -0.405347 -1.996689  0.977939  \n",
       "2    0.731855 -1.019394 -0.008688  1.158348  \n",
       "3   -2.201532       NaN -1.193019  2.142193  \n",
       "4   -0.729694  0.428557  1.049800  0.750736  \n",
       "6   -0.733056 -0.731165  1.356637  1.716389  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop toc 5\n",
    "t25_toc_stat = pd.read_csv(t25_toc_stat_file, index_col=0).drop([5])\n",
    "t25_toc_stat.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "300.0\n"
     ]
    }
   ],
   "source": [
    "# list of top 25 countries\n",
    "t25_list = t25_toc_stat.columns[1:-1].tolist()\n",
    "print(len(t25_list))\n",
    "\n",
    "# Expected number of non-self pairs: square matrix of 25*25 - 25 self, than half\n",
    "print((25*25-25)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1,c2,ks_stat,ks_pval,pr_stat,pr_pval,sp_stat,sp_pval\n",
    "t25_toc_pair_stat_file = work_dir / 't25_toc_pair_stat.csv'\n",
    "\n",
    "c_stats = {} # {c1:{c2:[[stat,pval],...]]} # if stat not significant, set to 0\n",
    "with open(t25_toc_pair_stat_file, 'w') as f:\n",
    "  f.write('c1,c2,ks_stat,ks_pval,pr_stat,pr_pval,sp_stat,sp_pval\\n')\n",
    "  for idx, c1 in enumerate(t25_list[:-1]):\n",
    "    c1_vals = t25_toc_stat[c1].values\n",
    "    c_stats[c1] = {}\n",
    "\n",
    "    # Deal with nan for pearsonr that does not take care of it\n",
    "    c1_nans = np.isnan(c1_vals)\n",
    "    for c2 in t25_list[idx+1:]:\n",
    "\n",
    "      if c2 in c_stats[c1]:\n",
    "        print(f\"ERROR: c_stats[{c1}][{c2}] already exist\")\n",
    "\n",
    "      c2_vals = t25_toc_stat[c2].values\n",
    "      c2_nans = np.isnan(c2_vals)\n",
    "\n",
    "      # Is nan in either\n",
    "      c1or2_nans     = c1_nans | c2_nans\n",
    "      # Is NOT nan in both\n",
    "      c1and2_nonnans = np.invert(c1or2_nans)\n",
    "\n",
    "      # Get c1and2_nonnan values\n",
    "      c1_nonan = c1_vals[c1and2_nonnans]\n",
    "      c2_nonan = c2_vals[c1and2_nonnans]\n",
    "\n",
    "      # stat, pval\n",
    "      (ks_st, ks_p) = kstest(c1_nonan, c2_nonan)\n",
    "      (pr_st, pr_p) = pearsonr(c1_nonan, c2_nonan)\n",
    "      (sp_st, sp_p) = spearmanr(c1_nonan, c2_nonan)\n",
    "\n",
    "      c_stats[c1][c2] = [[ks_st, ks_p], [pr_st, pr_p], [sp_st, sp_p]]\n",
    "\n",
    "      f.write(f'{c1},{c2},{ks_st},{ks_p},{pr_st},{pr_p},{sp_st},{sp_p}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.19101123595505617, 0.07764437164528368],\n",
       " [-0.21397456541669643, 0.04406415887324577],\n",
       " [-0.15318352059925094, 0.1518078756427866]]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_stats['CHN']['JPN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write stats metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_matrix(stat_flag):\n",
    "  '''\n",
    "  Args\n",
    "    stat_flag (str): ks, pr, or sp\n",
    "  '''\n",
    "  if stat_flag == \"ks\":   sidx = 0\n",
    "  elif stat_flag == \"pr\": sidx = 1\n",
    "  elif stat_flag == \"sp\": sidx = 2\n",
    "  else:                   print(\"ERR: unknwon stat flag,\", stat); return 0\n",
    "\n",
    "  file_name = work_dir / f't25_toc_pair_{stat_flag}_mat.csv'\n",
    "\n",
    "  with open(file_name, 'w') as f:\n",
    "\n",
    "    # Write stat matrix\n",
    "    f.write(\"Statistics\\n,\"+','.join(t25_list[1:])+ \"\\n\")\n",
    "    for idx, c1 in enumerate(t25_list[:-1]):\n",
    "      stats = []\n",
    "      for c2 in t25_list[idx+1:]:\n",
    "        stat = c_stats[c1][c2][sidx].copy()\n",
    "        stats.append(stat)\n",
    "      f.write(c1 + \",\"*(idx+1) + \",\".join([str(s[0]) for s in stats]) + \"\\n\")\n",
    "\n",
    "    # Write p-value matrix\n",
    "    f.write(\"\\n\\n\\'-log(P-values)\\'\\n,\"+','.join(t25_list[1:])+ \"\\n\")\n",
    "    for idx, c1 in enumerate(t25_list[:-1]):\n",
    "      stats = []\n",
    "      for c2 in t25_list[idx+1:]:\n",
    "        stat = c_stats[c1][c2][sidx].copy()\n",
    "        stats.append(stat)\n",
    "      f.write(c1 + \",\"*(idx+1) + \",\".join([str(-log10(s[1])) for s in stats]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_matrix(\"pr\")\n",
    "write_matrix(\"sp\")\n",
    "write_matrix(\"ks\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering of correlation matrix\n",
    "\n",
    "Realize that the above matrices need to be further processed\n",
    "- Particularly, want to see if there are clusters of countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHN</th>\n",
       "      <th>USA</th>\n",
       "      <th>JPN</th>\n",
       "      <th>DEU</th>\n",
       "      <th>FRA</th>\n",
       "      <th>GBR</th>\n",
       "      <th>IND</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ITA</th>\n",
       "      <th>AUS</th>\n",
       "      <th>...</th>\n",
       "      <th>SWE</th>\n",
       "      <th>MEX</th>\n",
       "      <th>ISR</th>\n",
       "      <th>ARG</th>\n",
       "      <th>DNK</th>\n",
       "      <th>AUT</th>\n",
       "      <th>TWN</th>\n",
       "      <th>FIN</th>\n",
       "      <th>CZE</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.312153</td>\n",
       "      <td>-1.542355</td>\n",
       "      <td>-0.055263</td>\n",
       "      <td>1.198622</td>\n",
       "      <td>-0.706536</td>\n",
       "      <td>-1.728808</td>\n",
       "      <td>-0.129337</td>\n",
       "      <td>2.473362</td>\n",
       "      <td>1.282652</td>\n",
       "      <td>0.288292</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005351</td>\n",
       "      <td>-1.870480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.841007</td>\n",
       "      <td>1.407829</td>\n",
       "      <td>4.874546</td>\n",
       "      <td>-1.354562</td>\n",
       "      <td>0.663111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.424717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.242767</td>\n",
       "      <td>-0.361898</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>-1.373959</td>\n",
       "      <td>-0.198650</td>\n",
       "      <td>-0.394981</td>\n",
       "      <td>2.660110</td>\n",
       "      <td>-0.503193</td>\n",
       "      <td>-0.559371</td>\n",
       "      <td>-1.091094</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.501572</td>\n",
       "      <td>0.147972</td>\n",
       "      <td>-0.680384</td>\n",
       "      <td>0.446187</td>\n",
       "      <td>-1.175619</td>\n",
       "      <td>-1.689199</td>\n",
       "      <td>0.479973</td>\n",
       "      <td>-0.405347</td>\n",
       "      <td>-1.996689</td>\n",
       "      <td>0.977939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CHN       USA       JPN       DEU       FRA       GBR       IND  \\\n",
       "toc                                                                         \n",
       "0   -3.312153 -1.542355 -0.055263  1.198622 -0.706536 -1.728808 -0.129337   \n",
       "1   -1.242767 -0.361898  0.070518 -1.373959 -0.198650 -0.394981  2.660110   \n",
       "\n",
       "          ESP       ITA       AUS  ...       SWE       MEX       ISR  \\\n",
       "toc                                ...                                 \n",
       "0    2.473362  1.282652  0.288292  ...  1.005351 -1.870480       NaN   \n",
       "1   -0.503193 -0.559371 -1.091094  ... -1.501572  0.147972 -0.680384   \n",
       "\n",
       "          ARG       DNK       AUT       TWN       FIN       CZE  Variance  \n",
       "toc                                                                        \n",
       "0   -1.841007  1.407829  4.874546 -1.354562  0.663111       NaN  3.424717  \n",
       "1    0.446187 -1.175619 -1.689199  0.479973 -0.405347 -1.996689  0.977939  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t25_toc_stat2 = t25_toc_stat.drop(columns=['toc_name'])\n",
    "t25_toc_stat2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t25_toc_corr = t25_toc_stat2.corr()\n",
    "t25_toc_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Original dataset')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spectral co-clustering\n",
    "#https://scikit-learn.org/stable/modules/biclustering.html\n",
    "#https://scikit-learn.org/stable/auto_examples/bicluster/plot_spectral_coclustering.html#sphx-glr-auto-examples-bicluster-plot-spectral-coclustering-py\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import SpectralCoclustering\n",
    "from sklearn.metrics import consensus_score\n",
    "\n",
    "data = t25_toc_corr\n",
    "plt.matshow(data, cmap=plt.cm.Blues)\n",
    "plt.title(\"Original dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = 0\n",
    "best_score = 0\n",
    "for n in range(3,10):\n",
    "  model = SpectralCoclustering(n_clusters=5, random_state=seed)\n",
    "  model.fit(data)\n",
    "  score = consensus_score(model.biclusters_, (rows[:, row_idx], columns[:, col_idx]))\n",
    "  if \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralCoclustering(n_clusters=5, random_state=seed)\n",
    "model.fit(data)\n",
    "score = consensus_score(model.biclusters_, (rows[:, row_idx], columns[:, col_idx]))\n",
    "\n",
    "print(\"consensus score: {:.3f}\".format(score))\n",
    "\n",
    "fit_data = data[np.argsort(model.row_labels_)]\n",
    "fit_data = fit_data[:, np.argsort(model.column_labels_)]\n",
    "\n",
    "plt.matshow(fit_data, cmap=plt.cm.Blues)\n",
    "plt.title(\"After biclustering; rearranged to show biclusters\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Test___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs between two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False]),\n",
       " array([False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False]),\n",
       " array([False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False]),\n",
       " array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_vals = t25_toc_stat['IND'].values\n",
    "test2_vals = t25_toc_stat['NLD'].values\n",
    "\n",
    "test1_nans = np.isnan(test1_vals)\n",
    "test2_nans = np.isnan(test2_vals)\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-invert-the-elements-of-a-boolean-array-in-python/\n",
    "test1or2_nans = test1_nans | test2_nans\n",
    "test1and2_nonnans = np.invert(test1or2_nans)\n",
    "\n",
    "test1_nans, test2_nans, test1or2_nans, test1and2_nonnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 87)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_nonan = test1_vals[test1and2_nonnans]\n",
    "test2_nonan = test2_vals[test1and2_nonnans]\n",
    "\n",
    "# Expect to be 90 -1 (topic 5) - 2 (two topic with nan values) = 87\n",
    "len(test1_nonan), len(test2_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.12933662,  2.66010959,  1.7174831 , -1.76779159,  0.47671307,\n",
       "        -1.94547324, -4.1492131 ,  0.5549004 , -2.14510986, -1.07288652,\n",
       "        -0.91212946, -0.36314519,  1.06158892,  0.42454886, -0.63767684,\n",
       "        -0.60575321, -0.42400763, -0.82656079, -1.36290649, -2.94103127,\n",
       "                nan, -1.44313146]),\n",
       " array([-0.12933662,  2.66010959,  1.7174831 ,  0.47671307, -1.94547324,\n",
       "        -4.1492131 ,  0.5549004 , -2.14510986, -1.07288652, -0.91212946,\n",
       "        -0.36314519,  1.06158892,  0.42454886, -0.63767684, -0.60575321,\n",
       "        -0.42400763, -0.82656079, -1.36290649, -2.94103127, -1.44313146,\n",
       "         0.94431466,  0.49696444]),\n",
       " array([ 0.70030879, -0.64844307, -1.32389994,         nan, -0.68618942,\n",
       "         0.35275611,  0.93099359, -0.35566446, -2.29403162, -1.03693063,\n",
       "        -0.30094133,  0.82342711, -3.19207138,  1.34187893, -0.15075686,\n",
       "         1.34994237,  0.08738711,  0.02734866, -0.58189349,  0.72963087,\n",
       "        -1.19952463,  0.37945306]),\n",
       " array([ 0.70030879, -0.64844307, -1.32389994, -0.68618942,  0.35275611,\n",
       "         0.93099359, -0.35566446, -2.29403162, -1.03693063, -0.30094133,\n",
       "         0.82342711, -3.19207138,  1.34187893, -0.15075686,  1.34994237,\n",
       "         0.08738711,  0.02734866, -0.58189349,  0.72963087,  0.37945306,\n",
       "        -2.07431777, -0.63309683]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elements are deleted properly\n",
    "test1_vals[:22], test1_nonan[:22], test2_vals[:22], test2_nonan[:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced\n",
    "def get_m_lst_lst_v1(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "    not_found (dict): {journal: [issn, [pmids]]}\n",
    "  '''\n",
    "  \n",
    "  df        = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  \n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "  #not_found = {}             # {journal: [issn, [pmids]}\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid    = pmids[idx]\n",
    "\n",
    "    # first check if issn is np.nan\n",
    "    if type(issn) == float:\n",
    "      if not np.isnan(issn):\n",
    "        print(\"ERR: float but not nan\", issn)\n",
    "      issn = []\n",
    "    else:\n",
    "      issn = issn.split(\",\")\n",
    "\n",
    "    # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "    m_list = []\n",
    "    for issn_token in issn:\n",
    "      if issn_token in d_metric:\n",
    "        metrics = d_metric[issn_token]\n",
    "        m_list.append(metrics)\n",
    "\n",
    "    # check if this journal is found in d_meric\n",
    "    m_list2 = [] # for getting average if multiple issns\n",
    "    if m_list != []:\n",
    "      for idx in range(0,4):\n",
    "        m_sum = 0\n",
    "        for ms in m_list:\n",
    "          m_sum += ms[idx]\n",
    "        m_avg = m_sum / len(m_list)\n",
    "        m_list2.append(m_avg)\n",
    "\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced\n",
    "def get_m_lst_lst_v1(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "    not_found (dict): {journal: [issn, [pmids]]}\n",
    "  '''\n",
    "  \n",
    "  df        = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  \n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "  #not_found = {}             # {journal: [issn, [pmids]}\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid    = pmids[idx]\n",
    "\n",
    "    # first check if issn is np.nan\n",
    "    if type(issn) == float:\n",
    "      if not np.isnan(issn):\n",
    "        print(\"ERR: float but not nan\", issn)\n",
    "      issn = []\n",
    "    else:\n",
    "      issn = issn.split(\",\")\n",
    "\n",
    "    # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "    m_list = []\n",
    "    for issn_token in issn:\n",
    "      if issn_token in d_metric:\n",
    "        metrics = d_metric[issn_token]\n",
    "        m_list.append(metrics)\n",
    "\n",
    "    # check if this journal is found in d_meric\n",
    "    m_list2 = [] # for getting average if multiple issns\n",
    "    if m_list != []:\n",
    "      for idx in range(0,4):\n",
    "        m_sum = 0\n",
    "        for ms in m_list:\n",
    "          m_sum += ms[idx]\n",
    "        m_avg = m_sum / len(m_list)\n",
    "        m_list2.append(m_avg)\n",
    "\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced\n",
    "def get_m_lst_lst_v1(a3, yr):\n",
    "  '''Get a list of metric lists for a given country and year\n",
    "  Args:\n",
    "    a3 (str): country a3 code\n",
    "    yr (int): year\n",
    "  Return:\n",
    "    m_lst_lst (list): [m_lst], where m_lst = [pmid, journal, issn, [Prank, SJR,\n",
    "      Hidx, Cite]]\n",
    "    not_found (dict): {journal: [issn, [pmids]]}\n",
    "  '''\n",
    "  \n",
    "  df        = df_acdty.loc[(df_acdty['A3']==a3) & (df_acdty['Year']==yr)]\n",
    "  pmids     = df.index\n",
    "  issns     = df['ISSN'].values\n",
    "  \n",
    "  d_metric  = d_d_metric[yr] # {issn: [Prank, SJR, Hidx, Cite]}\n",
    "  #not_found = {}             # {journal: [issn, [pmids]}\n",
    "  m_lst_lst = []  # [m_lst]\n",
    "  for idx, issn in enumerate(issns):\n",
    "    pmid    = pmids[idx]\n",
    "\n",
    "    # first check if issn is np.nan\n",
    "    if type(issn) == float:\n",
    "      if not np.isnan(issn):\n",
    "        print(\"ERR: float but not nan\", issn)\n",
    "      issn = []\n",
    "    else:\n",
    "      issn = issn.split(\",\")\n",
    "\n",
    "    # make sure issn, if exist, is in d_metric, then append to a metric list\n",
    "    m_list = []\n",
    "    for issn_token in issn:\n",
    "      if issn_token in d_metric:\n",
    "        metrics = d_metric[issn_token]\n",
    "        m_list.append(metrics)\n",
    "\n",
    "    # check if this journal is found in d_meric\n",
    "    m_list2 = [] # for getting average if multiple issns\n",
    "    if m_list != []:\n",
    "      for idx in range(0,4):\n",
    "        m_sum = 0\n",
    "        for ms in m_list:\n",
    "          m_sum += ms[idx]\n",
    "        m_avg = m_sum / len(m_list)\n",
    "        m_list2.append(m_avg)\n",
    "\n",
    "      # need m_list2, but add more info for debugging\n",
    "      m_lst_lst.append([pmid, issn,m_list2, m_list])\n",
    "\n",
    "  return m_lst_lst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
